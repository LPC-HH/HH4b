{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b003fdb7-5d91-4742-b23e-099459ad23b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "import utils\n",
    "import plotting\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "import mplhep as hep\n",
    "import vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "deabb526-29f4-4163-9feb-4131d6b9e538",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['GluGlutoHHto4B_kl-1p00_kt-1p00_c2-0p00_TuneCP5_13p6TeV_Private', 'QCD_HT-1000to1200', 'QCD_HT-1200to1500', 'QCD_HT-1500to2000', 'QCD_HT-2000', 'QCD_HT-200to400', 'QCD_HT-400to600', 'QCD_HT-600to800', 'QCD_HT-800to1000', 'TTto4Q', 'TTtoLNu2Q', 'VBFHHto4B_CV_1_C2V_1_C3_1_TuneCP5_13p6TeV_madgraph-pythia8', 'WminusH_Hto2B_Wto2Q_M-125', 'WplusH_Hto2B_Wto2Q_M-125', 'ZH_Hto2B_Zto2Q_M-125', 'ggZH_Hto2B_Zto2Q_M-125']\n",
      "Loading QCD_HT-1000to1200\n",
      "/eos/uscms/store/user/cmantill/bbbb/skimmer/24Jan18_v12//2022/QCD_HT-1000to1200/parquet\n",
      "Filter anbd Sample\n",
      "<class 'filter'>\n",
      "None\n",
      "QCD_HT-1000to1200\n",
      "Loading QCD_HT-1200to1500\n",
      "/eos/uscms/store/user/cmantill/bbbb/skimmer/24Jan18_v12//2022/QCD_HT-1200to1500/parquet\n",
      "Filter anbd Sample\n",
      "<class 'filter'>\n",
      "None\n",
      "QCD_HT-1200to1500\n",
      "Loading QCD_HT-1500to2000\n",
      "/eos/uscms/store/user/cmantill/bbbb/skimmer/24Jan18_v12//2022/QCD_HT-1500to2000/parquet\n",
      "Filter anbd Sample\n",
      "<class 'filter'>\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:No parquet file for QCD_HT-2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QCD_HT-1500to2000\n",
      "Loading QCD_HT-200to400\n",
      "/eos/uscms/store/user/cmantill/bbbb/skimmer/24Jan18_v12//2022/QCD_HT-200to400/parquet\n",
      "Filter anbd Sample\n",
      "<class 'filter'>\n",
      "None\n",
      "QCD_HT-200to400\n",
      "Loading QCD_HT-400to600\n",
      "/eos/uscms/store/user/cmantill/bbbb/skimmer/24Jan18_v12//2022/QCD_HT-400to600/parquet\n",
      "Filter anbd Sample\n",
      "<class 'filter'>\n",
      "None\n",
      "QCD_HT-400to600\n",
      "Loading QCD_HT-600to800\n",
      "/eos/uscms/store/user/cmantill/bbbb/skimmer/24Jan18_v12//2022/QCD_HT-600to800/parquet\n",
      "Filter anbd Sample\n",
      "<class 'filter'>\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:No parquet file for QCD_HT-800to1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QCD_HT-600to800\n",
      "Loading TTto4Q\n",
      "/eos/uscms/store/user/cmantill/bbbb/skimmer/24Jan18_v12//2022/TTto4Q/parquet\n",
      "Filter anbd Sample\n",
      "<class 'filter'>\n",
      "None\n",
      "TTto4Q\n",
      "Loading TTtoLNu2Q\n",
      "/eos/uscms/store/user/cmantill/bbbb/skimmer/24Jan18_v12//2022/TTtoLNu2Q/parquet\n",
      "Filter anbd Sample\n",
      "<class 'filter'>\n",
      "None\n",
      "TTtoLNu2Q\n",
      "Loading GluGlutoHHto4B_kl-1p00_kt-1p00_c2-0p00_TuneCP5_13p6TeV_Private\n",
      "/eos/uscms/store/user/cmantill/bbbb/skimmer/24Jan18_v12//2022/GluGlutoHHto4B_kl-1p00_kt-1p00_c2-0p00_TuneCP5_13p6TeV_Private/parquet\n",
      "Filter anbd Sample\n",
      "<class 'filter'>\n",
      "None\n",
      "GluGlutoHHto4B_kl-1p00_kt-1p00_c2-0p00_TuneCP5_13p6TeV_Private\n",
      "Keys:\n",
      "dict_keys(['qcd', 'ttbar'])\n"
     ]
    }
   ],
   "source": [
    "#Load your dataset\n",
    "samples = {\n",
    "    \n",
    "    \"qcd\": [\n",
    "        \"QCD_HT-1000to1200\",\n",
    "        \"QCD_HT-1200to1500\",\n",
    "        \"QCD_HT-1500to2000\",\n",
    "        \"QCD_HT-2000\",\n",
    "        \"QCD_HT-200to400\",\n",
    "        \"QCD_HT-400to600\",\n",
    "        \"QCD_HT-600to800\",\n",
    "        \"QCD_HT-800to1000\",\n",
    "    ],\n",
    "    \"ttbar\": [\n",
    "        \"TTto4Q\",\n",
    "        \"TTtoLNu2Q\",\n",
    "        \n",
    "    ],  \n",
    "    \"hh4b\": [\n",
    "        \"GluGlutoHHto4B_kl-1p00_kt-1p00_c2-0p00_TuneCP5_13p6TeV_Private\",\n",
    "    ],\n",
    "}\n",
    "\n",
    "year = \"2022\"#\n",
    "dir_name = \"24Jan18_v12\"\n",
    "path_to_dir = f\"/eos/uscms/store/user/cmantill/bbbb/skimmer/{dir_name}/\"\n",
    "dirs = {path_to_dir: samples}\n",
    "\n",
    "filters = [\n",
    "    [\n",
    "        (\"('ak8FatJetPt', '0')\", \">=\", 300),\n",
    "        (\"('ak8FatJetPt', '1')\", \">=\", 300),\n",
    "        (\"('ak8FatJetMsd', '0')\", \">=\", 50),\n",
    "        (\"('ak8FatJetPNetMass', '1')\", \">=\", 50),\n",
    "        (\"('ak8FatJetPNetXbb', '0')\", \">=\", 0.8),  \n",
    "        \n",
    "        #wasn't getting any hh4b events because of the filter\n",
    "    ]\n",
    "]\n",
    "\n",
    "# columns to load                                                                                                                                                                                                                                     \n",
    "# the parquet files are too big so we can only load a few columns at a time without consumming much memory\n",
    "load_columns = [\n",
    "    (\"weight\", 1),\n",
    "\t(\"ak8FatJetMsd\", 2),\n",
    "    (\"ak8FatJetPNetMass\", 2),\n",
    "\t(\"ak8FatJetPNetXbb\", 2),                                                                                                                                                                                                                     \n",
    "]\n",
    "# reformat into (\"column name\", \"idx\") format for reading multiindex columns                                                                                                                                                                          \n",
    "columns = []\n",
    "for key, num_columns in load_columns:\n",
    "    for i in range(num_columns):\n",
    "        columns.append(f\"('{key}', '{i}')\")\n",
    "\n",
    "\n",
    "events_dict = {}\n",
    "for input_dir, samples in dirs.items():\n",
    "   \n",
    "    events_dict = {\n",
    "        **events_dict,\n",
    "        # this function will load files (only the columns selected), apply filters and compute a weight per event\n",
    "        **utils.load_samples(input_dir, samples, year, filters=filters),\n",
    "    }\n",
    "print(\"Keys:\")\n",
    "print(events_dict.keys())\n",
    "samples_loaded = list(events_dict.keys())\n",
    "#print(samples_loaded)\n",
    "keys_loaded = list(events_dict[samples_loaded[0]].keys())\n",
    "\n",
    "#print(events_dict['qcd'])\n",
    "#This section prints all keys for inspection\n",
    "#print(f\"Keys in events_dict\")\n",
    "#for i in keys_loaded:\n",
    "#    print(i)\n",
    "\n",
    "\n",
    "# Assuming df has features and a binary target column named 'target'\n",
    "#features = df.drop('target', axis=1)\n",
    "#target = df['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a73db755-debc-4afa-a1fe-512163a2d9af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_vector(events: pd.DataFrame, obj: str):\n",
    "    \"\"\"Create a ``vector`` object from the columns of the dataframe\"\"\"\n",
    "    mstring = \"PNetMass\" if obj == \"ak8FatJet\" else \"Mass\"\n",
    "\n",
    "    return vector.array(\n",
    "        {\n",
    "            \"pt\": events[f\"{obj}Pt\"],\n",
    "            \"phi\": events[f\"{obj}Phi\"],\n",
    "            \"eta\": events[f\"{obj}Eta\"],\n",
    "            \"M\": events[f\"{obj}{mstring}\"],\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "db83ad36-5089-4488-af17-cb64a5f919f5",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'hh4b'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#DEFINE FEATURES & TARGET\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m events \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([\u001b[43mevents_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhh4b\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m, events_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mqcd\u001b[39m\u001b[38;5;124m\"\u001b[39m], events_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mttbar\u001b[39m\u001b[38;5;124m\"\u001b[39m]], keys\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhh4b\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mqcd\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mttbar\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m#events['target'] = 0  # Default to 0 (background)\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m#events.loc['hh4b', 'target'] = 1  # Set to 1 for 'hh4b' samples (signal)\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m#print(events)\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Extracting all unique keys\u001b[39;00m\n\u001b[1;32m     11\u001b[0m all_keys \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(key \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m events[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata_column\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(row, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m row\u001b[38;5;241m.\u001b[39mkeys())\n",
      "\u001b[0;31mKeyError\u001b[0m: 'hh4b'"
     ]
    }
   ],
   "source": [
    "#DEFINE FEATURES & TARGET\n",
    "\n",
    "\n",
    "events = pd.concat([events_dict[\"hh4b\"], events_dict[\"qcd\"], events_dict[\"ttbar\"]], keys=['hh4b','qcd', 'ttbar'])\n",
    "\n",
    "#events['target'] = 0  # Default to 0 (background)\n",
    "#events.loc['hh4b', 'target'] = 1  # Set to 1 for 'hh4b' samples (signal)\n",
    "\n",
    "#print(events)\n",
    "# Extracting all unique keys\n",
    "all_keys = set(key for row in events['data_column'] if isinstance(row, dict) for key in row.keys())\n",
    "\n",
    "# Display all unique keys\n",
    "print(all_keys)\n",
    "\n",
    "# fatjets sorted by xbb\n",
    "fatjets = make_vector(events, \"ak8FatJet\")\n",
    "\n",
    "# H1 candidate\n",
    "h1 = fatjets[:, 0]\n",
    "# H2 candidate\n",
    "h2 = fatjets[:, 1]\n",
    "\n",
    "h1_xbb = events.ak8FatJetPNetXbb[0]\n",
    "h2_xbb = events.ak8FatJetPNetXbb[1]\n",
    "\n",
    "# dihiggs candidate object\n",
    "hh = h1 + h2\n",
    "\n",
    "#define the dataframe\n",
    "df = pd.DataFrame()\n",
    "\n",
    "# define feature variables\n",
    "df['HHlogPt'] = np.log(hh.pt)\n",
    "df['HHeta'] = hh.eta\n",
    "df['HHmass'] = hh.mass\n",
    "#missing transverse energy\n",
    "#jet 1 Tau_32\n",
    "#jet 2 Tau_32\n",
    "# jet 1 softdrop mass\n",
    "df['H1logPt'] = np.log(h1.pt)\n",
    "df['H1eta'] = h1.eta\n",
    "df['H1Xbb'] = h1_xbb\n",
    "# Jet1 QCD b score\n",
    "# Jet 1 QCDbb score\n",
    "# Jet 1 QCDothers score\n",
    "df['H2logPt'] = np.log(h2.pt)\n",
    "df['H1Pt_HHmass'] = h1.pt/hh.mass\n",
    "df['H2Pt_HHmass'] = h2.pt/hh.mass\n",
    "df['H1Pt/H2Pt'] = h1.pt/h2.pt\n",
    "\n",
    "\n",
    "df.replace(np.inf, 10000, inplace=True)\n",
    "df.replace(-np.inf, 10000, inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af5f5cec-9f74-4a38-aa60-f37002144241",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LOAD FEATURES INTO PD DF\n",
    "\n",
    "features = df\n",
    "\n",
    "#define target\n",
    "target = events['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f593aee3-1d75-4da4-b50b-e10b81896b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "906a8c6a-d227-4f63-b528-23f11ba4b0f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the BDT model\n",
    "bdt_model = XGBClassifier(\n",
    "    n_estimators= 196,\n",
    "    max_depth= 17,\n",
    "    learning_rate=0.1,\n",
    "    subsample=0.5,\n",
    "    random_state=42\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c0864d-2c2e-400e-b378-b930a21bf100",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "bdt_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b88fb2-830c-4ff7-bdfe-fc3e5d476e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "predictions = bdt_model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c7a8344-d16a-4cc2-bab5-bc0220aca5f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "roc_auc = roc_auc_score(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1019742-7f30-4a8c-a282-e739e5c697ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "812f1af7-2b20-4a25-a972-4d6cec55fa92",
   "metadata": {},
   "outputs": [],
   "source": [
    "probabilities = bdt_model.predict_proba(X_test)\n",
    "\n",
    "print(probabilities[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d947c38d-d2ee-4fb2-bc93-71fc12d6f052",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_scores = bdt_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_scores)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "#histogram for y scores signal & background \n",
    "#rank by importance\n",
    "\n",
    "#number of b-jets that can be identified in resolved\n",
    "#another feather cos(theta_star)\n",
    "\n",
    "#Plottting\n",
    "plt.figure()\n",
    "plt.plot(tpr, fpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.xlabel('Signal (HH)')\n",
    "plt.ylabel('Background (QCD&ttbar)')\n",
    "plt.title('ROC')\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.yscale('log')\n",
    "plt.savefig('plots/ROC_BDT.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8375cfbb-5666-4fd2-982a-9f8146ac2604",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from skopt import BayesSearchCV\n",
    "import numpy as np\n",
    "\n",
    "# Load data\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "# Define the model\n",
    "model = RandomForestClassifier()\n",
    "\n",
    "# Define the hyperparameters and their ranges\n",
    "search_space = {\n",
    "    'n_estimators': (10, 200),  # Integer range\n",
    "    'max_depth': (5, 50)        # Integer range\n",
    "}\n",
    "\n",
    "# Set up Bayesian optimization\n",
    "bayes_search = BayesSearchCV(model, search_space, n_iter=32, scoring='accuracy', cv=5, n_jobs=-1, random_state=0)\n",
    "\n",
    "# Perform the Bayesian optimization\n",
    "bayes_search.fit(X, y)\n",
    "\n",
    "# Best parameters\n",
    "print(\"Best parameters:\", bayes_search.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d0cbfb-52e3-43e4-84a5-c78152226f36",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#determine importance of the features\n",
    "\n",
    "importances = bdt_model.feature_importances_\n",
    "\n",
    "feature_names = df.columns\n",
    "feature_importance = sorted(zip(feature_names, importances), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "for feature in feature_importance:\n",
    "    print(f\"{feature[0]}: {feature[1]:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c21d45a9-9fae-4e43-8b34-100feb411632",
   "metadata": {},
   "outputs": [],
   "source": [
    "hh4b_scores = bdt_model.predict_proba(X_test.loc['hh4b'])[:, 1]\n",
    "qcd_scores = bdt_model.predict_proba(X_test.loc['qcd'])[:, 1]\n",
    "ttbar_scores = bdt_model.predict_proba(X_test.loc['ttbar'])[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d15a1a42-eb7e-489b-b3fa-cdba4cc35bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.hist(hh4b_scores, bins=40, histtype='step', linewidth=1.5, color='darkblue')\n",
    "plt.hist(qcd_scores, bins=40, histtype='step', linewidth=1.5, color='red')\n",
    "plt.hist(ttbar_scores, bins=40, histtype='step', linewidth=1.5, color='darkgreen')\n",
    "plt.legend(['hh4b', 'qcd', 'ttbar'])\n",
    "plt.ylabel('Frequency')\n",
    "plt.xlabel('Prediciton Score')\n",
    "plt.title('Model Predictions Histogram')\n",
    "plt.yscale('log')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da465544-356a-4058-9226-4ad841afe4de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

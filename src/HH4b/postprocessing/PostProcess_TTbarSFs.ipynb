{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Postprocessing\n",
    "\n",
    "Makes control plots and templates.\n",
    "\n",
    "Authors: Raghav Kansal, Cristina Suarez"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "from HH4b import utils, plotting, postprocessing\n",
    "from HH4b.postprocessing import Region, weight_shifts\n",
    "from HH4b.utils import ShapeVar, CUT_MAX_VAL\n",
    "from HH4b.hh_vars import samples, data_key, bg_keys, sig_keys, LUMI\n",
    "\n",
    "from pathlib import Path\n",
    "from hist import Hist\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import mplhep as hep\n",
    "import matplotlib.ticker as mticker\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "plt.style.use(hep.style.CMS)\n",
    "hep.style.use(\"CMS\")\n",
    "formatter = mticker.ScalarFormatter(useMathText=True)\n",
    "formatter.set_powerlimits((-3, 3))\n",
    "plt.rcParams.update({\"font.size\": 16})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# automatically reloads imported files on edits\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAIN_DIR = \"../../../\"\n",
    "# this is the directory to the files\n",
    "# path_to_dir = f\"{MAIN_DIR}/../data/skimmer/Oct26/\"\n",
    "path_to_dir = \"/eos/uscms/store/user/ddiaz/bbbb/skimmer/24Mar31_v12_semilep-tt\"\n",
    "# path_to_dir = \"/eos/uscms/store/user/cmantill/bbbb/skimmer/24Feb1_v12_semilep-tt\"\n",
    "year = \"All\"\n",
    "\n",
    "# make plot and template directory\n",
    "date = \"24Mar31_v12_semilep-tt\"\n",
    "plot_dir = Path(f\"{MAIN_DIR}/plots/PostProcessing/{date}/{year}\")\n",
    "template_dir = f\"templates/{date}/\"\n",
    "_ = os.system(f\"mkdir -p {plot_dir}\")\n",
    "_ = os.system(f\"mkdir -p {template_dir}/cutflows/{year}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hh4b\n",
      "qcd\n",
      "data\n",
      "ttbar\n",
      "gghtobb\n",
      "vbfhtobb\n",
      "vhtobb\n",
      "tthtobb\n",
      "diboson\n",
      "vjetslnu\n",
      "vjets\n",
      "------------\n",
      "hh4b\n",
      "qcd\n",
      "data\n",
      "ttbar\n",
      "gghtobb\n",
      "vbfhtobb\n",
      "vhtobb\n",
      "tthtobb\n",
      "diboson\n",
      "vjetslnu\n",
      "vjets\n",
      "------------\n",
      "hh4b\n",
      "qcd\n",
      "data\n",
      "ttbar\n",
      "gghtobb\n",
      "vbfhtobb\n",
      "vhtobb\n",
      "tthtobb\n",
      "diboson\n",
      "vjetslnu\n",
      "vjets\n",
      "------------\n",
      "hh4b\n",
      "qcd\n",
      "data\n",
      "ttbar\n",
      "gghtobb\n",
      "vbfhtobb\n",
      "vhtobb\n",
      "tthtobb\n",
      "diboson\n",
      "vjetslnu\n",
      "vjets\n",
      "------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define dictionary with directories of files (this can be configured in a yaml file later in the script)\n",
    "sig_keys = []\n",
    "# ---2022\n",
    "samples_2022 = deepcopy(samples[\"2022\"])\n",
    "for key in list(samples_2022.keys()):\n",
    "    print(key)\n",
    "    if key not in bg_keys + [data_key]:\n",
    "        # if key not in bg_keys + sig_keys + [data_key]:\n",
    "        del samples_2022[key]\n",
    "\n",
    "sample_dirs_2022 = {path_to_dir: samples_2022}\n",
    "print(\"------------\")\n",
    "\n",
    "# ---2022EE\n",
    "samples_2022EE = deepcopy(samples[\"2022EE\"])\n",
    "for key in list(samples_2022EE.keys()):\n",
    "    print(key)\n",
    "    if key not in bg_keys + [data_key]:\n",
    "        # if key not in bg_keys + sig_keys + [data_key]:\n",
    "        del samples_2022EE[key]\n",
    "\n",
    "sample_dirs_2022EE = {path_to_dir: samples_2022EE}\n",
    "print(\"------------\")\n",
    "\n",
    "# ---2023\n",
    "samples_2023_ = deepcopy(samples[\"2023\"])\n",
    "for key in list(samples_2023_.keys()):\n",
    "    print(key)\n",
    "    if key not in bg_keys + [data_key]:\n",
    "        # if key not in bg_keys + sig_keys + [data_key]:\n",
    "        del samples_2023_[key]\n",
    "\n",
    "sample_dirs_2023_ = {path_to_dir: samples_2023_}\n",
    "print(\"------------\")\n",
    "\n",
    "# ---2023BPix\n",
    "samples_2023BPix = deepcopy(samples[\"2023BPix\"])\n",
    "for key in list(samples_2023BPix.keys()):\n",
    "    print(key)\n",
    "    if key not in bg_keys + [data_key]:\n",
    "        # if key not in bg_keys + sig_keys + [data_key]:\n",
    "        del samples_2023BPix[key]\n",
    "\n",
    "sample_dirs_2023BPix = {path_to_dir: samples_2023BPix}\n",
    "print(\"------------\")\n",
    "type(sample_dirs_2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(sample_dirs_2022))\n",
    "print(sample_dirs_2022)\n",
    "\n",
    "print(len(sample_dirs_2023_))\n",
    "print(sample_dirs_2023_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ak4JetEta', 0),\n",
       " ('ak4JetEta', 1),\n",
       " ('ak4JetEta', 2),\n",
       " ('ak4JetEta', 3),\n",
       " ('ak4JetPhi', 0),\n",
       " ('ak4JetPhi', 1),\n",
       " ('ak4JetPhi', 2),\n",
       " ('ak4JetPhi', 3),\n",
       " ('ak4JetMass', 0),\n",
       " ('ak4JetMass', 1),\n",
       " ('ak4JetMass', 2),\n",
       " ('ak4JetMass', 3),\n",
       " ('ak4JetPt', 0),\n",
       " ('ak4JetPt', 1),\n",
       " ('ak4JetPt', 2),\n",
       " ('ak4JetPt', 3),\n",
       " ('ak4JetrawFactor', 0),\n",
       " ('ak4JetrawFactor', 1),\n",
       " ('ak4JetrawFactor', 2),\n",
       " ('ak4JetrawFactor', 3),\n",
       " ('ak8FatJetEta', 0),\n",
       " ('ak8FatJetEta', 1),\n",
       " ('ak8FatJetEta', 2),\n",
       " ('ak8FatJetPhi', 0),\n",
       " ('ak8FatJetPhi', 1),\n",
       " ('ak8FatJetPhi', 2),\n",
       " ('ak8FatJetMass', 0),\n",
       " ('ak8FatJetMass', 1),\n",
       " ('ak8FatJetMass', 2),\n",
       " ('ak8FatJetPt', 0),\n",
       " ('ak8FatJetPt', 1),\n",
       " ('ak8FatJetPt', 2),\n",
       " ('ak8FatJetMsd', 0),\n",
       " ('ak8FatJetMsd', 1),\n",
       " ('ak8FatJetMsd', 2),\n",
       " ('ak8FatJetPNetXbb', 0),\n",
       " ('ak8FatJetPNetXbb', 1),\n",
       " ('ak8FatJetPNetXbb', 2),\n",
       " ('ak8FatJetPNetXjj', 0),\n",
       " ('ak8FatJetPNetXjj', 1),\n",
       " ('ak8FatJetPNetXjj', 2),\n",
       " ('ak8FatJetPNetQCD', 0),\n",
       " ('ak8FatJetPNetQCD', 1),\n",
       " ('ak8FatJetPNetQCD', 2),\n",
       " ('ak8FatJetPNetQCD1HF', 0),\n",
       " ('ak8FatJetPNetQCD1HF', 1),\n",
       " ('ak8FatJetPNetQCD1HF', 2),\n",
       " ('ak8FatJetPNetQCD2HF', 0),\n",
       " ('ak8FatJetPNetQCD2HF', 1),\n",
       " ('ak8FatJetPNetQCD2HF', 2),\n",
       " ('ak8FatJetPNetQCD0HF', 0),\n",
       " ('ak8FatJetPNetQCD0HF', 1),\n",
       " ('ak8FatJetPNetQCD0HF', 2),\n",
       " ('ak8FatJetPNetMass', 0),\n",
       " ('ak8FatJetPNetMass', 1),\n",
       " ('ak8FatJetPNetMass', 2),\n",
       " ('ak8FatJetPNetMassRaw', 0),\n",
       " ('ak8FatJetPNetMassRaw', 1),\n",
       " ('ak8FatJetPNetMassRaw', 2),\n",
       " ('ak8FatJetTau3OverTau2', 0),\n",
       " ('ak8FatJetTau3OverTau2', 1),\n",
       " ('ak8FatJetTau3OverTau2', 2),\n",
       " ('ak8FatJetrawFactor', 0),\n",
       " ('ak8FatJetrawFactor', 1),\n",
       " ('ak8FatJetrawFactor', 2),\n",
       " ('ak8FatJetPNetMassLegacy', 0),\n",
       " ('ak8FatJetPNetMassLegacy', 1),\n",
       " ('ak8FatJetPNetMassLegacy', 2),\n",
       " ('ak8FatJetMatchedGenJetPt', 0),\n",
       " ('ak8FatJetMatchedGenJetPt', 1),\n",
       " ('ak8FatJetMatchedGenJetPt', 2),\n",
       " ('ak8FatJetparticleNetWithMass_TvsQCD', 0),\n",
       " ('ak8FatJetparticleNetWithMass_TvsQCD', 1),\n",
       " ('ak8FatJetparticleNetWithMass_TvsQCD', 2),\n",
       " ('bbFatJetEta', 0),\n",
       " ('bbFatJetEta', 1),\n",
       " ('bbFatJetPhi', 0),\n",
       " ('bbFatJetPhi', 1),\n",
       " ('bbFatJetMass', 0),\n",
       " ('bbFatJetMass', 1),\n",
       " ('bbFatJetPt', 0),\n",
       " ('bbFatJetPt', 1),\n",
       " ('bbFatJetMsd', 0),\n",
       " ('bbFatJetMsd', 1),\n",
       " ('bbFatJetPNetXbb', 0),\n",
       " ('bbFatJetPNetXbb', 1),\n",
       " ('bbFatJetPNetXjj', 0),\n",
       " ('bbFatJetPNetXjj', 1),\n",
       " ('bbFatJetPNetQCD', 0),\n",
       " ('bbFatJetPNetQCD', 1),\n",
       " ('bbFatJetPNetQCD1HF', 0),\n",
       " ('bbFatJetPNetQCD1HF', 1),\n",
       " ('bbFatJetPNetQCD2HF', 0),\n",
       " ('bbFatJetPNetQCD2HF', 1),\n",
       " ('bbFatJetPNetQCD0HF', 0),\n",
       " ('bbFatJetPNetQCD0HF', 1),\n",
       " ('bbFatJetPNetMass', 0),\n",
       " ('bbFatJetPNetMass', 1),\n",
       " ('bbFatJetPNetMassRaw', 0),\n",
       " ('bbFatJetPNetMassRaw', 1),\n",
       " ('bbFatJetTau3OverTau2', 0),\n",
       " ('bbFatJetTau3OverTau2', 1),\n",
       " ('bbFatJetrawFactor', 0),\n",
       " ('bbFatJetrawFactor', 1),\n",
       " ('bbFatJetPNetMassLegacy', 0),\n",
       " ('bbFatJetPNetMassLegacy', 1),\n",
       " ('bbFatJetMatchedGenJetPt', 0),\n",
       " ('bbFatJetMatchedGenJetPt', 1),\n",
       " ('bbFatJetparticleNetWithMass_TvsQCD', 0),\n",
       " ('bbFatJetparticleNetWithMass_TvsQCD', 1),\n",
       " ('run', 0),\n",
       " ('event', 0),\n",
       " ('luminosityBlock', 0),\n",
       " ('MET_pt', 0),\n",
       " ('ht', 0),\n",
       " ('nJets', 0),\n",
       " ('nFatJets', 0),\n",
       " ('vbfVeto', 0),\n",
       " ('nPU', 0),\n",
       " ('nPV', 0),\n",
       " ('Ele32_WPTight_Gsf', 0),\n",
       " ('IsoMu27', 0),\n",
       " ('QuadPFJet70_50_40_35_PFBTagParticleNet_2BTagSum0p65', 0),\n",
       " ('PFHT1050', 0),\n",
       " ('AK8PFJet230_SoftDropMass40_PFAK8ParticleNetBB0p35', 0),\n",
       " ('AK8PFJet250_SoftDropMass40_PFAK8ParticleNetBB0p35', 0),\n",
       " ('AK8PFJet275_SoftDropMass40_PFAK8ParticleNetBB0p35', 0),\n",
       " ('AK8PFJet230_SoftDropMass40', 0),\n",
       " ('AK8PFJet425_SoftDropMass40', 0),\n",
       " ('AK8DiPFJet250_250_MassSD50', 0),\n",
       " ('AK8DiPFJet260_260_MassSD30', 0),\n",
       " ('AK8PFJet230_SoftDropMass40_PNetBB0p06', 0),\n",
       " ('AK8PFJet230_SoftDropMass40_PNetBB0p10', 0),\n",
       " ('AK8PFJet250_SoftDropMass40_PNetBB0p06', 0),\n",
       " ('TriggerObjectPt', 0),\n",
       " ('TriggerObjectPt', 1),\n",
       " ('TriggerObjectPt', 2),\n",
       " ('TriggerObjectPt', 3),\n",
       " ('TriggerObjectEta', 0),\n",
       " ('TriggerObjectEta', 1),\n",
       " ('TriggerObjectEta', 2),\n",
       " ('TriggerObjectEta', 3),\n",
       " ('TriggerObjectPhi', 0),\n",
       " ('TriggerObjectPhi', 1),\n",
       " ('TriggerObjectPhi', 2),\n",
       " ('TriggerObjectPhi', 3),\n",
       " ('TriggerObjectBit', 0),\n",
       " ('TriggerObjectBit', 1),\n",
       " ('TriggerObjectBit', 2),\n",
       " ('TriggerObjectBit', 3),\n",
       " ('TriggerObjectMatched_bbFatJet0', 0),\n",
       " ('TriggerObjectMatched_bbFatJet0', 1),\n",
       " ('TriggerObjectMatched_bbFatJet0', 2),\n",
       " ('TriggerObjectMatched_bbFatJet0', 3),\n",
       " ('TriggerObjectMatched_bbFatJet1', 0),\n",
       " ('TriggerObjectMatched_bbFatJet1', 1),\n",
       " ('TriggerObjectMatched_bbFatJet1', 2),\n",
       " ('TriggerObjectMatched_bbFatJet1', 3),\n",
       " ('lepEta', 0),\n",
       " ('lepEta', 1),\n",
       " ('lepPhi', 0),\n",
       " ('lepPhi', 1),\n",
       " ('lepMass', 0),\n",
       " ('lepMass', 1),\n",
       " ('lepPt', 0),\n",
       " ('lepPt', 1),\n",
       " ('lepId', 0),\n",
       " ('lepId', 1),\n",
       " ('weight', 0),\n",
       " ('weight_trigsf_2jetUp', 0),\n",
       " ('weight_pileupDown', 0),\n",
       " ('weight_pileupUp', 0),\n",
       " ('weight_trigsf_2jetDown', 0),\n",
       " ('single_weight_genweight', 0),\n",
       " ('single_weight_pileup', 0),\n",
       " ('single_weight_trigsf_2jet', 0),\n",
       " ('weight_noxsec', 0)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pd.read_parquet(f\"{path_to_dir}/2022EE/QCD_HT-2000/parquet\").columns\n",
    "# pd.read_parquet(f\"{path_to_dir}/2022EE/GluGlutoHHto4B_kl-1p00_kt-1p00_c2-0p00_TuneCP5_13p6TeV_TSG/parquet\").columns\n",
    "list(pd.read_parquet(f\"{path_to_dir}/2022EE/WW/parquet\").columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns to load\n",
    "# the parquet files are too big so we can only load a few columns at a time without consumming much memory\n",
    "load_columns = [\n",
    "    (\"weight\", 1),\n",
    "    (\"MET_pt\", 1),\n",
    "    (\"nFatJets\", 1),\n",
    "    (\"ak8FatJetPt\", 2),\n",
    "    (\"ak8FatJetEta\", 2),\n",
    "    (\"ak8FatJetPhi\", 2),\n",
    "    (\"ak8FatJetPNetXbb\", 2),\n",
    "    (\"ak8FatJetMsd\", 2),\n",
    "    (\"ak8FatJetPNetMass\", 2),\n",
    "    (\"ak8FatJetTau3OverTau2\", 2),\n",
    "    (\"bbFatJetMass\", 2),\n",
    "    (\"bbFatJetPt\", 2),\n",
    "    (\"bbFatJetEta\", 2),\n",
    "    (\"bbFatJetPhi\", 2),\n",
    "    (\"ht\", 1),\n",
    "    (\"nPV\", 1),\n",
    "]\n",
    "\n",
    "if \"v12\" in path_to_dir:\n",
    "    load_columns += [(\"ak8FatJetPNetMassRaw\", 2)]\n",
    "\n",
    "load_columns_mc = load_columns + [\n",
    "    (\"single_weight_pileup\", 1),\n",
    "    (\"single_weight_genWeight\"),\n",
    "    (\"single_weight_trigsf_2jet\"),\n",
    "]\n",
    "# + [(f\"weight_{syst}_{shift}\", 1) for syst in weight_shifts for shift in [\"up\", \"down\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_cut = 300\n",
    "pt_veto = 200\n",
    "msd_cut = 50\n",
    "eta_cut = 2.5\n",
    "\n",
    "filters = [\n",
    "    [\n",
    "        (\"('ak8FatJetPt', '0')\", \">=\", pt_cut),\n",
    "        (\"('ak8FatJetPt', '1')\", \"<\", pt_veto),\n",
    "        (\"('ak8FatJetMsd', '0')\", \">=\", msd_cut),\n",
    "        (\"('ak8FatJetMsd', '1')\", \"<\", msd_cut),\n",
    "        # (\"('ak8FatJetEta', '0')\", \"<=\", eta_cut),\n",
    "        # (\"('ak8FatJetEta', '0')\", \">=\", -1*eta_cut),\n",
    "        # (\"('ak8FatJetPNetXbb', '0')\", \">=\", 0.8),\n",
    "    ],\n",
    "    #    [\n",
    "    #        (\"('ak8FatJetPt', '0')\", \">=\", pt_cut),\n",
    "    #        (\"('ak8FatJetPt', '1')\", \"<\", pt_veto),\n",
    "    #        (\"('ak8FatJetEta', '0')\", \"<=\", eta_cut),\n",
    "    #        (\"('ak8FatJetEta', '1')\", \"<=\", eta_cut),\n",
    "    #        (\"('ak8FatJetEta', '0')\", \">=\", -1*eta_cut),\n",
    "    #        (\"('ak8FatJetEta', '1')\", \">=\", -1*eta_cut),\n",
    "    #        (\"('ak8FatJetMsd', '0')\", \">=\", msd_cut),\n",
    "    #        (\"('ak8FatJetMsd', '1')\", \"<\", msd_cut),\n",
    "    #        (\"('ak8FatJetPNetXbb', '1')\", \">=\", 0.8),\n",
    "    #    ],\n",
    "]\n",
    "\n",
    "# save cutflow as pandas table\n",
    "# cutflow = pd.DataFrame(index=list(samples.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary that will contain all information (from 2022 samples)\n",
    "events_dict_2022_ = {}\n",
    "for input_dir, samples in sample_dirs_2022.items():\n",
    "    events_dict_2022_ = {\n",
    "        **events_dict_2022_,\n",
    "        # this function will load files (only the columns selected), apply filters and compute a weight per event\n",
    "        **utils.load_samples(\n",
    "            input_dir,\n",
    "            samples,\n",
    "            \"2022\",\n",
    "            filters=filters,\n",
    "            columns=utils.format_columns(load_columns),\n",
    "            variations=False,\n",
    "            # columns_mc=utils.format_columns(load_columns_mc),\n",
    "        ),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(events_dict_2022.keys())\n",
    "print(events_dict_2022[\"data\"].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events_dict_2022EE = {}\n",
    "for input_dir, samples in sample_dirs_2022EE.items():\n",
    "    events_dict_2022EE = {\n",
    "        **events_dict_2022EE,\n",
    "        # this function will load files (only the columns selected), apply filters and compute a weight per event\n",
    "        **utils.load_samples(\n",
    "            input_dir,\n",
    "            samples,\n",
    "            \"2022EE\",\n",
    "            filters=filters,\n",
    "            columns=utils.format_columns(load_columns),\n",
    "            variations=False,\n",
    "            # columns_mc=utils.format_columns(load_columns_mc),\n",
    "        ),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a combined 2022 dictionary\n",
    "events_dict_combo = [events_dict_2022_, events_dict_2022EE]\n",
    "all_keys_2022 = set().union(*[d.keys() for d in events_dict_combo])\n",
    "events_dict_2022 = {\n",
    "    key: pd.concat([d[key] for d in events_dict_combo if key in d]) for key in all_keys_2022\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events_dict_2023_ = {}\n",
    "for input_dir, samples in sample_dirs_2023_.items():\n",
    "    events_dict_2023_ = {\n",
    "        **events_dict_2023_,\n",
    "        # this function will load files (only the columns selected), apply filters and compute a weight per event\n",
    "        **utils.load_samples(\n",
    "            input_dir,\n",
    "            samples,\n",
    "            \"2023\",\n",
    "            filters=filters,\n",
    "            columns=utils.format_columns(load_columns),\n",
    "            variations=False,\n",
    "            # columns_mc=utils.format_columns(load_columns_mc),\n",
    "        ),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events_dict_2023BPix = {}\n",
    "for input_dir, samples in sample_dirs_2023BPix.items():\n",
    "    events_dict_2023BPix = {\n",
    "        **events_dict_2023BPix,\n",
    "        # this function will load files (only the columns selected), apply filters and compute a weight per event\n",
    "        **utils.load_samples(\n",
    "            input_dir,\n",
    "            samples,\n",
    "            \"2023BPix\",\n",
    "            filters=filters,\n",
    "            columns=utils.format_columns(load_columns),\n",
    "            variations=False,\n",
    "            # columns_mc=utils.format_columns(load_columns_mc),\n",
    "        ),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a combined 2023 dictionary\n",
    "events_dict_combo = [events_dict_2023_, events_dict_2023BPix]\n",
    "all_keys_2023 = set().union(*[d.keys() for d in events_dict_combo])\n",
    "events_dict_2023 = {\n",
    "    key: pd.concat([d[key] for d in events_dict_combo if key in d]) for key in all_keys_2023\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel_bg_keys = list(events_dict_2022EE.keys())\n",
    "print(sel_bg_keys)\n",
    "sel_bg_keys.remove(\"data\")\n",
    "# print(events_dict)\n",
    "# utils.add_to_cutflow(events_dict, \"Preselection\", \"weight\", cutflow)\n",
    "# print(\"\\n\", cutflow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(events_dict.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make some pre-corrected plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ylims = {\n",
    "    \"2022\": 5e4,\n",
    "    \"2022EE\": 5e4,\n",
    "}\n",
    "tau32Bins = [\n",
    "    0.0,\n",
    "    0.1,\n",
    "    0.1333,\n",
    "    0.1667,\n",
    "    0.2,\n",
    "    0.2333,\n",
    "    0.2667,\n",
    "    0.3,\n",
    "    0.3333,\n",
    "    0.3667,\n",
    "    0.4,\n",
    "    0.4333,\n",
    "    0.4667,\n",
    "    0.5,\n",
    "    0.5333,\n",
    "    0.5667,\n",
    "    0.6,\n",
    "    0.6333,\n",
    "    0.6667,\n",
    "    0.7,\n",
    "    0.7333,\n",
    "    0.7667,\n",
    "    0.8,\n",
    "    0.8333,\n",
    "    0.8667,\n",
    "    0.9,\n",
    "    0.9333,\n",
    "    0.9667,\n",
    "    1.0,\n",
    "]\n",
    "# {var: (bins, label)}\n",
    "control_plot_vars = [\n",
    "    # var must match key in events dictionary (i.e. as saved in parquet file)\n",
    "    # ShapeVar(var=\"DijetMass\", label=r\"$m^{jj}$ (GeV)\", bins=[30, 600, 4000]),\n",
    "    #    ShapeVar(var=\"ak8FatJetPt0\", label=r\"$p_T^{j1}$ (GeV)\", bins=[66, 0, 1000]),\n",
    "    #    ShapeVar(var=\"ak8FatJetPt1\", label=r\"$p_T^{j2}$ (GeV)\", bins=[66, 0, 1000]),\n",
    "    #    ShapeVar(var=\"ak8FatJetMsd0\", label=r\"$M_{SD}^{j1}$ (GeV)\", bins=[40, 0, 500]),\n",
    "    #    ShapeVar(var=\"ak8FatJetEta0\", label=r\"$\\eta^{j1}$\", bins=[20, -5, 5]),\n",
    "    #    ShapeVar(var=\"ak8FatJetMsd1\", label=r\"$M_{SD}^{j1}$ (GeV)\", bins=[40, 0, 500]),\n",
    "    #    ShapeVar(var=\"ak8FatJetEta1\", label=r\"$\\eta^{j1}$\", bins=[20, -5, 5]),\n",
    "    #    ShapeVar(var=\"ak8FatJetPNetXbb0\", label=r\"$X_{bb}^{j1}$ \", bins=[25, 0, 1.0]),\n",
    "    # ShapeVar(var=\"ak8FatJetTau3OverTau20\", label=r\"$[\\tau_3/\\tau_2]^{j1}_$ \", bins=[20, 0.1, 0.5]),\n",
    "    # ShapeVar(var=\"ak8FatJetTau3OverTau20\", label=r\"$[\\tau_3/\\tau_2]^{j1}$ \", bins=[30, 0., 1.]),\n",
    "    # ShapeVar(var=\"ak8FatJetTau3OverTau20\", label=r\"$[\\tau_3/\\tau_2]^{j1}$ \", bins=[20, 0., 1.]),\n",
    "    ShapeVar(\n",
    "        var=\"ak8FatJetTau3OverTau20\", label=r\"$[\\tau_3/\\tau_2]^{j1}$ \", bins=tau32Bins, reg=False\n",
    "    ),\n",
    "]\n",
    "\n",
    "hists = {}\n",
    "for shape_var in control_plot_vars:\n",
    "    if shape_var.var not in hists:\n",
    "        hists[shape_var.var] = utils.singleVarHist(\n",
    "            events_dict,\n",
    "            shape_var,\n",
    "            weight_key=\"weight\",\n",
    "        )\n",
    "\n",
    "for shape_var in control_plot_vars:\n",
    "    name = f\"{plot_dir}/{shape_var.var}.png\"\n",
    "    label = name.replace(\".png\", \"_pre.png\")\n",
    "    plotting.ratioHistPlot(\n",
    "        hists[shape_var.var],\n",
    "        year,\n",
    "        sig_keys,\n",
    "        sel_bg_keys,\n",
    "        name=label,\n",
    "        show=True,\n",
    "        log=True,\n",
    "        plot_significance=False,\n",
    "        significance_dir=shape_var.significance_dir,\n",
    "        ratio_ylims=[0.0, 2.0],\n",
    "        ylim=ylims[year],\n",
    "        ylim_low=1e-3,\n",
    "    )\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_Datattbar = {\"data\", \"ttbar\"}\n",
    "samples_Nottbar = {\"diboson\", \"qcd\", \"vjets\", \"vjetslnu\"}\n",
    "samples_Data = {\"data\"}\n",
    "samples_ttbar = {\"ttbar\"}\n",
    "varBins = tau32Bins\n",
    "# varBins=[0.1,0.16,0.18,0.2,0.22,0.24,0.26,0.28,0.3,0.32,0.34,0.36,0.38,0.4,0.42,0.44,0.46]\n",
    "# theShapeVar = ShapeVar(var=\"ak8FatJetTau3OverTau20\", label=r\"$[\\tau_3/\\tau_2]^{j1}_$ \", bins=[20, 0.1, 0.5])\n",
    "theShapeVar = ShapeVar(\n",
    "    bins=varBins,\n",
    "    var=\"ak8FatJetTau3OverTau20\",\n",
    "    label=r\"$[\\tau_3/\\tau_2]^{j1}$\",\n",
    "    # bins=[20, 0.1, 0.5])\n",
    "    reg=False,\n",
    ")\n",
    "vars = [theShapeVar.var]\n",
    "# for sample in samples:\n",
    "histos = {}\n",
    "histos[\"ttbar\"] = utils.singleVarHistSel(\n",
    "    events_dict,\n",
    "    theShapeVar,\n",
    "    samples_ttbar,\n",
    "    weight_key=\"weight\",\n",
    ")\n",
    "histos[\"Nottbar\"] = utils.singleVarHistSel(\n",
    "    events_dict,\n",
    "    theShapeVar,\n",
    "    samples_Nottbar,\n",
    "    weight_key=\"weight\",\n",
    ")\n",
    "histos[\"data\"] = utils.singleVarHistSel(\n",
    "    events_dict,\n",
    "    theShapeVar,\n",
    "    samples_Data,\n",
    "    weight_key=\"weight\",\n",
    ")\n",
    "binContent_ttbar = np.array(histos[\"ttbar\"].values())\n",
    "binContent_Data = np.array(histos[\"data\"].values())\n",
    "binContent_Nottbar = np.sum(np.array(histos[\"Nottbar\"].values()), axis=0)\n",
    "print(\"TTBar only: \", binContent_ttbar)\n",
    "print(\"Data only: \", binContent_Data)\n",
    "print(\"MC No TTbar: \", binContent_Nottbar)\n",
    "print(\"*************\")\n",
    "tau32BinnedSFs = (binContent_Data - binContent_Nottbar) / binContent_ttbar\n",
    "print(\"(Data - NonTTbarMC)/TTbar: \", (tau32BinnedSFs))\n",
    "sigma_f = np.sqrt(\n",
    "    ((1 / binContent_ttbar) * np.sqrt(binContent_Data)) ** 2\n",
    "    + ((-1 / binContent_ttbar) * np.sqrt(binContent_Nottbar)) ** 2\n",
    "    + (((binContent_Data - binContent_Nottbar) / binContent_ttbar**2) * np.sqrt(binContent_ttbar))\n",
    "    ** 2\n",
    ")\n",
    "print(\"sigma \", sigma_f)\n",
    "##plotting.ratioHistPlot(\n",
    "##    histos[theShapeVar.var],\n",
    "##    year,\n",
    "##    sig_keys,\n",
    "##    samples_ttbar,\n",
    "##    name=theShapeVar.label,\n",
    "##    show=True,\n",
    "##    log=True,\n",
    "##    ratio_ylims=[0.0, 2.0],\n",
    "##    ylim=ylims[year],\n",
    "##    ylim_low=1e-1,\n",
    "###    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make some Post Corrected plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events = events_dict[\"ttbar\"]\n",
    "# print(events)\n",
    "# tau32 = events[\"ak8FatJetTau3OverTau20\"].to_numpy()\n",
    "tau32 = {\"ak8FatJetTau3OverTau20\": utils.get_feat(events, \"ak8FatJetTau3OverTau20\")}[\n",
    "    \"ak8FatJetTau3OverTau20\"\n",
    "]\n",
    "print(tau32)\n",
    "ftau32 = tau32[tau32 < 0.5]\n",
    "tau32FittedSF_4 = (\n",
    "    18.4912 - 235.086 * ftau32 + 1098.94 * ftau32**2 - 2163 * ftau32**3 + 1530.59 * ftau32**4\n",
    ")\n",
    "# print(events[\"weight\"].to_numpy().squeeze())\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(ftau32, tau32FittedSF_4, alpha=0.5)\n",
    "plt.title(\"4th Order Polynomial Fit for tau32FittedSF\")\n",
    "plt.xlabel(\"tau32\")\n",
    "plt.ylabel(\"tau32FittedSF_4\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot with the Binned SF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "control_plot_vars = [\n",
    "    # var must match key in events dictionary (i.e. as saved in parquet file)\n",
    "    # ShapeVar(var=\"DijetMass\", label=r\"$m^{jj}$ (GeV)\", bins=[30, 600, 4000]),\n",
    "    # ShapeVar(var=\"ak8FatJetPt0\", label=r\"$p_T^{j1}$ (GeV)\", bins=[66, 0, 1000]),\n",
    "    # ShapeVar(var=\"ak8FatJetPt1\", label=r\"$p_T^{j2}$ (GeV)\", bins=[66, 0, 1000]),\n",
    "    # ShapeVar(var=\"ak8FatJetMsd0\", label=r\"$M_{SD}^{j1}$ (GeV)\", bins=[40, 0, 500]),\n",
    "    # ShapeVar(var=\"ak8FatJetEta0\", label=r\"$\\eta^{j1}$\", bins=[20, -5, 5]),\n",
    "    # ShapeVar(var=\"ak8FatJetPNetXbb0\", label=r\"$X_{bb}^{j1}$ \", bins=[25, 0, 1.0]),\n",
    "    # ShapeVar(var=\"ak8FatJetTau3OverTau20\", label=r\"$[\\tau_3/\\tau_2]^{j1}_$ \", bins=[20, 0.1, 0.5]),\n",
    "    # ShapeVar(var=\"ak8FatJetTau3OverTau20\", label=r\"$[\\tau_3/\\tau_2]^{j1}$ \", bins=[30, 0., 1.]),\n",
    "    # ShapeVar(var=\"ak8FatJetTau3OverTau20\", label=r\"$[\\tau_3/\\tau_2]^{j1}$ \", bins=[20, 0., 1.]),\n",
    "    ShapeVar(\n",
    "        var=\"ak8FatJetTau3OverTau20\", label=r\"$[\\tau_3/\\tau_2]^{j1}$ \", bins=tau32Bins, reg=False\n",
    "    ),\n",
    "]\n",
    "\n",
    "hists = {}\n",
    "for shape_var in control_plot_vars:\n",
    "    if shape_var.var not in hists:\n",
    "        hists[shape_var.var] = utils.singleVarHist(\n",
    "            events_dict,\n",
    "            shape_var,\n",
    "            weight_key=\"weight\",\n",
    "        )\n",
    "\n",
    "hists[\"ak8FatJetTau3OverTau20\"].view()[\n",
    "    utils.get_key_index(hists[\"ak8FatJetTau3OverTau20\"], \"ttbar\"), ...\n",
    "] *= tau32BinnedSFs.squeeze()\n",
    "\n",
    "for shape_var in control_plot_vars:\n",
    "    name = f\"{plot_dir}/{shape_var.var}.png\"\n",
    "    label = name.replace(\".png\", \"_postTau32binnedSF.png\")\n",
    "    plotting.ratioHistPlot(\n",
    "        hists[shape_var.var],\n",
    "        year,\n",
    "        sig_keys,\n",
    "        sel_bg_keys,\n",
    "        name=label,\n",
    "        show=True,\n",
    "        log=True,\n",
    "        plot_significance=False,\n",
    "        significance_dir=shape_var.significance_dir,\n",
    "        ratio_ylims=[0.0, 2.0],\n",
    "        ylim=ylims[year],\n",
    "        ylim_low=1e-3,\n",
    "    )\n",
    "    # break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitted SFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "control_plot_vars = [\n",
    "    # var must match key in events dictionary (i.e. as saved in parquet file)\n",
    "    # ShapeVar(var=\"DijetMass\", label=r\"$m^{jj}$ (GeV)\", bins=[30, 600, 4000]),\n",
    "    ShapeVar(var=\"ak8FatJetPt0\", label=r\"$p_T^{j1}$ (GeV)\", bins=[66, 0, 1000]),\n",
    "    ShapeVar(var=\"ak8FatJetPt1\", label=r\"$p_T^{j2}$ (GeV)\", bins=[66, 0, 1000]),\n",
    "    ShapeVar(var=\"ak8FatJetMsd0\", label=r\"$M_{SD}^{j1}$ (GeV)\", bins=[40, 0, 500]),\n",
    "    ShapeVar(var=\"ak8FatJetEta0\", label=r\"$\\eta^{j1}$\", bins=[20, -5, 5]),\n",
    "    ShapeVar(var=\"ak8FatJetPNetXbb0\", label=r\"$X_{bb}^{j1}$ \", bins=[25, 0, 1.0]),\n",
    "    # ShapeVar(var=\"ak8FatJetTau3OverTau20\", label=r\"$[\\tau_3/\\tau_2]^{j1}_$ \", bins=[20, 0.1, 0.5]),\n",
    "    # ShapeVar(var=\"ak8FatJetTau3OverTau20\", label=r\"$[\\tau_3/\\tau_2]^{j1}$ \", bins=[30, 0., 1.]),\n",
    "    # ShapeVar(var=\"ak8FatJetTau3OverTau20\", label=r\"$[\\tau_3/\\tau_2]^{j1}$ \", bins=[20, 0., 1.]),\n",
    "    ShapeVar(\n",
    "        var=\"ak8FatJetTau3OverTau20\", label=r\"$[\\tau_3/\\tau_2]^{j1}$ \", bins=tau32Bins, reg=False\n",
    "    ),\n",
    "]\n",
    "\n",
    "hists = {}\n",
    "for shape_var in control_plot_vars:\n",
    "    if shape_var.var not in hists:\n",
    "        hists[shape_var.var] = utils.singleVarHist(\n",
    "            events_dict, shape_var, weight_key=\"weight\", sf=[\"tau32SF\"]\n",
    "        )\n",
    "\n",
    "# hists[\"ak8FatJetTau3OverTau20\"].view()[utils.get_key_index(hists[\"ak8FatJetTau3OverTau20\"], \"ttbar\"), ...] *= tau32BinnedSFs.squeeze()\n",
    "\n",
    "for shape_var in control_plot_vars:\n",
    "    name = f\"{plot_dir}/{shape_var.var}.png\"\n",
    "    label = name.replace(\".png\", \"_postTau32FittedSF.png\")\n",
    "    plotting.ratioHistPlot(\n",
    "        hists[shape_var.var],\n",
    "        year,\n",
    "        sig_keys,\n",
    "        sel_bg_keys,\n",
    "        name=label,\n",
    "        show=True,\n",
    "        log=True,\n",
    "        plot_significance=False,\n",
    "        significance_dir=shape_var.significance_dir,\n",
    "        ratio_ylims=[0.0, 2.0],\n",
    "        ylim=ylims[year],\n",
    "        ylim_low=1e-3,\n",
    "    )\n",
    "    # break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c56774",
   "metadata": {},
   "outputs": [],
   "source": [
    "# automatically reloads imported files on edits\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc9de15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from HH4b import utils\n",
    "from HH4b import postprocessing\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edbe9ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_path: Path = Path(\"Zbb_events_combined.pkl\")\n",
    "REPROCESS: bool = False  # if True, reprocess from the skimmed ntuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba476244",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if True, apply the Z->2Q corrections from ZMuMu measurement\n",
    "\n",
    "APPLY_Zto2Q_CORR: bool = False\n",
    "if APPLY_Zto2Q_CORR:\n",
    "    import correctionlib\n",
    "\n",
    "    corr_dir = Path(\"ZMuMu_corrs/pT\")\n",
    "    corr_dict = {}\n",
    "\n",
    "    for year in [\"2022\", \"2023\"]:\n",
    "        corr_file = corr_dir / f\"corr_{year}.json\"\n",
    "        if not corr_file.exists():\n",
    "            raise FileNotFoundError(f\"Correction file {corr_file} does not exist.\")\n",
    "\n",
    "        # Load the correction\n",
    "        corr = correctionlib.CorrectionSet.from_file(str(corr_file))\n",
    "        corr_dict[year] = corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93acecb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if REPROCESS or not processed_path.exists():\n",
    "    path_dir = \"/ceph/cms/store/user/zichun/bbbb/skimmer/ZbbHT25May28_v12v2_private_zbb/\"\n",
    "\n",
    "    # names of all samples,\n",
    "    samples_run3 = {\n",
    "        \"data\": [f\"{key}_Run\" for key in [\"JetMET\"]],\n",
    "        \"ttbar\": [\"TTto4Q\", \"TTtoLNu2Q\"],\n",
    "        \"qcd\": [\"QCD_HT\"],\n",
    "        \"hbb\": [\"GluGluHto2B_M-125\"],\n",
    "        \"Zto2Q\": [\"Zto2Q-4Jets\"],\n",
    "        \"Wto2Q\": [\"Wto2Q-3Jets\"],\n",
    "    }\n",
    "\n",
    "    sys_vars = [\"FSRPartonShower\", \"ISRPartonShower\", \"pileup\"]\n",
    "\n",
    "    base_columns = [\n",
    "        (\"bbFatJetPt\", 2),\n",
    "        (\"bbFatJetEta\", 2),\n",
    "        (\"bbFatJetMsd\", 2),\n",
    "        (\"bbFatJetParTmassVis\", 2),\n",
    "        (\"bbFatJetPNetMassLegacy\", 2),\n",
    "        (\"bbFatJetParTTXbb\", 2),\n",
    "        (\"weight\", 1),\n",
    "    ]\n",
    "\n",
    "    triggers = {\n",
    "        \"2022\": [\n",
    "            \"AK8PFJet500\",\n",
    "            \"AK8PFJet420_MassSD30\",\n",
    "            \"AK8PFJet425_SoftDropMass40\",\n",
    "            \"AK8PFJet250_SoftDropMass40_PFAK8ParticleNetBB0p35\",\n",
    "        ],\n",
    "        \"2022EE\": [\n",
    "            \"AK8PFJet500\",\n",
    "            \"AK8PFJet420_MassSD30\",\n",
    "            \"AK8PFJet425_SoftDropMass40\",\n",
    "            \"AK8PFJet250_SoftDropMass40_PFAK8ParticleNetBB0p35\",\n",
    "        ],\n",
    "        \"2023\": [\n",
    "            \"AK8PFJet500\",\n",
    "            \"AK8PFJet420_MassSD30\",\n",
    "            \"AK8PFJet425_SoftDropMass40\",\n",
    "            \"AK8PFJet250_SoftDropMass40_PFAK8ParticleNetBB0p35\",\n",
    "            \"AK8PFJet230_SoftDropMass40_PNetBB0p06\",\n",
    "        ],\n",
    "        \"2023BPix\": [\n",
    "            \"AK8PFJet500\",\n",
    "            \"AK8PFJet420_MassSD30\",\n",
    "            \"AK8PFJet425_SoftDropMass40\",\n",
    "            \"AK8PFJet230_SoftDropMass40_PNetBB0p06\",\n",
    "        ],\n",
    "    }\n",
    "\n",
    "    load_columns_pt_var = []\n",
    "    for jesr, ud in itertools.product([\"JES\", \"JER\"], [\"up\", \"down\"]):\n",
    "        load_columns_pt_var.append((f\"bbFatJetPt_{jesr}_{ud}\", 2))\n",
    "\n",
    "    load_columns_mass_var = []\n",
    "    for jmsr, ud in itertools.product([\"JMS\", \"JMR\"], [\"up\", \"down\"]):\n",
    "        load_columns_mass_var.append((f\"bbFatJetMsd_{jmsr}_{ud}\", 2))\n",
    "        load_columns_mass_var.append((f\"bbFatJetParTmassVis_{jmsr}_{ud}\", 2))\n",
    "        load_columns_mass_var.append((f\"bbFatJetPNetMassLegacy_{jmsr}_{ud}\", 2))\n",
    "\n",
    "    load_weight_shifts = []\n",
    "    for var, ud in itertools.product(sys_vars, [\"Up\", \"Down\"]):\n",
    "        load_weight_shifts.append((f\"weight_{var}{ud}\", 1))\n",
    "\n",
    "    MC_common_extra_columns = load_columns_mass_var + load_columns_pt_var + load_weight_shifts\n",
    "\n",
    "    ZQQ_extra_columns = [(\"GenZPt\", 1), (\"GenZBB\", 1), (\"GenZCC\", 1), (\"bbFatJetVQQMatch\", 2)]\n",
    "    WQQ_extra_columns = [(\"GenWPt\", 1), (\"GenWCS\", 1), (\"GenWUD\", 1), (\"bbFatJetVQQMatch\", 2)]\n",
    "\n",
    "    extra_columns_dict = {\n",
    "        \"data\": [],\n",
    "        \"qcd\": load_weight_shifts,\n",
    "        \"ttbar\": MC_common_extra_columns,\n",
    "        \"hbb\": MC_common_extra_columns,\n",
    "        \"Zto2Q\": MC_common_extra_columns + ZQQ_extra_columns,\n",
    "        \"Wto2Q\": MC_common_extra_columns + WQQ_extra_columns,\n",
    "    }\n",
    "\n",
    "    events_dict = {}\n",
    "    for year in [\"2022\", \"2022EE\", \"2023\", \"2023BPix\"]:\n",
    "        # for year in [\"2022\"]:\n",
    "        events_dict[year] = {}\n",
    "\n",
    "        # Have to load the samples separately because branches vary\n",
    "        for sample, sample_list in samples_run3.items():\n",
    "            print(f\"Loading {sample} for {year}...\")\n",
    "            triggers_col = [(trigger, 1) for trigger in triggers[year]]\n",
    "\n",
    "            # append the event dictionary for each year\n",
    "            columns = triggers_col + base_columns + extra_columns_dict.get(sample, [])\n",
    "            dataframes = {\n",
    "                **utils.load_samples(\n",
    "                    data_dir=path_dir,\n",
    "                    samples={sample: sample_list},\n",
    "                    year=year,\n",
    "                    columns=utils.format_columns(columns),\n",
    "                    variations=True,\n",
    "                    weight_shifts=[\"FSRPartonShower\", \"ISRPartonShower\", \"pileup\"],\n",
    "                )\n",
    "            }\n",
    "            # concatenate all dataframes in this sample\n",
    "            events_dict[year][sample] = []\n",
    "            for key, df in dataframes.items():\n",
    "                df[\"sample\"] = key\n",
    "                # rename columns to a single level\n",
    "                for col, n in columns:\n",
    "                    if n > 1:\n",
    "                        for i in range(n):\n",
    "                            df[f\"{col}{i}\"] = df[(col, i)]\n",
    "                    else:\n",
    "                        df[col] = df[(col, 0)]\n",
    "\n",
    "                # Fill non-existing HLT columns with 0\n",
    "                if year in (\"2023\", \"2023BPix\"):\n",
    "                    # add AK8PFJet250_SoftDropMass40_PFAK8ParticleNetBB0p35 (filled with 0)\n",
    "                    if \"AK8PFJet250_SoftDropMass40_PFAK8ParticleNetBB0p35\" not in df.columns:\n",
    "                        df[\"AK8PFJet250_SoftDropMass40_PFAK8ParticleNetBB0p35\"] = np.zeros(\n",
    "                            len(df), dtype=int\n",
    "                        )\n",
    "                    # also fill NaN values in AK8PFJet250_SoftDropMass40_PFAK8ParticleNetBB0p35 with 0\n",
    "                    df[\"AK8PFJet250_SoftDropMass40_PFAK8ParticleNetBB0p35\"] = (\n",
    "                        df[\"AK8PFJet250_SoftDropMass40_PFAK8ParticleNetBB0p35\"]\n",
    "                        .fillna(0)\n",
    "                        .astype(int)\n",
    "                    )\n",
    "                elif year in (\"2022\", \"2022EE\"):\n",
    "                    if \"AK8PFJet230_SoftDropMass40_PNetBB0p06\" in df.columns:\n",
    "                        # Add AK8PFJet230_SoftDropMass40_PNetBB0p06 (filled with 0)\n",
    "                        df[\"AK8PFJet230_SoftDropMass40_PNetBB0p06\"] = np.zeros(len(df), dtype=int)\n",
    "                events_dict[year][sample].append(df)\n",
    "            # concatenate all dataframes for this sample\n",
    "            events_dict[year][sample] = pd.concat(events_dict[year][sample], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07954dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if REPROCESS or not processed_path.exists():\n",
    "    events_combined = {\n",
    "        \"2022All\": {},\n",
    "        \"2023All\": {},\n",
    "    }\n",
    "    for key in samples_run3:\n",
    "        events_combined[\"2022All\"][key] = pd.concat(\n",
    "            [events_dict[year][key] for year in [\"2022\", \"2022EE\"] if key in events_dict[year]]\n",
    "        )\n",
    "        events_combined[\"2023All\"][key] = pd.concat(\n",
    "            [events_dict[year][key] for year in [\"2023\", \"2023BPix\"] if key in events_dict[year]]\n",
    "        )\n",
    "\n",
    "    # store events_combined as a pickle file\n",
    "    with processed_path.open(\"wb\") as f:\n",
    "        pd.to_pickle(events_combined, f)\n",
    "    print(f\"Events combined and saved to {processed_path}\")\n",
    "else:\n",
    "    # directly load the processed file\n",
    "    print(f\"Loading events from {processed_path}...\")\n",
    "    with processed_path.open(\"rb\") as f:\n",
    "        events_combined = pd.read_pickle(f)\n",
    "    print(f\"Loaded events from {processed_path}\")\n",
    "\n",
    "if APPLY_Zto2Q_CORR:\n",
    "    print(\"Applying Zto2Q corrections...\")\n",
    "    for year in [\"2022All\", \"2023All\"]:\n",
    "        # apply corrections to the events\n",
    "        corr = corr_dict[year.replace(\"All\", \"\")][\"GenZPtWeight\"]\n",
    "        GenZ_pt = events_combined[year][\"Zto2Q\"][\"GenZPt\"].values[:, 0]\n",
    "        sf_nom = corr.evaluate(GenZ_pt, \"nominal\")\n",
    "        sf_up = corr.evaluate(GenZ_pt, \"stat_up\")\n",
    "        sf_down = corr.evaluate(GenZ_pt, \"stat_down\")\n",
    "        events_combined[year][\"Zto2Q\"][\"SF_GenZPt\"] = sf_nom\n",
    "        events_combined[year][\"Zto2Q\"][\"SF_GenZPt_up\"] = sf_up\n",
    "        events_combined[year][\"Zto2Q\"][\"SF_GenZPt_down\"] = sf_down\n",
    "        events_combined[year][\"Zto2Q\"][\"finalWeight\"] = (\n",
    "            events_combined[year][\"Zto2Q\"][\"finalWeight\"] * sf_nom\n",
    "        )\n",
    "        events_combined[year][\"Zto2Q\"][\"weight_GenZPtUp\"] = (\n",
    "            events_combined[year][\"Zto2Q\"][\"finalWeight\"] * sf_up\n",
    "        )\n",
    "        events_combined[year][\"Zto2Q\"][\"weight_GenZPtDown\"] = (\n",
    "            events_combined[year][\"Zto2Q\"][\"finalWeight\"] * sf_down\n",
    "        )\n",
    "    print(\"Zto2Q corrections applied\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0274383",
   "metadata": {},
   "outputs": [],
   "source": [
    "# further split Zto2Q and Wto2Q events into different categories\n",
    "for year in [\"2022All\", \"2023All\"]:\n",
    "    Zto2Q = events_combined[year][\"Zto2Q\"]\n",
    "    matched = Zto2Q[\"bbFatJetVQQMatch0\"] == 1\n",
    "    is_ZBB = Zto2Q[(\"GenZBB\", 0)]\n",
    "    is_ZCC = Zto2Q[(\"GenZCC\", 0)]\n",
    "    is_ZQQ = ~(is_ZBB | is_ZCC)  # u, d, s quarks\n",
    "    ZtoBB = is_ZBB & matched\n",
    "    ZtoCC = is_ZCC & matched\n",
    "    ZtoQQ = is_ZQQ & matched\n",
    "    Z_unmatched = ~matched\n",
    "    events_combined[year][\"Zto2Q_BB\"] = Zto2Q[ZtoBB]\n",
    "    events_combined[year][\"Zto2Q_CC\"] = Zto2Q[ZtoCC]\n",
    "    events_combined[year][\"Zto2Q_QQ\"] = Zto2Q[ZtoQQ]\n",
    "    events_combined[year][\"Zto2Q_unmatched\"] = Zto2Q[Z_unmatched]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f2e5131",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass and fail regions\n",
    "txbb_bins = [0.95, 0.975, 0.99, 1.0]\n",
    "# pT bins\n",
    "pt_bins = [350, 550, 10000]\n",
    "\n",
    "txbb_bins = list(zip(txbb_bins[:-1], txbb_bins[1:]))\n",
    "pt_bins = list(zip(pt_bins[:-1], pt_bins[1:]))\n",
    "\n",
    "# Mass bins\n",
    "m_low, m_high = 50, 150\n",
    "bins = 5\n",
    "n_mass_bins = int((m_high - m_low) / bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32077334",
   "metadata": {},
   "outputs": [],
   "source": [
    "# placeholders\n",
    "bkg_keys = [\"Zto2Q_BB\", \"Zto2Q_CC\", \"Zto2Q_QQ\", \"Zto2Q_unmatched\", \"Wto2Q\", \"hbb\", \"qcd\", \"ttbar\"]\n",
    "sig_keys = [\"Zto2Q_BB\"]\n",
    "\n",
    "jshift_keys = [\"\"]\n",
    "# TODO: add JES and JER shifts\n",
    "# for var, ud in itertools.product([\"JES\", \"JER\"], [\"up\", \"down\"]):\n",
    "#     jshift_keys.append(f\"{var}_{ud}\")\n",
    "\n",
    "for year, events in events_combined.items():\n",
    "\n",
    "    templates = {}\n",
    "\n",
    "    for txbb_bin, (pt_low, pt_high) in itertools.product(txbb_bins, pt_bins):\n",
    "        templ_dir = Path(f\"templates_zbb_pt{pt_low}to{pt_high}/TXbb{txbb_bin[0]}to{txbb_bin[1]}\")\n",
    "        templ_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        cutflows_dir = Path(f\"{templ_dir}/cutflows/{year}\")\n",
    "        cutflows_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        plot_dir = Path(f\"{templ_dir}/{year}\")\n",
    "        plot_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        for jshift in jshift_keys:\n",
    "            if jshift == \"\":\n",
    "                mass_branch = \"bbFatJetParTmassVis0\"\n",
    "                pt_branch = \"bbFatJetPt0\"\n",
    "            elif \"jms\" in jshift or \"jmr\" in jshift:\n",
    "                mass_branch = f\"bbFatJetParTmassVis0_{jshift}\"\n",
    "                pt_branch = f\"bbFatJetPt0\"\n",
    "            elif \"jes\" in jshift or \"jer\" in jshift:\n",
    "                mass_branch = \"bbFatJetParTmassVis0\"\n",
    "                pt_branch = f\"bbFatJetPt0_{jshift}\"\n",
    "\n",
    "            selection_regions = {\n",
    "                \"pass\": postprocessing.Region(\n",
    "                    cuts={\n",
    "                        # edit these cuts to match your selection\n",
    "                        pt_branch: [pt_low, pt_high],\n",
    "                        mass_branch: [m_low, m_high],\n",
    "                        \"bbFatJetParTTXbb0\": txbb_bin,\n",
    "                    },\n",
    "                    label=\"pass\",\n",
    "                ),\n",
    "                \"fail\": postprocessing.Region(\n",
    "                    cuts={\n",
    "                        # edit these cuts to match your selection\n",
    "                        pt_branch: [pt_low, pt_high],\n",
    "                        mass_branch: [m_low, m_high],\n",
    "                        \"bbFatJetParTTXbb0\": [0.1, min(0.9, txbb_bin[1])],\n",
    "                    },\n",
    "                    label=\"fail\",\n",
    "                ),\n",
    "            }\n",
    "\n",
    "            fit_shape_var = postprocessing.ShapeVar(\n",
    "                mass_branch,\n",
    "                r\"$m_\\mathrm{reg}$ (GeV)\",\n",
    "                [n_mass_bins, m_low, m_high],\n",
    "                reg=True,\n",
    "            )\n",
    "            ttemps = postprocessing.get_templates(\n",
    "                events,\n",
    "                year=year,\n",
    "                sig_keys=sig_keys,\n",
    "                plot_sig_keys=sig_keys,\n",
    "                selection_regions=selection_regions,\n",
    "                shape_vars=[fit_shape_var],\n",
    "                systematics={},\n",
    "                template_dir=templ_dir,\n",
    "                bg_keys=bkg_keys,\n",
    "                plot_dir=plot_dir,\n",
    "                weight_key=\"finalWeight\",\n",
    "                weight_shifts={},  # skip systematics for now\n",
    "                plot_shifts=True,  # skip for time\n",
    "                show=False,\n",
    "                energy=13.6,\n",
    "                jshift=jshift,\n",
    "                blind=False,\n",
    "            )\n",
    "            templates = {**templates, **ttemps}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02473d2d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hh4b",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

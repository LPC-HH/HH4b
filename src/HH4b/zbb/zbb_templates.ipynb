{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c56774",
   "metadata": {},
   "outputs": [],
   "source": [
    "# automatically reloads imported files on edits\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc9de15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import uproot\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from HH4b import utils\n",
    "from HH4b import postprocessing\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edbe9ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_path: Path = Path(\"Zbb_events_combined.pkl\")\n",
    "REPROCESS: bool = False  # if True, reprocess from the skimmed ntuples\n",
    "\n",
    "samples_run3 = {\n",
    "    \"data\": [f\"{key}_Run\" for key in [\"JetMET\"]],\n",
    "    \"ttbar\": [\"TTto4Q\", \"TTtoLNu2Q\"],\n",
    "    \"qcd\": [\"QCD_HT\"],\n",
    "    \"hbb\": [\"GluGluHto2B_M-125\"],\n",
    "    \"Zto2Q\": [\"Zto2Q-4Jets\"],\n",
    "    \"Wto2Q\": [\"Wto2Q-3Jets\"],\n",
    "}\n",
    "\n",
    "sys_vars = [\"FSRPartonShower\", \"ISRPartonShower\", \"pileup\"]\n",
    "\n",
    "fatjet_vars = [\n",
    "    \"bbFatJetPt\",\n",
    "    \"bbFatJetEta\",\n",
    "    \"bbFatJetMsd\",\n",
    "    \"bbFatJetParTmassVis\",\n",
    "    \"bbFatJetPNetMassLegacy\",\n",
    "    \"bbFatJetParTTXbb\",\n",
    "]\n",
    "\n",
    "pt_variations = []\n",
    "for jesr, ud in itertools.product([\"JES\", \"JER\"], [\"up\", \"down\"]):\n",
    "    pt_variations.append(f\"bbFatJetPt_{jesr}_{ud}\")\n",
    "\n",
    "mass_variations = []\n",
    "for jmsr, ud in itertools.product([\"JMS\", \"JMR\"], [\"up\", \"down\"]):\n",
    "    mass_variations.append(f\"bbFatJetMsd_{jmsr}_{ud}\")\n",
    "    mass_variations.append(f\"bbFatJetParTmassVis_{jmsr}_{ud}\")\n",
    "    mass_variations.append(f\"bbFatJetPNetMassLegacy_{jmsr}_{ud}\")\n",
    "\n",
    "\n",
    "base_columns = [(var, 2) for var in fatjet_vars] + [(\"weight\", 1)]\n",
    "\n",
    "triggers = {\n",
    "    \"2022\": [\n",
    "        \"AK8PFJet500\",\n",
    "        \"AK8PFJet420_MassSD30\",\n",
    "        \"AK8PFJet425_SoftDropMass40\",\n",
    "        \"AK8PFJet250_SoftDropMass40_PFAK8ParticleNetBB0p35\",\n",
    "    ],\n",
    "    \"2022EE\": [\n",
    "        \"AK8PFJet500\",\n",
    "        \"AK8PFJet420_MassSD30\",\n",
    "        \"AK8PFJet425_SoftDropMass40\",\n",
    "        \"AK8PFJet250_SoftDropMass40_PFAK8ParticleNetBB0p35\",\n",
    "    ],\n",
    "    \"2023\": [\n",
    "        \"AK8PFJet500\",\n",
    "        \"AK8PFJet420_MassSD30\",\n",
    "        \"AK8PFJet425_SoftDropMass40\",\n",
    "        \"AK8PFJet250_SoftDropMass40_PFAK8ParticleNetBB0p35\",\n",
    "        \"AK8PFJet230_SoftDropMass40_PNetBB0p06\",\n",
    "    ],\n",
    "    \"2023BPix\": [\n",
    "        \"AK8PFJet500\",\n",
    "        \"AK8PFJet420_MassSD30\",\n",
    "        \"AK8PFJet425_SoftDropMass40\",\n",
    "        \"AK8PFJet230_SoftDropMass40_PNetBB0p06\",\n",
    "    ],\n",
    "}\n",
    "\n",
    "union_triggers = set()\n",
    "for year, trigger_list in triggers.items():\n",
    "    union_triggers.update(trigger_list)\n",
    "\n",
    "load_columns_pt_var = []\n",
    "# for jesr, ud in itertools.product([\"JES\", \"JER\"], [\"up\", \"down\"]):\n",
    "#     load_columns_pt_var.append((f\"bbFatJetPt_{jesr}_{ud}\", 2))\n",
    "for pt_var in pt_variations:\n",
    "    load_columns_pt_var.append((pt_var, 2))\n",
    "\n",
    "load_columns_mass_var = []\n",
    "# for jmsr, ud in itertools.product([\"JMS\", \"JMR\"], [\"up\", \"down\"]):\n",
    "#     load_columns_mass_var.append((f\"bbFatJetMsd_{jmsr}_{ud}\", 2))\n",
    "#     load_columns_mass_var.append((f\"bbFatJetParTmassVis_{jmsr}_{ud}\", 2))\n",
    "#     load_columns_mass_var.append((f\"bbFatJetPNetMassLegacy_{jmsr}_{ud}\", 2))\n",
    "for mass_var in mass_variations:\n",
    "    load_columns_mass_var.append((mass_var, 2))\n",
    "\n",
    "load_weight_shifts = []\n",
    "for var, ud in itertools.product(sys_vars, [\"Up\", \"Down\"]):\n",
    "    load_weight_shifts.append((f\"weight_{var}{ud}\", 1))\n",
    "\n",
    "MC_common_extra_columns = load_columns_mass_var + load_columns_pt_var + load_weight_shifts\n",
    "\n",
    "ZQQ_extra_columns = [(\"GenZPt\", 1), (\"GenZBB\", 1), (\"GenZCC\", 1), (\"bbFatJetVQQMatch\", 2)]\n",
    "WQQ_extra_columns = [(\"GenWPt\", 1), (\"GenWCS\", 1), (\"GenWUD\", 1), (\"bbFatJetVQQMatch\", 2)]\n",
    "\n",
    "extra_columns_dict = {\n",
    "    \"data\": [],\n",
    "    \"qcd\": load_weight_shifts,\n",
    "    \"ttbar\": MC_common_extra_columns,\n",
    "    \"hbb\": MC_common_extra_columns,\n",
    "    \"Zto2Q\": MC_common_extra_columns + ZQQ_extra_columns,\n",
    "    \"Wto2Q\": MC_common_extra_columns + WQQ_extra_columns,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba476244",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if True, apply the Z->2Q corrections from ZMuMu measurement\n",
    "APPLY_Zto2Q_CORR: bool = False\n",
    "if APPLY_Zto2Q_CORR:\n",
    "    import correctionlib\n",
    "\n",
    "    corr_dir = Path(\"ZMuMu_corrs/pT\")\n",
    "    corr_dict = {}\n",
    "\n",
    "    for year in [\"2022\", \"2023\"]:\n",
    "        corr_file = corr_dir / f\"corr_{year}.json\"\n",
    "        if not corr_file.exists():\n",
    "            raise FileNotFoundError(f\"Correction file {corr_file} does not exist.\")\n",
    "\n",
    "        # Load the correction\n",
    "        corr = correctionlib.CorrectionSet.from_file(str(corr_file))\n",
    "        corr_dict[year] = corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93acecb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if REPROCESS or not processed_path.exists():\n",
    "    path_dir = \"/ceph/cms/store/user/zichun/bbbb/skimmer/ZbbHT25May28_v12v2_private_zbb/\"\n",
    "\n",
    "    events_dict = {}\n",
    "    for year in [\"2022\", \"2022EE\", \"2023\", \"2023BPix\"]:\n",
    "        # for year in [\"2022\"]:\n",
    "        events_dict[year] = {}\n",
    "\n",
    "        # Have to load the samples separately because branches vary\n",
    "        for sample, sample_list in samples_run3.items():\n",
    "            print(f\"Loading {sample} for {year}...\")\n",
    "            triggers_cols = [(trigger, 1) for trigger in triggers[year]]\n",
    "\n",
    "            # append the event dictionary for each year\n",
    "            columns = triggers_cols + base_columns + extra_columns_dict.get(sample, [])\n",
    "            dataframes = {\n",
    "                **utils.load_samples(\n",
    "                    data_dir=path_dir,\n",
    "                    samples={sample: sample_list},\n",
    "                    year=year,\n",
    "                    columns=utils.format_columns(columns),\n",
    "                    variations=True,\n",
    "                    weight_shifts=[\"FSRPartonShower\", \"ISRPartonShower\", \"pileup\"],\n",
    "                )\n",
    "            }\n",
    "            # concatenate all dataframes in this sample\n",
    "            events_dict[year][sample] = []\n",
    "            for key, df in dataframes.items():\n",
    "                # if pT variations are not present, set them to pT\n",
    "                for pt_var in [\"bbFatJetPt\"] + pt_variations:\n",
    "                    if pt_var not in df.columns:\n",
    "                        for i in range(2):\n",
    "                            df[f\"{pt_var}{i}\"] = df[(\"bbFatJetPt\", i)].copy()\n",
    "\n",
    "                # if mass variations are not present, set them to mass\n",
    "                for mass_var in [\n",
    "                    \"bbFatJetMsd\",\n",
    "                    \"bbFatJetParTmassVis\",\n",
    "                    \"bbFatJetPNetMassLegacy\",\n",
    "                ] + mass_variations:\n",
    "                    if mass_var not in df.columns:\n",
    "                        for i in range(2):\n",
    "                            df[f\"{mass_var}{i}\"] = df[(mass_var.split(\"_\")[0], i)].copy()\n",
    "\n",
    "                for trigger in union_triggers:\n",
    "                    if trigger not in df.columns:\n",
    "                        df[trigger] = np.zeros(len(df), dtype=int)\n",
    "                    df[trigger] = df[trigger].fillna(0).astype(int)\n",
    "\n",
    "                events_dict[year][sample].append(df)\n",
    "\n",
    "            # concatenate all dataframes for this sample\n",
    "            events_dict[year][sample] = pd.concat(events_dict[year][sample], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07954dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if REPROCESS or not processed_path.exists():\n",
    "    events_combined = {\n",
    "        \"2022All\": {},\n",
    "        \"2023All\": {},\n",
    "    }\n",
    "    for sample in samples_run3:\n",
    "        events_combined[\"2022All\"][sample] = pd.concat(\n",
    "            [\n",
    "                events_dict[year][sample]\n",
    "                for year in [\"2022\", \"2022EE\"]\n",
    "                if sample in events_dict[year]\n",
    "            ]\n",
    "        )\n",
    "        events_combined[\"2023All\"][sample] = pd.concat(\n",
    "            [\n",
    "                events_dict[year][sample]\n",
    "                for year in [\"2023\", \"2023BPix\"]\n",
    "                if sample in events_dict[year]\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    # store events_combined as a pickle file\n",
    "    with processed_path.open(\"wb\") as f:\n",
    "        pd.to_pickle(events_combined, f)\n",
    "    print(f\"Events combined and saved to {processed_path}\")\n",
    "else:\n",
    "    # directly load the processed file\n",
    "    print(f\"Loading events from {processed_path}...\")\n",
    "    with processed_path.open(\"rb\") as f:\n",
    "        events_combined = pd.read_pickle(f)\n",
    "    print(f\"Loaded events from {processed_path}\")\n",
    "\n",
    "if APPLY_Zto2Q_CORR:\n",
    "    print(\"Applying Zto2Q corrections...\")\n",
    "    for year in [\"2022All\", \"2023All\"]:\n",
    "        # apply corrections to the events\n",
    "        corr = corr_dict[year.replace(\"All\", \"\")][\"GenZPtWeight\"]\n",
    "        GenZ_pt = events_combined[year][\"Zto2Q\"][\"GenZPt\"].values[:, 0]\n",
    "        sf_nom = corr.evaluate(GenZ_pt, \"nominal\")\n",
    "        sf_up = corr.evaluate(GenZ_pt, \"stat_up\")\n",
    "        sf_down = corr.evaluate(GenZ_pt, \"stat_down\")\n",
    "        events_combined[year][\"Zto2Q\"][\"SF_GenZPt\"] = sf_nom\n",
    "        events_combined[year][\"Zto2Q\"][\"SF_GenZPt_up\"] = sf_up\n",
    "        events_combined[year][\"Zto2Q\"][\"SF_GenZPt_down\"] = sf_down\n",
    "        events_combined[year][\"Zto2Q\"][\"finalWeight\"] = (\n",
    "            events_combined[year][\"Zto2Q\"][\"finalWeight\"] * sf_nom\n",
    "        )\n",
    "        events_combined[year][\"Zto2Q\"][\"weight_GenZPtUp\"] = (\n",
    "            events_combined[year][\"Zto2Q\"][\"finalWeight\"] * sf_up\n",
    "        )\n",
    "        events_combined[year][\"Zto2Q\"][\"weight_GenZPtDown\"] = (\n",
    "            events_combined[year][\"Zto2Q\"][\"finalWeight\"] * sf_down\n",
    "        )\n",
    "    print(\"Zto2Q corrections applied\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0274383",
   "metadata": {},
   "outputs": [],
   "source": [
    "# further split Zto2Q and Wto2Q events into different categories\n",
    "for year in [\"2022All\", \"2023All\"]:\n",
    "    Zto2Q = events_combined[year][\"Zto2Q\"]\n",
    "    matched = Zto2Q[(\"bbFatJetVQQMatch\", 0)] == 1\n",
    "    is_ZBB = Zto2Q[(\"GenZBB\", 0)]\n",
    "    is_ZCC = Zto2Q[(\"GenZCC\", 0)]\n",
    "    is_ZQQ = ~(is_ZBB | is_ZCC)  # u, d, s quarks\n",
    "    ZtoBB = is_ZBB & matched\n",
    "    ZtoCC = is_ZCC & matched\n",
    "    ZtoQQ = is_ZQQ & matched\n",
    "    Z_unmatched = ~matched\n",
    "    events_combined[year][\"Zto2Q_BB\"] = Zto2Q[ZtoBB]\n",
    "    events_combined[year][\"Zto2Q_CC\"] = Zto2Q[ZtoCC]\n",
    "    events_combined[year][\"Zto2Q_QQ\"] = Zto2Q[ZtoQQ]\n",
    "    events_combined[year][\"Zto2Q_unmatched\"] = Zto2Q[Z_unmatched]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f2e5131",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass and fail regions\n",
    "txbb_bins = [0.95, 0.975, 0.99, 1.0]\n",
    "# pT bins\n",
    "pt_bins = [350, 550, 10000]\n",
    "\n",
    "txbb_bins = list(zip(txbb_bins[:-1], txbb_bins[1:]))\n",
    "pt_bins = list(zip(pt_bins[:-1], pt_bins[1:]))\n",
    "\n",
    "# Mass bins\n",
    "m_low, m_high = 50, 150\n",
    "bins = 5\n",
    "n_mass_bins = int((m_high - m_low) / bins)\n",
    "\n",
    "\n",
    "def save_to_file(outfile: Path, templates: dict):\n",
    "    with uproot.recreate(str(outfile)) as f_out:\n",
    "        for category in templates.keys():\n",
    "            for sample in list(samples_run3.keys()) + [\n",
    "                \"Zto2Q_BB\",\n",
    "                \"Zto2Q_CC\",\n",
    "                \"Zto2Q_QQ\",\n",
    "                \"Zto2Q_unmatched\",\n",
    "            ]:\n",
    "                h = templates[category][{\"Sample\": sample}]\n",
    "                f_out[f\"{sample}_{category}\"] = h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32077334",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bkg_keys = [\"Zto2Q_CC\", \"Zto2Q_QQ\", \"Zto2Q_unmatched\", \"Wto2Q\", \"hbb\", \"ttbar\", \"qcd\"]\n",
    "# sig_keys = [\"Zto2Q_BB\"]\n",
    "# use this if you want to include Zto2Q_BB in the stack plot\n",
    "bkg_keys = [\"Zto2Q_BB\", \"Zto2Q_CC\", \"Zto2Q_QQ\", \"Zto2Q_unmatched\", \"Wto2Q\", \"hbb\", \"ttbar\", \"qcd\"]\n",
    "sig_keys = []\n",
    "bg_order = list(reversed(bkg_keys))\n",
    "\n",
    "jshift_keys = [\"\"]\n",
    "for var, ud in itertools.product([\"JES\", \"JER\", \"JMS\", \"JMR\"], [\"up\", \"down\"]):\n",
    "    jshift_keys.append(f\"{var}_{ud}\")\n",
    "\n",
    "\n",
    "for year, events in events_combined.items():\n",
    "    for txbb_bin, (pt_low, pt_high) in itertools.product(txbb_bins, pt_bins):\n",
    "        out_dir = Path(f\"templates_zbb/pt{pt_low}to{pt_high}/TXbb{txbb_bin[0]}to{txbb_bin[1]}\")\n",
    "        out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        cutflows_dir = Path(f\"{out_dir}/cutflows/{year}\")\n",
    "        cutflows_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        plot_dir = Path(f\"{out_dir}/plots/{year}\")\n",
    "        plot_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        template_dir = Path(f\"{out_dir}/templates\")\n",
    "        template_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        templates = {}\n",
    "        for jshift in jshift_keys:\n",
    "            if jshift == \"\":\n",
    "                pt_branch = \"bbFatJetPt0\"\n",
    "                mass_branch = \"bbFatJetParTmassVis0\"\n",
    "            elif jshift.startswith(\"JES\") or jshift.startswith(\"JER\"):\n",
    "                pt_branch = f\"bbFatJetPt_{jshift}0\"\n",
    "                mass_branch = \"bbFatJetParTmassVis0\"\n",
    "            elif jshift.startswith(\"JMS\") or jshift.startswith(\"JMR\"):\n",
    "                pt_branch = \"bbFatJetPt0\"\n",
    "                mass_branch = f\"bbFatJetParTmassVis_{jshift}0\"\n",
    "            else:\n",
    "                raise ValueError(f\"Unknown jshift: {jshift}\")\n",
    "\n",
    "            selection_regions = {\n",
    "                \"pass\": postprocessing.Region(\n",
    "                    cuts={\n",
    "                        pt_branch: [pt_low, pt_high],\n",
    "                        mass_branch: [m_low, m_high],\n",
    "                        \"bbFatJetParTTXbb0\": txbb_bin,\n",
    "                    },\n",
    "                    label=\"pass\",\n",
    "                ),\n",
    "                \"fail\": postprocessing.Region(\n",
    "                    cuts={\n",
    "                        pt_branch: [pt_low, pt_high],\n",
    "                        mass_branch: [m_low, m_high],\n",
    "                        \"bbFatJetParTTXbb0\": [0.1, min(0.9, txbb_bin[1])],\n",
    "                    },\n",
    "                    label=\"fail\",\n",
    "                ),\n",
    "            }\n",
    "\n",
    "            fit_shape_var = postprocessing.ShapeVar(\n",
    "                mass_branch,\n",
    "                r\"$m_\\mathrm{reg}$ (GeV)\",\n",
    "                [n_mass_bins, m_low, m_high],\n",
    "                reg=True,\n",
    "            )\n",
    "\n",
    "            print(f\"{jshift=}\")\n",
    "            ttemps = postprocessing.get_templates(\n",
    "                events,\n",
    "                year=year,\n",
    "                sig_keys=sig_keys,\n",
    "                plot_sig_keys=sig_keys,\n",
    "                selection_regions=selection_regions,\n",
    "                shape_vars=[fit_shape_var],\n",
    "                systematics={},\n",
    "                template_dir=out_dir,\n",
    "                bg_keys=bkg_keys,\n",
    "                bg_order=bg_order,\n",
    "                bg_err_mcstat=False,\n",
    "                plot_dir=plot_dir,\n",
    "                weight_key=\"finalWeight\",\n",
    "                weight_shifts={},  # skip systematics for now\n",
    "                plot_shifts=False,  # skip for time\n",
    "                show=False,\n",
    "                energy=13.6,\n",
    "                jshift=jshift,\n",
    "                blind=False,\n",
    "            )\n",
    "            templates = {**templates, **ttemps}\n",
    "        # save the templates to a file\n",
    "        outfile = template_dir / f\"templates_{year}.root\"\n",
    "        save_to_file(outfile, templates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a93376",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hh4b",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

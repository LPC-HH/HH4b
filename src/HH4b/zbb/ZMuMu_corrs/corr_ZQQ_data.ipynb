{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e46ae47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# automatically reloads imported files on edits\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d95ec179",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "from constants import PT_BINS\n",
    "from HH4b.hh_vars import LUMI\n",
    "\n",
    "import mplhep as hep\n",
    "\n",
    "hep.style.use(hep.style.CMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47bbb4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "PLOT_DIR = Path(\"plots/corr_ZQQ_data\")\n",
    "PLOT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "OUTPUT_PKL_PATH = Path(\"corrs/ZQQ_data.pkl\")\n",
    "(OUTPUT_PKL_PATH.parent).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f951f5a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_pickle(path: Path):\n",
    "    with path.open(\"rb\") as f:\n",
    "        return pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b41ccb6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_DYLL_data = Path(\"corrs/DYLL_data.pkl\")\n",
    "path_ZQQ_DYLL = Path(\"corrs/ZQQ_DYLL.pkl\")\n",
    "\n",
    "SF_dict_DYLL_data = read_pickle(path_DYLL_data)\n",
    "SF_dict_ZQQ_DYLL = read_pickle(path_ZQQ_DYLL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd5b9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiply_SFs_asymmetric(\n",
    "    SF_dict_1: dict[str, np.ndarray], SF_dict_2: dict[str, np.ndarray]\n",
    ") -> dict[str, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Alternative method that handles asymmetric errors more rigorously.\n",
    "    This method propagates the up and down variations separately.\n",
    "    \"\"\"\n",
    "    result_dict = {}\n",
    "\n",
    "    nominal1 = SF_dict_1[\"nominal\"]\n",
    "    up1 = SF_dict_1[\"up\"]\n",
    "    down1 = SF_dict_1[\"down\"]\n",
    "\n",
    "    nominal2 = SF_dict_2[\"nominal\"]\n",
    "    up2 = SF_dict_2[\"up\"]\n",
    "    down2 = SF_dict_2[\"down\"]\n",
    "\n",
    "    # Multiply nominal values\n",
    "    result_nominal = nominal1 * nominal2\n",
    "\n",
    "    # For asymmetric errors, we need to consider all combinations\n",
    "    # and take the envelope\n",
    "    combinations = [\n",
    "        up1 * up2,  # both up\n",
    "        up1 * down2,  # first up, second down\n",
    "        down1 * up2,  # first down, second up\n",
    "        down1 * down2,  # both down\n",
    "    ]\n",
    "\n",
    "    # Find the maximum and minimum deviations from nominal\n",
    "    max_result = np.max(combinations, axis=0)\n",
    "    min_result = np.min(combinations, axis=0)\n",
    "\n",
    "    result_dict = {\n",
    "        \"nominal\": result_nominal,\n",
    "        \"up\": max_result,\n",
    "        \"down\": min_result,\n",
    "        \"pt\": SF_dict_1[\"pt\"],\n",
    "    }\n",
    "\n",
    "    return result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a64d086",
   "metadata": {},
   "outputs": [],
   "source": [
    "SF_dict_ZQQ_data = {}\n",
    "for year in SF_dict_DYLL_data:\n",
    "    SF = multiply_SFs_asymmetric(SF_dict_ZQQ_DYLL[year], SF_dict_DYLL_data[year])\n",
    "    SF_dict_ZQQ_data[year] = SF\n",
    "\n",
    "# Save the combined SFs\n",
    "with OUTPUT_PKL_PATH.open(\"wb\") as f:\n",
    "    pickle.dump(SF_dict_ZQQ_data, f)\n",
    "\n",
    "# # Use DYLL->Data correction directly since ZQQ->DYLL is essentially 1\n",
    "# SF_dict_ZQQ_data = SF_dict_DYLL_data\n",
    "\n",
    "# with OUTPUT_PKL_PATH.open(\"wb\") as f:\n",
    "#     pickle.dump(SF_dict_ZQQ_data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f5b1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the scale factors\n",
    "for year in SF_dict_ZQQ_data:\n",
    "    sf = SF_dict_ZQQ_data[year]\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "    # Plot nominal scale factor\n",
    "    ax.errorbar(\n",
    "        (PT_BINS[:-1] + PT_BINS[1:]) / 2,\n",
    "        sf[\"nominal\"],\n",
    "        xerr=(PT_BINS[1:] - PT_BINS[:-1]) / 2,\n",
    "        yerr=sf[\"up\"] - sf[\"nominal\"],\n",
    "        fmt=\"o\",\n",
    "        color=\"blue\",\n",
    "        markersize=5,\n",
    "        capsize=3,\n",
    "    )\n",
    "\n",
    "    # plot 1\n",
    "    ax.axhline(y=1, color=\"red\", linestyle=\"--\", label=\"Nominal SF = 1\")\n",
    "\n",
    "    ax.set_xlabel(r\"Z $p_\\mathrm{T}$ [GeV]\")\n",
    "    ax.set_ylabel(\"Scale Factor\")\n",
    "    # ax.set_xlim(PT_BINS[0], PT_BINS[-1])\n",
    "    ax.set_ylim(0.5, 1.5)\n",
    "    # ax.grid(True)\n",
    "\n",
    "    hep.cms.label(\n",
    "        ax=ax,\n",
    "        label=\"Work in Progress\",\n",
    "        data=True,\n",
    "        year=year.replace(\"All\", \"\"),\n",
    "        com=13.6,\n",
    "        lumi=(round(LUMI[year] / 1000, 2)),\n",
    "    )\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(PLOT_DIR / f\"SF_{year}.pdf\", bbox_inches=\"tight\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e56ed6a",
   "metadata": {},
   "source": [
    "# Export to Correctionlib Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff9855e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from correctionlib import schemav2\n",
    "\n",
    "\n",
    "def binning(edges, content):\n",
    "    return schemav2.Binning(\n",
    "        nodetype=\"binning\",\n",
    "        input=\"pt\",\n",
    "        edges=edges,\n",
    "        content=list(content),\n",
    "        flow=\"clamp\",\n",
    "    )\n",
    "\n",
    "\n",
    "def get_corr(edges, val_nom, val_up, val_down):\n",
    "    pt_weight = schemav2.Correction(\n",
    "        name=\"GenZPtWeight\",\n",
    "        version=1,\n",
    "        description=\"Gen-Level Z pT reweighting correction derived from ZMuMu\",\n",
    "        inputs=[\n",
    "            schemav2.Variable(\n",
    "                name=\"pt\",\n",
    "                type=\"real\",\n",
    "                description=\"Gen Z transverse momentum\",\n",
    "            ),\n",
    "            schemav2.Variable(\n",
    "                name=\"systematic\",\n",
    "                type=\"string\",\n",
    "                description=\"Systematic variation\",\n",
    "            ),\n",
    "        ],\n",
    "        output=schemav2.Variable(\n",
    "            name=\"weight\", type=\"real\", description=\"Multiplicative event weight\"\n",
    "        ),\n",
    "        data=schemav2.Category(\n",
    "            nodetype=\"category\",\n",
    "            input=\"systematic\",\n",
    "            content=[\n",
    "                {\"key\": \"nominal\", \"value\": binning(edges, val_nom)},\n",
    "                {\"key\": \"stat_up\", \"value\": binning(edges, val_up)},\n",
    "                {\"key\": \"stat_dn\", \"value\": binning(edges, val_down)},\n",
    "            ],\n",
    "            default=binning(edges, val_nom),\n",
    "        ),\n",
    "        generic_formulas=[],\n",
    "    )\n",
    "    cset = schemav2.CorrectionSet(\n",
    "        schema_version=2,\n",
    "        description=\"Gen-Level Z pT reweighting correction derived from ZMuMu\",\n",
    "        corrections=[\n",
    "            pt_weight,\n",
    "        ],\n",
    "        compound_corrections=[],\n",
    "    )\n",
    "\n",
    "    return cset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844be3d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for year, SF in SF_dict_ZQQ_data.items():\n",
    "    year = year.replace(\"All\", \"\")\n",
    "    edges = SF[\"pt\"]\n",
    "    if (len(edges) != len(PT_BINS)) or (not np.isclose(edges, PT_BINS).all()):\n",
    "        raise ValueError(f\"Edges ({edges}) for {year} do not match PT_BINS {PT_BINS}\")\n",
    "    cset = get_corr(edges, SF[\"nominal\"], SF[\"up\"], SF[\"down\"])\n",
    "    with open(f\"corr_{year}.json\", \"w\") as fout:\n",
    "        fout.write(cset.model_dump_json(exclude_unset=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b6170cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hh4b",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

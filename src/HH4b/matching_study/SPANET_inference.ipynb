{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# automatically reloads imported files on edits\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import mplhep as hep\n",
    "import matplotlib.ticker as mticker\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "import hist\n",
    "\n",
    "hep.style.use([\"CMS\", \"firamath\"])\n",
    "\n",
    "formatter = mticker.ScalarFormatter(useMathText=True)\n",
    "formatter.set_powerlimits((-3, 3))\n",
    "plt.rcParams.update({\"font.size\": 12})\n",
    "plt.rcParams[\"lines.linewidth\"] = 2\n",
    "plt.rcParams[\"grid.color\"] = \"#CCCCCC\"\n",
    "plt.rcParams[\"grid.linewidth\"] = 0.5\n",
    "plt.rcParams[\"figure.edgecolor\"] = \"none\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnxruntime\n",
    "\n",
    "MAIN_DIR = \"../../../\"\n",
    "sess_options = onnxruntime.SessionOptions()\n",
    "sess_options.intra_op_num_threads = 23\n",
    "sess_options.execution_mode = onnxruntime.ExecutionMode.ORT_PARALLEL\n",
    "session = onnxruntime.InferenceSession(\n",
    "    f\"{MAIN_DIR}/../data/spanet-inference/spanet_pnet_all_vars_v0.onnx\", sess_options\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_name = session.get_inputs()[0].name\n",
    "output_name = session.get_outputs()[0].name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events = pd.read_parquet(\n",
    "    \"../../../../data/matching/23Nov18_WSel_v9_private/2018/GluGlutoHHto4B_cHHH1_TuneCP5_PSWeights_13TeV-powheg-pythia8/parquet\"\n",
    ")\n",
    "list(events.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nevents = len(events.ak4JetPt[0])\n",
    "nevents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import vector\n",
    "\n",
    "\n",
    "def make_vector(events: pd.DataFrame, obj: str):\n",
    "    \"\"\"Create a ``vector`` object from the columns of the dataframe\"\"\"\n",
    "    mstring = \"PNetMass\" if obj == \"ak8FatJet\" else \"Mass\"\n",
    "\n",
    "    return vector.array(\n",
    "        {\n",
    "            \"pt\": events[f\"{obj}Pt\"],\n",
    "            \"phi\": events[f\"{obj}Phi\"],\n",
    "            \"eta\": events[f\"{obj}Eta\"],\n",
    "            \"M\": events[f\"{obj}{mstring}\"],\n",
    "        }\n",
    "    )\n",
    "\n",
    "\n",
    "jets = make_vector(events, \"ak4Jet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "njets = 10\n",
    "jet_vars = [\"PtCorr\", \"Eta\", \"SinPhi\", \"CosPhi\", \"PNetB\", \"Mass\"]\n",
    "arrays = []\n",
    "for i in range(njets):\n",
    "    df = pd.DataFrame(0, index=np.arange(nevents), columns=jet_vars)\n",
    "    df[\"PtCorr\"] = events.ak4JetPt[i]\n",
    "    df[\"Eta\"] = events.ak4JetEta[i]\n",
    "    df[\"SinPhi\"] = np.sin(events.ak4JetPhi[i])\n",
    "    df[\"CosPhi\"] = np.cos(events.ak4JetPhi[i])\n",
    "    df[\"Mass\"] = events.ak4JetMass[i]\n",
    "    num = events.ak4JetbtagPNetProbb[i] + events.ak4JetbtagPNetProbbb[i]\n",
    "    den = (\n",
    "        events.ak4JetbtagPNetProbb[i]\n",
    "        + events.ak4JetbtagPNetProbbb[i]\n",
    "        + events.ak4JetbtagPNetProbc[i]\n",
    "        + events.ak4JetbtagPNetProbcc[i]\n",
    "        + events.ak4JetbtagPNetProbg[i]\n",
    "        + events.ak4JetbtagPNetProbuds[i]\n",
    "    )\n",
    "    df[\"PNetB\"] = np.where(den > 0, num / den, -1)\n",
    "    np_arr = df.values.T.astype(np.float32)\n",
    "    arrays.append(np_arr)\n",
    "\n",
    "Jets_data = np.transpose(np.transpose(arrays, (1, 0, 2)))\n",
    "Jets_Pt = Jets_data[:, :, 0]\n",
    "MIN_PT = 20\n",
    "Jets_mask = Jets_Pt > MIN_PT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boosted_arrays = []\n",
    "fatjet_vars = [\"Pt\", \"Eta\", \"SinPhi\", \"CosPhi\", \"PNetXbb\", \"PNetXjj\", \"PNetQCD\", \"Mass\"]\n",
    "nfatjets = 3\n",
    "for i in range(nfatjets):\n",
    "    df = pd.DataFrame(0, index=np.arange(nevents), columns=fatjet_vars)\n",
    "    df[\"Pt\"] = events.ak8FatJetPt[i]\n",
    "    df[\"Eta\"] = events.ak8FatJetEta[i]\n",
    "    df[\"SinPhi\"] = np.sin(events.ak8FatJetPhi[i])\n",
    "    df[\"CosPhi\"] = np.cos(events.ak8FatJetPhi[i])\n",
    "    df[\"PNetXbb\"] = events.ak8FatJetPNetXbb[i]\n",
    "    df[\"PNetXjj\"] = events.ak8FatJetPNetXjj[i]\n",
    "    df[\"PNetQCD\"] = events.ak8FatJetPNetQCD[i]\n",
    "    df[\"Mass\"] = events.ak8FatJetPNetMass[i]\n",
    "\n",
    "    np_arr = df.values.T.astype(np.float32)\n",
    "    boosted_arrays.append(np_arr)\n",
    "\n",
    "BoostedJets_data = np.transpose(np.transpose(boosted_arrays, (1, 0, 2)))\n",
    "MIN_FJPT = 200\n",
    "BoostedJets_Pt = BoostedJets_data[:, :, 0]\n",
    "BoostedJets_mask = BoostedJets_Pt > MIN_FJPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lep_arrays = []\n",
    "lep_vars = [\"Pt\", \"Eta\", \"SinPhi\", \"CosPhi\"]\n",
    "nleptons = 2\n",
    "for i in range(nleptons):\n",
    "    df = pd.DataFrame(0, index=np.arange(nevents), columns=lep_vars)\n",
    "    df[\"Pt\"] = events.LeptonPt[i]\n",
    "    df[\"Eta\"] = events.LeptonEta[i]\n",
    "    df[\"SinPhi\"] = np.sin(events.LeptonPhi[i])\n",
    "    df[\"CosPhi\"] = np.cos(events.LeptonPhi[i])\n",
    "\n",
    "    np_arr = df.values.T.astype(np.float32)\n",
    "    lep_arrays.append(np_arr)\n",
    "\n",
    "Leptons_data = np.transpose(np.transpose(lep_arrays, (1, 0, 2)))\n",
    "Leptons_Pt = Leptons_data[:, :, 0]\n",
    "Leptons_mask = Leptons_Pt > 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tau_arrays = []\n",
    "tau_vars = [\"Pt\", \"Eta\", \"SinPhi\", \"CosPhi\"]\n",
    "ntaus = 2\n",
    "for i in range(ntaus):\n",
    "    df = pd.DataFrame(0, index=np.arange(nevents), columns=tau_vars)\n",
    "    df[\"Pt\"] = events.tauPt[i]\n",
    "    df[\"Eta\"] = events.tauEta[i]\n",
    "    df[\"SinPhi\"] = np.sin(events.tauPhi[i])\n",
    "    df[\"CosPhi\"] = np.cos(events.tauPhi[i])\n",
    "\n",
    "    np_arr = df.values.T.astype(np.float32)\n",
    "    tau_arrays.append(np_arr)\n",
    "\n",
    "Taus_data = np.transpose(np.transpose(tau_arrays, (1, 0, 2)))\n",
    "Taus_Pt = Taus_data[:, :, 0]\n",
    "Taus_mask = Taus_Pt > 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "met_arrays = [np.array([events.MET_pt.values.squeeze()])]\n",
    "MET_data = np.transpose(met_arrays)\n",
    "MET_mask = MET_data[:, :, 0] > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ht_arrays = [np.array([events.ht.values.squeeze()])]\n",
    "HT_data = np.transpose(ht_arrays)\n",
    "HT_mask = HT_data[:, :, 0] > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Jets_arrays = {}\n",
    "Higgs_vars = [\"mass\", \"pt\", \"eta\", \"sinphi\", \"cosphi\", \"dr\"]\n",
    "for i in range(njets):\n",
    "    name = \"Jet%s\" % i\n",
    "    Higgs_list = []\n",
    "    for j in range(1, njets):\n",
    "        if i == j:\n",
    "            continue\n",
    "        if int(j) < int(i):\n",
    "            continue\n",
    "        j_i = jets[:, i]\n",
    "        j_j = jets[:, j]\n",
    "        jj = j_i + j_j\n",
    "        df = pd.DataFrame(0, index=np.arange(nevents), columns=Higgs_vars)\n",
    "        df[\"mass\"] = jj.mass\n",
    "        df[\"pt\"] = jj.pt\n",
    "        df[\"eta\"] = jj.eta\n",
    "        df[\"sinphi\"] = np.sin(jj.phi)\n",
    "        df[\"cosphi\"] = np.cos(jj.phi)\n",
    "        df[\"dr\"] = j_i.deltaR(j_j)\n",
    "        df = df.fillna(0)\n",
    "        np_arr = df.values.T.astype(np.float32)\n",
    "        Higgs_list.append(np_arr)\n",
    "    Jets_arrays[name] = Higgs_list\n",
    "\n",
    "Jet_data = {}\n",
    "Jet_mask = {}\n",
    "for i in range(njets - 1):\n",
    "    Jet_data[i] = np.transpose(np.transpose(Jets_arrays[f\"Jet{i}\"], (1, 0, 2)))\n",
    "    pt = Jet_data[i][:, :, 0]\n",
    "    Jet_mask[i] = pt > 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dict = {\n",
    "    \"Jets_data\": Jets_data,\n",
    "    \"Jets_mask\": Jets_mask,\n",
    "    \"BoostedJets_data\": BoostedJets_data,\n",
    "    \"BoostedJets_mask\": BoostedJets_mask,\n",
    "    \"Leptons_data\": Leptons_data,\n",
    "    \"Leptons_mask\": Leptons_mask,\n",
    "    \"Taus_data\": Taus_data,\n",
    "    \"Taus_mask\": Taus_mask,\n",
    "    \"MET_data\": MET_data,\n",
    "    \"MET_mask\": MET_mask,\n",
    "    \"HT_data\": HT_data,\n",
    "    \"HT_mask\": HT_mask,\n",
    "    \"Jet1_data\": Jet_data[0],\n",
    "    \"Jet1_mask\": Jet_mask[0],\n",
    "    \"Jet2_data\": Jet_data[1],\n",
    "    \"Jet2_mask\": Jet_mask[1],\n",
    "    \"Jet3_data\": Jet_data[2],\n",
    "    \"Jet3_mask\": Jet_mask[2],\n",
    "    \"Jet4_data\": Jet_data[3],\n",
    "    \"Jet4_mask\": Jet_mask[3],\n",
    "    \"Jet5_data\": Jet_data[4],\n",
    "    \"Jet5_mask\": Jet_mask[4],\n",
    "    \"Jet6_data\": Jet_data[5],\n",
    "    \"Jet6_mask\": Jet_mask[5],\n",
    "    \"Jet7_data\": Jet_data[6],\n",
    "    \"Jet7_mask\": Jet_mask[6],\n",
    "    \"Jet8_data\": Jet_data[7],\n",
    "    \"Jet8_mask\": Jet_mask[7],\n",
    "    \"Jet9_data\": Jet_data[8],\n",
    "    \"Jet9_mask\": Jet_mask[8],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_nodes = session.get_outputs()\n",
    "output_names = [node.name for node in output_nodes]\n",
    "output_values = session.run(output_names, input_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0-8: SPANET matching\n",
    "# assignment probabilities\n",
    "#  max_h1, index_h1: 0\n",
    "#  max_h2, index_h2: 1\n",
    "#  max_h3, index_h3: 2\n",
    "# detection probabilities\n",
    "#  h1Det: 6\n",
    "#  h2Det: 7\n",
    "#  h3Det: 8\n",
    "# boosted assignment probabilities\n",
    "#  bh1: 3\n",
    "#  bh2: 4\n",
    "#  bh3: 5\n",
    "# boosted detection probabilities\n",
    "#  9-11\n",
    "# 12\n",
    "#  0 ?\n",
    "#  prob_hhh: 1\n",
    "#  prob_qcd: 2\n",
    "#  prob_tt: 3\n",
    "#  prob_vjets: 4\n",
    "#  prob_vv: 5\n",
    "#  prob_hhh4b2tau: 6\n",
    "#  prob_hh4b: 7\n",
    "#  prob_hh2b2tau: 8\n",
    "classification = output_values[12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_hhh = output_values[12][:, 1]\n",
    "prob_qcd = output_values[12][:, 2]\n",
    "prob_tt = output_values[12][:, 3]\n",
    "prob_vjets = output_values[12][:, 4]\n",
    "prob_vv = output_values[12][:, 5]\n",
    "prob_hhh4b2tau = output_values[12][:, 6]\n",
    "prob_hh4b = output_values[12][:, 7]\n",
    "prob_hh2b2tau = output_values[12][:, 8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spanet_discr_axis = hist.axis.Regular(40, 0, 1, name=\"discr\", label=\"SPANET Discriminator\")\n",
    "class_axis = hist.axis.StrCategory([], name=\"class\", growth=True)\n",
    "h = hist.Hist(spanet_discr_axis, class_axis)\n",
    "h.fill(prob_hhh, \"hhh\")\n",
    "h.fill(prob_qcd, \"qcd\")\n",
    "h.fill(prob_tt, \"tt\")\n",
    "h.fill(prob_vjets, \"vjets\")\n",
    "h.fill(prob_vv, \"vv\")\n",
    "h.fill(prob_hhh4b2tau, \"hhh4b2tau\")\n",
    "h.fill(prob_hh4b, \"hh4b\")\n",
    "h.fill(prob_hh2b2tau, \"hh2b2tau\")\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(6, 4))\n",
    "legend_elements = []\n",
    "linestyles = {\n",
    "    \"hh4b\": \"solid\",\n",
    "    \"hhh\": \"dashed\",\n",
    "    \"qcd\": \"dashdot\",\n",
    "    \"tt\": \"dotted\",\n",
    "    \"vv\": \"solid\",\n",
    "    \"vjets\": \"dashed\",\n",
    "}\n",
    "color_by_prob = {\n",
    "    \"hh4b\": \"red\",\n",
    "    \"hhh\": \"green\",\n",
    "    \"qcd\": \"orange\",\n",
    "    \"tt\": \"blue\",\n",
    "    \"vv\": \"teal\",\n",
    "    \"vjets\": \"violet\",\n",
    "}\n",
    "for key in [\"hhh\", \"qcd\", \"tt\", \"vv\", \"hh4b\"]:\n",
    "    hep.histplot(\n",
    "        h[{\"class\": key}],\n",
    "        density=True,\n",
    "        lw=2,\n",
    "        ls=linestyles[key],\n",
    "        color=color_by_prob[key],\n",
    "    )\n",
    "    legend_elements.append(\n",
    "        Line2D([0], [0], color=color_by_prob[key], lw=2, label=key, ls=linestyles[key])\n",
    "    )\n",
    "ax.legend(handles=legend_elements)\n",
    "ax.set_ylabel(\"Density\")\n",
    "ax.set_yscale(\"log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session_assignment = onnxruntime.InferenceSession(\n",
    "    f\"{MAIN_DIR}/../data/spanet-inference/spanet_categorisation_v6.onnx\", sess_options\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_nodes_assignment = session_assignment.get_outputs()\n",
    "output_names_assignment = [node.name for node in output_nodes_assignment]\n",
    "output_values_assignment = session_assignment.run(output_names_assignment, input_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_names_assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_3bh0h = output_values_assignment[12][:, 1]\n",
    "prob_2bh1h = output_values_assignment[12][:, 2]\n",
    "prob_1bh2h = output_values_assignment[12][:, 3]\n",
    "prob_0bh3h = output_values_assignment[12][:, 4]\n",
    "prob_2bh0h = output_values_assignment[12][:, 5]\n",
    "prob_1bh1h = output_values_assignment[12][:, 6]\n",
    "prob_0bh2h = output_values_assignment[12][:, 7]\n",
    "prob_1bh0h = output_values_assignment[12][:, 8]\n",
    "prob_0bh1h = output_values_assignment[12][:, 9]\n",
    "prob_0bh0h = output_values_assignment[12][:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import awkward as ak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_maximas(assignment_prob):\n",
    "    assignment_prob_ak = ak.from_numpy(np.triu(assignment_prob[:][:, 0:njets, 0:njets]))\n",
    "    arr_flat = ak.flatten(assignment_prob_ak, axis=2)\n",
    "    max_indices = ak.argsort(arr_flat, ascending=False, axis=1).to_numpy()[:, :45]\n",
    "    max_values = arr_flat[max_indices]\n",
    "    return max_indices, max_values\n",
    "\n",
    "\n",
    "# h1 - h3 assignment probability\n",
    "index_h1, prob_h1 = get_maximas(output_values[0][:])\n",
    "index_h2, prob_h2 = get_maximas(output_values[1][:])\n",
    "index_h3, prob_h3 = get_maximas(output_values[2][:])\n",
    "\n",
    "# boosted h1 - h3 assignment probability\n",
    "h1Det = output_values[6][:]\n",
    "h2Det = output_values[7][:]\n",
    "h3Det = output_values[8][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bh1 = output_values[3][:]\n",
    "bh2 = output_values[4][:]\n",
    "bh3 = output_values[5][:]\n",
    "\n",
    "# boosted_higgs = find_boosted_higgs(bh1,bh2,bh3)\n",
    "bh1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bh1[0][10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bh1[0][11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bh1[0][12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "coffea",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

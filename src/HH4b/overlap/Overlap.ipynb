{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Study overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uproot\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from HH4b.utils import load_samples, format_columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load samples from Resolved group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../../../data/overlap/Main_PNet_MinDiag_w4j35_w2bj30_dHHjw30_withoutSyst_25April2024_2022_0L/mc/parts//GluGlutoHHto4B_kl-1p00_kt-1p00_c2-0p00_TuneCP5_13p6TeV_powheg-pythia8_tree.root\n",
      "Number of raw events:  2377354\n",
      "Number of resolved dataframe entries:  2377354\n",
      "Number of boosted dataframe entries:  571933\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/np/80b736zs2753ch8xq6lq33d80000gq/T/ipykernel_10991/3420084075.py:96: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"dHiggsDeltaRegMass\"] = np.sqrt(\n"
     ]
    }
   ],
   "source": [
    "dir = \"../../../../data/overlap/Main_PNet_MinDiag_w4j35_w2bj30_dHHjw30_withoutSyst_25April2024_2022_0L/mc/parts/\"\n",
    "samples = {\n",
    "    \"hh4b\": \"GluGlutoHHto4B_kl-1p00_kt-1p00_c2-0p00_TuneCP5_13p6TeV_powheg-pythia8_tree.root\",\n",
    "}\n",
    "\n",
    "ak8_columns = [\n",
    "    \"ak8_pt\",\n",
    "    \"ak8_eta\",\n",
    "    \"ak8_phi\",\n",
    "    \"ak8_jetId\",\n",
    "    \"ak8_msoftdrop\",\n",
    "    \"ak8_mass\",\n",
    "    \"ak8_tau3\",\n",
    "    \"ak8_tau2\",\n",
    "    \"ak8_Txbb\",\n",
    "    \"ak8_PQCDb\",\n",
    "    \"ak8_PQCDbb\",\n",
    "    \"ak8_PQCDothers\",\n",
    "    \"ak8_particleNet_mass\",\n",
    "]\n",
    "\n",
    "columns_to_load_resolved = [\n",
    "    \"passmetfilters\",\n",
    "    \"passjetvetomap\",\n",
    "    \"passTrig_HLT_QuadPFJet70_50_40_35_PFBTagParticleNet_2BTagSum0p65\",\n",
    "    \"passL1unprescaled_HLT_QuadPFJet70_50_40_35_PFBTagParticleNet_2BTagSum0p65\",\n",
    "    \"passTrigObjMatching_HLT_QuadPFJet70_50_40_35_PFBTagParticleNet_2BTagSum0p65\",\n",
    "    \"avgbdisc_twoldgbdiscjets\",\n",
    "    \"alljets_ht\",\n",
    "    \"dHH_NbtagM\",\n",
    "    \"dHH_H1_regmass\",\n",
    "    \"dHH_H2_regmass\",\n",
    "    \"event\",\n",
    "    \"lumiwgt\", # luminosity in fb 26.6717 for 2022EE\n",
    "    \"xsecWeight\", #  xsec * 1000 / sum('genEventSumw'), xsec in pb\n",
    "    \"genWeight\",\n",
    "    \"puWeight\",\n",
    "    \"trgSF_HLT_QuadPFJet70_50_40_35_PFBTagParticleNet_2BTagSum0p65_central\",\n",
    "    \"btagSF_central\",\n",
    "    \"passTrig_HLT_AK8PFJet250_SoftDropMass40_PFAK8ParticleNetBB0p35\",\n",
    "    \"passTrig_HLT_AK8PFJet425_SoftDropMass40\",\n",
    "]\n",
    "columns_to_load_boosted = columns_to_load_resolved + [\n",
    "    \"n_ak8\",\n",
    "    \"ak8_pt\",\n",
    "    \"ak8_eta\",\n",
    "    \"ak8_phi\",\n",
    "    \"ak8_jetId\",\n",
    "    \"ak8_msoftdrop\",\n",
    "    \"ak8_mass\",\n",
    "    \"ak8_tau3\",\n",
    "    \"ak8_tau2\",\n",
    "    \"ak8_Txbb\",\n",
    "    \"ak8_PQCDb\",\n",
    "    \"ak8_PQCDbb\",\n",
    "    \"ak8_PQCDothers\",\n",
    "    \"ak8_particleNet_mass\",\n",
    "    \"pass_resolved_skim\", # trigger & >=4 jets with some pt cuts and >= 2 bjets above 30 GeV\n",
    "    \"pass_boosted_skim\", # trigger & >=2  tight AK8 jets with pT > 250 GeV and |eta|<2.4\n",
    "]\n",
    "\n",
    "\"\"\"\n",
    "    2b: dHH_NbtagM == 2\n",
    "    4b: dHH_NbtagM == 4\n",
    "    asr_4b: ASR_4b\n",
    "    asr_2b: ASR_2b\n",
    "    acr_4b: ACR_4b\n",
    "    acr_2b: ACR_2b\n",
    "    vsr_4b: VSR_4b\n",
    "    vsr_2b: VSR_2b\n",
    "    vcr_4b: VCR_4b\n",
    "    vcr_2b: VCR_2b\n",
    "\"\"\"\n",
    "\n",
    "def get_resolved_masks(df):\n",
    "    regions = {}\n",
    "    regions[\"RES\"] = (\n",
    "        (df[\"passTrig_HLT_QuadPFJet70_50_40_35_PFBTagParticleNet_2BTagSum0p65\"]) &\n",
    "        (df[\"passL1unprescaled_HLT_QuadPFJet70_50_40_35_PFBTagParticleNet_2BTagSum0p65\"]) &\n",
    "        (df[\"passTrigObjMatching_HLT_QuadPFJet70_50_40_35_PFBTagParticleNet_2BTagSum0p65\"]) &\n",
    "        (df[\"passmetfilters\"]) &\n",
    "        (df[\"passjetvetomap\"]) &\n",
    "        (df[\"avgbdisc_twoldgbdiscjets\"] > 0.65) &\n",
    "        (df[\"alljets_ht\"] > 0)\n",
    "    )\n",
    "\n",
    "    # Calculate variables\n",
    "    #df['AR_dHM'] = np.sqrt((df['dHH_H1_regmass'] - 125)**2 + (df['dHH_H2_regmass'] - 120)**2)\n",
    "    #df['VR_dHM'] = np.sqrt((df['dHH_H1_regmass'] - 185)**2 + (df['dHH_H2_regmass'] - 182)**2)\n",
    "    # Define additional regions based on these variables\n",
    "    #df['ASR_4b'] = (df['AR_dHM'] < 30) & (df['dHH_NbtagM'] == 4)\n",
    "    #df['ACR_4b'] = (df['AR_dHM'] >= 30) & (df['AR_dHM'] < 55) & (df['dHH_NbtagM'] == 4)\n",
    "    #df['VSR_4b'] = (df['VR_dHM'] < 30) & (df['dHH_NbtagM'] == 4)\n",
    "    #df['VCR_4b'] = (df['VR_dHM'] >= 30) & (df['VR_dHM'] < 55) & (df['dHH_NbtagM'] == 4)\n",
    "\n",
    "    df[\"dHiggsDeltaRegMass\"] = np.sqrt(\n",
    "        ((df[\"dHH_H1_regmass\"]-125.0)*(df[\"dHH_H1_regmass\"]-125.0)) + \n",
    "        ((df[\"dHH_H2_regmass\"]-120.0)*(df[\"dHH_H2_regmass\"]-120.0))\n",
    "    )\n",
    "\n",
    "    regions = {\n",
    "        **regions,\n",
    "        \"RES4b\": (regions[\"RES\"] & (df[\"dHH_NbtagM\"] == 4)),\n",
    "        \"RES4bSR\": (regions[\"RES\"] & (df[\"dHiggsDeltaRegMass\"] < 30.) & (df[\"dHH_NbtagM\"] == 4)),\n",
    "    }\n",
    "\n",
    "    return regions\n",
    "\n",
    "for sample, sample_file in samples.items():\n",
    "    print(f\"{dir}/{sample_file}\")\n",
    "    tree = uproot.open(f\"{dir}/{sample_file}:Events\")         \n",
    "    print(\"Number of raw events: \", len(tree.arrays([\"event\"])[\"event\"]))\n",
    "    #########################################\n",
    "    # Load resolved data as a pandas DataFrame\n",
    "    df = tree.arrays(columns_to_load_resolved, library=\"pd\")\n",
    "    print(\"Number of resolved dataframe entries: \",len(df[\"event\"]))\n",
    "\n",
    "    # Weights\n",
    "    df['resolved_weight'] = df['lumiwgt'] * df['xsecWeight'] * df['genWeight'] * df[\"puWeight\"] * df['trgSF_HLT_QuadPFJet70_50_40_35_PFBTagParticleNet_2BTagSum0p65_central'] * df[\"btagSF_central\"]\n",
    "    \n",
    "    # Define resolved regions\n",
    "    regions = get_resolved_masks(df)\n",
    "\n",
    "    # Get resolved yields and counts\n",
    "    resolved_yields = {region: [np.sum(df['resolved_weight'][region_mask])] for region, region_mask in regions.items()}\n",
    "    resolved_counts = {region: int(df['event'][region_mask].shape[0]) for region, region_mask in regions.items()}\n",
    "\n",
    "    #########################################\n",
    "    # Load boosted data as a pandas DataFrame\n",
    "    df_b = tree.arrays(columns_to_load_boosted, library=\"pd\")\n",
    "    # Ask for at least 2 ak8 jets in boosted pandas dataframe\n",
    "    df_b = df_b[\n",
    "        (df_b[\"n_ak8\"]>=2) &\n",
    "        (df_b[\"passmetfilters\"]) & (df_b[\"passjetvetomap\"]) &\n",
    "        ( (df_b[\"passTrig_HLT_AK8PFJet250_SoftDropMass40_PFAK8ParticleNetBB0p35\"]) |\n",
    "           (df_b[\"passTrig_HLT_AK8PFJet425_SoftDropMass40\"]) )\n",
    "    ].copy()\n",
    "    print(\"Number of boosted dataframe entries: \",len(df_b[\"event\"]))\n",
    "\n",
    "    # Add weights\n",
    "    df_b[\"boosted_weight\"] = df_b['lumiwgt'] * df_b['xsecWeight'] * df_b['genWeight'] * df_b[\"puWeight\"]\n",
    "    df_b[\"resolved_weight\"] = df_b['lumiwgt'] * df_b['xsecWeight'] * df_b['genWeight'] * df_b[\"puWeight\"] * df_b['trgSF_HLT_QuadPFJet70_50_40_35_PFBTagParticleNet_2BTagSum0p65_central'] * df_b[\"btagSF_central\"]\n",
    "\n",
    "    # Order jets by fatjet Xbb\n",
    "    df_ak8 = df_b.reset_index()\n",
    "    df_ak8 = df_ak8.sort_values(by=['entry', 'ak8_Txbb'], ascending=[True, False]).set_index(['entry', 'subentry'])\n",
    "    subindex = df_ak8.sort_index().index.get_level_values(1)\n",
    "    df_ak8 = df_ak8.reset_index()\n",
    "    df_ak8['subentry'] = subindex\n",
    "    df_ak8 = df_ak8.set_index(['entry', 'subentry'])\n",
    "\n",
    "    # For boosted, yields must be obtained for one of the entries\n",
    "    jet0 = df_ak8.query(\"subentry == 0\")\n",
    "    jet1 = df_ak8.query(\"subentry == 1\")\n",
    "\n",
    "    # Define resolved regions for this dataframe\n",
    "    resolved_regions = {\n",
    "        **{f\"BST-{region}\": region_mask for region, region_mask in get_resolved_masks(jet0).items()}\n",
    "    }\n",
    "\n",
    "    # NOTE!!!: you must use .to_numpy() to get the masks with jet0 otherwise you cannot do an OR\n",
    "    boosted_regions = {\n",
    "        \"BST30060-X0bb08\": (\n",
    "            (jet0['ak8_pt'] >= 300).to_numpy() & (jet1['ak8_pt'] >= 300).to_numpy() &\n",
    "            (jet0['ak8_msoftdrop'] >= 60).to_numpy() & (jet1['ak8_msoftdrop'] >= 60).to_numpy() &\n",
    "            (jet0['ak8_Txbb'] >= 0.8).to_numpy()\n",
    "        ),\n",
    "        \"BST25060-X0bb08\": (\n",
    "            (jet0['ak8_pt'] >= 250).to_numpy() & (jet1['ak8_pt'] >= 250).to_numpy() &\n",
    "            (jet0['ak8_msoftdrop'] >= 60).to_numpy() & (jet1['ak8_msoftdrop'] >= 60).to_numpy() &\n",
    "            (jet0['ak8_Txbb'] >= 0.8).to_numpy()\n",
    "        ),\n",
    "    }\n",
    "\n",
    "\n",
    "    # compute overlap\n",
    "    overlap_regions = {\n",
    "        \"RES4b-BST30060-X0bb08\": (resolved_regions[\"BST-RES4b\"] & boosted_regions[\"BST30060-X0bb08\"]),\n",
    "    }\n",
    "\n",
    "    boosted_yields = {region: [np.sum(jet0['boosted_weight'][region_mask])] for region, region_mask in boosted_regions.items()}\n",
    "    boosted_counts = {region: int(jet0['event'][region_mask].shape[0]) for region, region_mask in boosted_regions.items()}\n",
    "\n",
    "    overlap_yields = {region: [np.sum(jet0['resolved_weight'][region_mask])] for region, region_mask in overlap_regions.items()}\n",
    "    overlap_counts = {region: int(jet0['event'][region_mask].shape[0]) for region, region_mask in overlap_regions.items()}\n",
    "    \n",
    "    # make yields and  counts dataframe\n",
    "    df_yields = pd.DataFrame({\n",
    "        \"sample\": key,\n",
    "        **resolved_yields,\n",
    "        **boosted_yields,\n",
    "        **overlap_yields,\n",
    "    })\n",
    "    \n",
    "    df_counts = pd.DataFrame({\n",
    "        \"sample\": key,\n",
    "        \"all\": int(df['event'].shape[0]),\n",
    "        **resolved_counts,\n",
    "        **boosted_counts,\n",
    "        **overlap_counts,\n",
    "    }, index=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|    | sample           |     RES |   RES4b |   RES4bSR |   BST30060 |   RES4b-BST30060 |\n",
      "|---:|:-----------------|--------:|--------:|----------:|-----------:|-----------------:|\n",
      "|  0 | hh4b_v12_private | 68.2276 | 19.9474 |   13.2769 |     3.0976 |          1.22037 |\n"
     ]
    }
   ],
   "source": [
    "print(df_yields.to_markdown())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|    | sample           |     all |     RES |   RES4b |   RES4bSR |   BST30060 |   RES4b-BST30060 |\n",
      "|---:|:-----------------|--------:|--------:|--------:|----------:|-----------:|-----------------:|\n",
      "|  0 | hh4b_v12_private | 2377354 | 1741977 |  559983 |    385524 |      85355 |            39097 |\n"
     ]
    }
   ],
   "source": [
    "print(df_counts.to_markdown())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.any(df['genWeight'] < 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross check yield with boosted ntuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../../../data/skimmer/24Apr23LegacyLowerThresholds_v12_private_signal/\n",
      "Loaded GluGlutoHHto4B_kl-1p00_kt-1p00_c2-0p00_TuneCP5_13p6TeV: 169191 entries\n",
      "hh4b_v12_private\n",
      "2.935299445451215 82763\n"
     ]
    }
   ],
   "source": [
    "year = \"2022EE\"\n",
    "\n",
    "sample_dirs = {\n",
    "    f\"../../../../data/skimmer/24Apr23LegacyLowerThresholds_v12_private_signal/\": {\n",
    "        \"hh4b_v12_private\": [\"GluGlutoHHto4B_kl-1p00_kt-1p00_c2-0p00_TuneCP5_13p6TeV\"],\n",
    "    },\n",
    "}\n",
    "\n",
    "load_columns = [\n",
    "    (\"bbFatJetPNetTXbbLegacy\", 2),\n",
    "    (\"bbFatJetPNetMassLegacy\", 2),\n",
    "    (\"bbFatJetPNetTXbb\", 2),\n",
    "    (\"bbFatJetPNetMass\", 2),  \n",
    "    (\"bbFatJetMsd\", 2), \n",
    "    (\"bbFatJetPt\", 2),\n",
    "    (\"weight\", 1),    \n",
    "    (\"trigger_sf\", 1),\n",
    "    (\"AK8PFJet250_SoftDropMass40_PFAK8ParticleNetBB0p35\", 1),\n",
    "    (\"AK8PFJet425_SoftDropMass40\", 1),\n",
    "]\n",
    "\n",
    "events_dict = {}\n",
    "for input_dir, samples_dict in sample_dirs.items():\n",
    "    print(input_dir)\n",
    "    events_dict = {\n",
    "        **events_dict,\n",
    "        # this function will load files (only the columns selected), apply filters and compute a weight per event\n",
    "        **load_samples(\n",
    "            input_dir,\n",
    "            samples_dict,\n",
    "            year,\n",
    "            variations=False,\n",
    "            columns=format_columns(load_columns),\n",
    "            reorder_legacy_txbb=True,\n",
    "        ),\n",
    "    }\n",
    "\n",
    "\n",
    "for key in [\"hh4b_v12_private\"]:\n",
    "    print(key)\n",
    "    events = events_dict[key]\n",
    "\n",
    "    boosted_mask = (\n",
    "        (events[\"bbFatJetPt\"][0] >300) &\n",
    "        (events[\"bbFatJetPt\"][1] >300) &\n",
    "        (events[\"bbFatJetPNetTXbb\"][0] >0.8) &\n",
    "        (events[\"bbFatJetMsd\"][0] >60) &\n",
    "        (events[\"bbFatJetMsd\"][1] >60) &\n",
    "        np.any([events[\"AK8PFJet250_SoftDropMass40_PFAK8ParticleNetBB0p35\"], events[\"AK8PFJet425_SoftDropMass40\"]])\n",
    "    )\n",
    "    print(np.sum(events[\"finalWeight\"][boosted_mask]), len(events[\"finalWeight\"][boosted_mask]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>505.399161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>155.528530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>134.532464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-399.780456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>532.347110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169186</th>\n",
       "      <td>-219.166446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169187</th>\n",
       "      <td>399.780456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169188</th>\n",
       "      <td>505.399161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169189</th>\n",
       "      <td>437.040691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169190</th>\n",
       "      <td>437.040691</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>169191 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0\n",
       "0       505.399161\n",
       "1       155.528530\n",
       "2       134.532464\n",
       "3      -399.780456\n",
       "4       532.347110\n",
       "...            ...\n",
       "169186 -219.166446\n",
       "169187  399.780456\n",
       "169188  505.399161\n",
       "169189  437.040691\n",
       "169190  437.040691\n",
       "\n",
       "[169191 rows x 1 columns]"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "events['weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "coffea",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

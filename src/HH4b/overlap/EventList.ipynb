{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# automatically reloads imported files on edits\n",
    "from __future__ import annotations\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from argparse import Namespace\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from HH4b.postprocessing.PostProcess import load_process_run3_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = \"24Sep25_v12v2_private_signal\"\n",
    "args = Namespace(\n",
    "    templates_tag=\"24June27\",\n",
    "    data_dir=\"/ceph/cms/store/user/cmantill/bbbb/skimmer/\",\n",
    "    tag=data_folder,\n",
    "    years=[\"2022\"],\n",
    "    training_years=None,\n",
    "    mass=\"H2PNetMass\",\n",
    "    bdt_model=\"25Feb5_v13_glopartv2_rawmass\",\n",
    "    bdt_config=\"v13_glopartv2\",\n",
    "    txbb_wps=[0.945, 0.75],\n",
    "    bdt_wps=[0.935, 0.67, 0.03],\n",
    "    method=\"sideband\",\n",
    "    vbf_txbb_wp=0.81,\n",
    "    vbf_bdt_wp=0.988,\n",
    "    sig_keys=[\"hh4b\", \"vbfhh4b\"],\n",
    "    pt_first=300,\n",
    "    pt_second=250,\n",
    "    bdt_roc=False,\n",
    "    control_plots=False,\n",
    "    fom_scan=False,\n",
    "    fom_scan_bin1=True,\n",
    "    fom_scan_bin2=True,\n",
    "    fom_scan_vbf=False,\n",
    "    templates=False,\n",
    "    legacy=True,\n",
    "    vbf=True,\n",
    "    vbf_priority=False,\n",
    "    weight_ttbar_bdt=1,\n",
    "    blind=True,\n",
    "    txbb=\"glopart-v2\",\n",
    "    correct_vbf_bdt_shape=True,\n",
    "    bdt_disc=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bdt_training_keys = [\"qcd\", \"vbfhh4b-k2v0\", \"hh4b\", \"ttbar\"]\n",
    "mass_window = np.array([105, 150])\n",
    "years = [\"2022\", \"2022EE\", \"2023\", \"2023BPix\"]\n",
    "\n",
    "ev_dicts = []\n",
    "for year in years:\n",
    "    ev_dict, _ = load_process_run3_samples(\n",
    "        args,\n",
    "        year=year,\n",
    "        bdt_training_keys=bdt_training_keys,\n",
    "        control_plots=False,\n",
    "        plot_dir=\"plot_dir\",\n",
    "        mass_window=mass_window,\n",
    "    )\n",
    "    ev_dicts.append((year, ev_dict))\n",
    "\n",
    "\"\"\"\n",
    "python3 PostProcess.py --templates-tag 24June27 --tag 24May24_v12_private_signal --mass H2PNetMass --legacy --bdt-config 24May31_lr_0p02_md_8_AK4Away --bdt-model 24May31_lr_0p02_md_8_AK4Away --txbb-wps 0.975 0.92 --bdt-wps 0.98 0.88 0.03 --vbf-txbb-wp 0.95 --vbf-bdt-wp 0.98 --no-bdt-roc --no-fom-scan --no-fom-scan-bin2 --no-fom-scan-bin1 --data-dir /ceph/cms/store/user/cmantill/bbbb/skimmer/ --method abcd --no-vbf-priority --vbf --no-fom-scan-vbf --pt-second 250 --templates --years 2022 --sig-keys hh4b vbfhh4b\n",
    "\"\"\"\n",
    "\n",
    "# save as root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import uproot\n",
    "\n",
    "# select columns to extract for eventlist\n",
    "eventlist_dict = [\n",
    "    \"event\",\n",
    "    \"bdt_score\",\n",
    "    \"bdt_score_vbf\",\n",
    "    \"H2TXbb\",\n",
    "    \"H2Msd\",\n",
    "    \"run\",\n",
    "    \"Category\",\n",
    "    \"H2PNetMass\",\n",
    "    \"luminosityBlock\",\n",
    "]\n",
    "keys_to_save = [\"hh4b\", \"vbfhh4b\", \"data\"]\n",
    "\n",
    "# Ensure the eventlist folder exists\n",
    "eventlist_folder = Path(\"eventlist_files_2025May15\")\n",
    "eventlist_folder.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# TODO: check how data is loaded (should reference the folder names somewhere)\n",
    "# TODO: print eventlist_dict to see if you can get keys \"data\" and vbfhh4b\n",
    "# Loop over all years and save event lists for each year in separate root files\n",
    "for year, ev_dict in ev_dicts:\n",
    "    for key in ev_dict:\n",
    "        if \"data\" in key or \"hh4b\" in key or \"vbfhh4b\" in key:\n",
    "            print(key)\n",
    "            tree_df = ev_dict[key]\n",
    "            event_list = tree_df[eventlist_dict]\n",
    "            array_to_save = {col: event_list[col].to_numpy() for col in event_list.columns}\n",
    "\n",
    "            # Define the ROOT file path\n",
    "            file_path = f\"{eventlist_folder}/eventlist_boostedHH4b_{year}.root\"\n",
    "            file_path = Path(file_path)\n",
    "\n",
    "            # Check if the ROOT file already exists\n",
    "            if file_path.exists():\n",
    "                # File exists, use update mode to append the new tree\n",
    "                with uproot.update(file_path) as file:\n",
    "                    file[key] = array_to_save  # Append new tree\n",
    "            else:\n",
    "                # File doesn't exist, create a new one\n",
    "                with uproot.recreate(file_path) as file:\n",
    "                    file[key] = array_to_save  # Create the first tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Double-check file contents\n",
    "years = [\"2022\", \"2022EE\", \"2023\", \"2023BPix\"]\n",
    "dfs_from_root = {}\n",
    "\n",
    "for year in years:\n",
    "    # Define the ROOT file path\n",
    "    file_path = f\"{eventlist_folder}/eventlist_boostedHH4b_{year}.root\"\n",
    "\n",
    "    with uproot.open(file_path) as file:\n",
    "        for key in file:\n",
    "            tree = file[key]\n",
    "            arrays = tree.arrays(library=\"np\")\n",
    "            event_df = pd.DataFrame(arrays)\n",
    "\n",
    "            # Make dict\n",
    "            dfs_from_root[(year, key)] = event_df\n",
    "\n",
    "# test_df = dfs_from_root[\"2022\"] - dfs_from_root[\"2022EE\"]\n",
    "# print(test_df)\n",
    "# Display df\n",
    "for (year, key), event_df in dfs_from_root.items():\n",
    "    print(f\"DataFrame for year {year}, tree: '{key}':\\n{event_df}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hh4b",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

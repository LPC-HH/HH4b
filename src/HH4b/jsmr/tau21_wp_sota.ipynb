{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d3d5c3b-e008-47d9-9b72-0501b407b89f",
   "metadata": {},
   "source": [
    "# Ratio Plot after JSMR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b003fdb7-5d91-4742-b23e-099459ad23b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import mplhep as hep\n",
    "import vector\n",
    "\n",
    "import HH4b.utils as utils\n",
    "from HH4b.utils import ShapeVar\n",
    "import HH4b.plotting as plotting\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a73db755-debc-4afa-a1fe-512163a2d9af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_vector(events: pd.DataFrame, obj: str):\n",
    "    \"\"\"Create a ``vector`` object from the columns of the dataframe\"\"\"\n",
    "    mstring = \"PNetMass\" if obj == \"ak8FatJet\" else \"Mass\"\n",
    "\n",
    "    return vector.array(\n",
    "        {\n",
    "            \"pt\": events[f\"{obj}Pt\"],\n",
    "            \"phi\": events[f\"{obj}Phi\"],\n",
    "            \"eta\": events[f\"{obj}Eta\"],\n",
    "            \"M\": events[f\"{obj}{mstring}\"],\n",
    "            \"tau21\":events[\"ak8FatJetTau2OverTau1\"]\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdb4d83a-fdec-45a0-8ce4-c716491f0499",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa327d0d-a58d-413e-b673-a3d94f5e9494",
   "metadata": {},
   "outputs": [],
   "source": [
    "year = \"2022EE\"  #\n",
    "dir_name = \"24Apr22_v12_signal\"\n",
    "path_to_dir = f\"/eos/uscms/store/user/haoyang/bbbb/ttSkimmer/{dir_name}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "deabb526-29f4-4163-9feb-4131d6b9e538",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded TTto2L2Nu                                         : 808779 entries\n",
      "Loaded TTto4Q                                            : 12829 entries\n",
      "Loaded TTtoLNu2Q                                         : 3477992 entries\n",
      "Keys in events_dict\n",
      "('weight', 0)\n",
      "('ak8FatJetTau2OverTau1', 0)\n",
      "('ak8FatJetTau2OverTau1', 1)\n",
      "('ak8FatJetMsd', 0)\n",
      "('ak8FatJetMsd', 1)\n",
      "('ak8FatJetPNetMass', 0)\n",
      "('ak8FatJetPNetMass', 1)\n",
      "('ak8FatJetEta', 0)\n",
      "('ak8FatJetEta', 1)\n",
      "('ak8FatJetPhi', 0)\n",
      "('ak8FatJetPhi', 1)\n",
      "('ak8FatJetPt', 0)\n",
      "('ak8FatJetPt', 1)\n",
      "('bbFatJetTopMatch', 0)\n",
      "('bbFatJetTopMatch', 1)\n",
      "('bbFatJetNumQMatchedTop1', 0)\n",
      "('bbFatJetNumQMatchedTop1', 1)\n",
      "('bbFatJetNumQMatchedTop2', 0)\n",
      "('bbFatJetNumQMatchedTop2', 1)\n",
      "('bbFatJetNumBMatchedTop1', 0)\n",
      "('bbFatJetNumBMatchedTop1', 1)\n",
      "('bbFatJetNumBMatchedTop2', 0)\n",
      "('bbFatJetNumBMatchedTop2', 1)\n",
      "('weight_noxsec', 0)\n",
      "('weight_nonorm', '')\n",
      "('finalWeight', '')\n"
     ]
    }
   ],
   "source": [
    "# Load your dataset\n",
    "samples = {\n",
    "    \"tt\": [\"TTto2L2Nu\", \"TTto4Q\", \"TTtoLNu2Q\"],\n",
    "}\n",
    "\n",
    "dirs = {path_to_dir: samples}\n",
    "\n",
    "filters = None\n",
    "\n",
    "# columns to load\n",
    "# the parquet files are too big so we can only load a few columns at a time without consumming much memory\n",
    "load_columns = [\n",
    "    (\"weight\", 1),\n",
    "    (\"ak8FatJetTau2OverTau1\", 2),\n",
    "    (\"ak8FatJetMsd\", 2),\n",
    "    (\"ak8FatJetPNetMass\", 2),\n",
    "    (\"ak8FatJetEta\", 2),\n",
    "    (\"ak8FatJetPhi\", 2),\n",
    "    (\"ak8FatJetPt\", 2),\n",
    "    (\"bbFatJetTopMatch\", 2),\n",
    "    ('bbFatJetNumQMatchedTop1', 2),\n",
    "    ('bbFatJetNumQMatchedTop2', 2),\n",
    "    ('bbFatJetNumBMatchedTop1', 2),\n",
    "    ('bbFatJetNumBMatchedTop2', 2),\n",
    "    (\"finalWeight\", 0),\n",
    "]\n",
    "# reformat into (\"column name\", \"idx\") format for reading multiindex columns\n",
    "columns = []\n",
    "for key, num_columns in load_columns:\n",
    "    for i in range(num_columns):\n",
    "        columns.append(f\"('{key}', '{i}')\")\n",
    "\n",
    "\n",
    "events_dict = {}\n",
    "for input_dir, samples in dirs.items():\n",
    "    events_dict = {\n",
    "        **events_dict,\n",
    "        # this function will load files (only the columns selected), apply filters and compute a weight per event\n",
    "        **utils.load_samples(input_dir, samples, year, filters=filters, columns=columns, reorder_legacy_txbb=False),\n",
    "    }\n",
    "\n",
    "samples_loaded = list(events_dict.keys())\n",
    "keys_loaded = list(events_dict[samples_loaded[0]].keys())\n",
    "print(f\"Keys in events_dict\")\n",
    "for i in keys_loaded:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bef5d1d8-b783-4bee-9546-e23adfa0811a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ArrowInvalid",
     "evalue": "No match for FieldRef.Name(('weight_noxsec', '0')) in ('run', '0'): uint32\n('event', '0'): uint64\n('luminosityBlock', '0'): uint32\n('MET_pt', '0'): float\n('ak8FatJetEta', '0'): double\n('ak8FatJetEta', '1'): double\n('ak8FatJetEta', '2'): double\n('ak8FatJetPhi', '0'): double\n('ak8FatJetPhi', '1'): double\n('ak8FatJetPhi', '2'): double\n('ak8FatJetMass', '0'): double\n('ak8FatJetMass', '1'): double\n('ak8FatJetMass', '2'): double\n('ak8FatJetPt', '0'): double\n('ak8FatJetPt', '1'): double\n('ak8FatJetPt', '2'): double\n('ak8FatJetMsd', '0'): double\n('ak8FatJetMsd', '1'): double\n('ak8FatJetMsd', '2'): double\n('ak8FatJetPNetXbb', '0'): double\n('ak8FatJetPNetXbb', '1'): double\n('ak8FatJetPNetXbb', '2'): double\n('ak8FatJetPNetXjj', '0'): double\n('ak8FatJetPNetXjj', '1'): double\n('ak8FatJetPNetXjj', '2'): double\n('ak8FatJetPNetQCD', '0'): double\n('ak8FatJetPNetQCD', '1'): double\n('ak8FatJetPNetQCD', '2'): double\n('ak8FatJetPNetMass', '0'): double\n('ak8FatJetPNetMass', '1'): double\n('ak8FatJetPNetMass', '2'): double\n('ak8FatJetPNetMassRaw', '0'): double\n('ak8FatJetPNetMassRaw', '1'): double\n('ak8FatJetPNetMassRaw', '2'): double\n('ak8FatJetTau2OverTau1', '0'): double\n('ak8FatJetTau2OverTau1', '1'): double\n('ak8FatJetTau2OverTau1', '2'): double\n('ak8FatJetTau3OverTau2', '0'): double\n('ak8FatJetTau3OverTau2', '1'): double\n('ak8FatJetTau3OverTau2', '2'): double\n('ak8FatJetrawFactor', '0'): double\n('ak8FatJetrawFactor', '1'): double\n('ak8FatJetrawFactor', '2'): double\n('leptonEta', '0'): double\n('leptonEta', '1'): double\n('leptonPhi', '0'): double\n('leptonPhi', '1'): double\n('leptonMass', '0'): double\n('leptonMass', '1'): double\n('leptonPt', '0'): double\n('leptonPt', '1'): double\n('leptonId', '0'): int64\n('leptonId', '1'): int64\n('weight', '0'): double\n__fragment_index: int32\n__batch_index: int32\n__last_in_fragment: bool\n__filename: string",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mArrowInvalid\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 38\u001b[0m\n\u001b[1;32m     33\u001b[0m events_dict_data \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m input_dir, samples \u001b[38;5;129;01min\u001b[39;00m dirs\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m     35\u001b[0m     events_dict_data \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     36\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mevents_dict,\n\u001b[1;32m     37\u001b[0m         \u001b[38;5;66;03m# this function will load files (only the columns selected), apply filters and compute a weight per event\u001b[39;00m\n\u001b[0;32m---> 38\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_samples\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msamples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43myear\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreorder_legacy_txbb\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m,\n\u001b[1;32m     39\u001b[0m     }\n\u001b[1;32m     41\u001b[0m samples_loaded \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(events_dict\u001b[38;5;241m.\u001b[39mkeys())\n\u001b[1;32m     42\u001b[0m keys_loaded \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(events_dict[samples_loaded[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39mkeys())\n",
      "File \u001b[0;32m/uscms_data/d3/haoyang/HH4b_LPC/src/HH4b/utils.py:336\u001b[0m, in \u001b[0;36mload_samples\u001b[0;34m(data_dir, samples, year, filters, columns, variations, weight_shifts, reorder_legacy_txbb)\u001b[0m\n\u001b[1;32m    333\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m    335\u001b[0m \u001b[38;5;66;03m# print(f\"Loading {sample}\")\u001b[39;00m\n\u001b[0;32m--> 336\u001b[0m events \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_parquet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparquet_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mload_columns\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    338\u001b[0m \u001b[38;5;66;03m# no events?\u001b[39;00m\n\u001b[1;32m    339\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(events):\n",
      "File \u001b[0;32m~/nobackup/mambaforge/envs/hh4b/lib/python3.9/site-packages/pandas/io/parquet.py:509\u001b[0m, in \u001b[0;36mread_parquet\u001b[0;34m(path, engine, columns, storage_options, use_nullable_dtypes, dtype_backend, **kwargs)\u001b[0m\n\u001b[1;32m    506\u001b[0m     use_nullable_dtypes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    507\u001b[0m check_dtype_backend(dtype_backend)\n\u001b[0;32m--> 509\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimpl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    510\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    511\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    512\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    513\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_nullable_dtypes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_nullable_dtypes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    514\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype_backend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    515\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    516\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/nobackup/mambaforge/envs/hh4b/lib/python3.9/site-packages/pandas/io/parquet.py:227\u001b[0m, in \u001b[0;36mPyArrowImpl.read\u001b[0;34m(self, path, columns, use_nullable_dtypes, dtype_backend, storage_options, **kwargs)\u001b[0m\n\u001b[1;32m    220\u001b[0m path_or_handle, handles, kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfilesystem\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m _get_path_or_handle(\n\u001b[1;32m    221\u001b[0m     path,\n\u001b[1;32m    222\u001b[0m     kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfilesystem\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m    223\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39mstorage_options,\n\u001b[1;32m    224\u001b[0m     mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    225\u001b[0m )\n\u001b[1;32m    226\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 227\u001b[0m     pa_table \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparquet\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_table\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    228\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath_or_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    229\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    230\u001b[0m     result \u001b[38;5;241m=\u001b[39m pa_table\u001b[38;5;241m.\u001b[39mto_pandas(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mto_pandas_kwargs)\n\u001b[1;32m    232\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m manager \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/nobackup/mambaforge/envs/hh4b/lib/python3.9/site-packages/pyarrow/parquet/core.py:2986\u001b[0m, in \u001b[0;36mread_table\u001b[0;34m(source, columns, use_threads, metadata, schema, use_pandas_metadata, read_dictionary, memory_map, buffer_size, partitioning, filesystem, filters, use_legacy_dataset, ignore_prefixes, pre_buffer, coerce_int96_timestamp_unit, decryption_properties, thrift_string_size_limit, thrift_container_size_limit)\u001b[0m\n\u001b[1;32m   2975\u001b[0m         \u001b[38;5;66;03m# TODO test that source is not a directory or a list\u001b[39;00m\n\u001b[1;32m   2976\u001b[0m         dataset \u001b[38;5;241m=\u001b[39m ParquetFile(\n\u001b[1;32m   2977\u001b[0m             source, metadata\u001b[38;5;241m=\u001b[39mmetadata, read_dictionary\u001b[38;5;241m=\u001b[39mread_dictionary,\n\u001b[1;32m   2978\u001b[0m             memory_map\u001b[38;5;241m=\u001b[39mmemory_map, buffer_size\u001b[38;5;241m=\u001b[39mbuffer_size,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2983\u001b[0m             thrift_container_size_limit\u001b[38;5;241m=\u001b[39mthrift_container_size_limit,\n\u001b[1;32m   2984\u001b[0m         )\n\u001b[0;32m-> 2986\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_threads\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_threads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2987\u001b[0m \u001b[43m                        \u001b[49m\u001b[43muse_pandas_metadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_pandas_metadata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2989\u001b[0m warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   2990\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPassing \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muse_legacy_dataset=True\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m to get the legacy behaviour is \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2991\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdeprecated as of pyarrow 8.0.0, and the legacy implementation will \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2992\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbe removed in a future version.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   2993\u001b[0m     \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m   2995\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ignore_prefixes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/nobackup/mambaforge/envs/hh4b/lib/python3.9/site-packages/pyarrow/parquet/core.py:2614\u001b[0m, in \u001b[0;36m_ParquetDatasetV2.read\u001b[0;34m(self, columns, use_threads, use_pandas_metadata)\u001b[0m\n\u001b[1;32m   2606\u001b[0m         index_columns \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m   2607\u001b[0m             col \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m _get_pandas_index_columns(metadata)\n\u001b[1;32m   2608\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(col, \u001b[38;5;28mdict\u001b[39m)\n\u001b[1;32m   2609\u001b[0m         ]\n\u001b[1;32m   2610\u001b[0m         columns \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   2611\u001b[0m             \u001b[38;5;28mlist\u001b[39m(columns) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m(index_columns) \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mset\u001b[39m(columns))\n\u001b[1;32m   2612\u001b[0m         )\n\u001b[0;32m-> 2614\u001b[0m table \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_table\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2615\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mfilter\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_filter_expression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2616\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_threads\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_threads\u001b[49m\n\u001b[1;32m   2617\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2619\u001b[0m \u001b[38;5;66;03m# if use_pandas_metadata, restore the pandas metadata (which gets\u001b[39;00m\n\u001b[1;32m   2620\u001b[0m \u001b[38;5;66;03m# lost if doing a specific `columns` selection in to_table)\u001b[39;00m\n\u001b[1;32m   2621\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_pandas_metadata:\n",
      "File \u001b[0;32m~/nobackup/mambaforge/envs/hh4b/lib/python3.9/site-packages/pyarrow/_dataset.pyx:537\u001b[0m, in \u001b[0;36mpyarrow._dataset.Dataset.to_table\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/nobackup/mambaforge/envs/hh4b/lib/python3.9/site-packages/pyarrow/_dataset.pyx:383\u001b[0m, in \u001b[0;36mpyarrow._dataset.Dataset.scanner\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/nobackup/mambaforge/envs/hh4b/lib/python3.9/site-packages/pyarrow/_dataset.pyx:3202\u001b[0m, in \u001b[0;36mpyarrow._dataset.Scanner.from_dataset\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/nobackup/mambaforge/envs/hh4b/lib/python3.9/site-packages/pyarrow/_dataset.pyx:3120\u001b[0m, in \u001b[0;36mpyarrow._dataset.Scanner._make_scan_options\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/nobackup/mambaforge/envs/hh4b/lib/python3.9/site-packages/pyarrow/_dataset.pyx:3071\u001b[0m, in \u001b[0;36mpyarrow._dataset._populate_builder\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/nobackup/mambaforge/envs/hh4b/lib/python3.9/site-packages/pyarrow/error.pxi:100\u001b[0m, in \u001b[0;36mpyarrow.lib.check_status\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mArrowInvalid\u001b[0m: No match for FieldRef.Name(('weight_noxsec', '0')) in ('run', '0'): uint32\n('event', '0'): uint64\n('luminosityBlock', '0'): uint32\n('MET_pt', '0'): float\n('ak8FatJetEta', '0'): double\n('ak8FatJetEta', '1'): double\n('ak8FatJetEta', '2'): double\n('ak8FatJetPhi', '0'): double\n('ak8FatJetPhi', '1'): double\n('ak8FatJetPhi', '2'): double\n('ak8FatJetMass', '0'): double\n('ak8FatJetMass', '1'): double\n('ak8FatJetMass', '2'): double\n('ak8FatJetPt', '0'): double\n('ak8FatJetPt', '1'): double\n('ak8FatJetPt', '2'): double\n('ak8FatJetMsd', '0'): double\n('ak8FatJetMsd', '1'): double\n('ak8FatJetMsd', '2'): double\n('ak8FatJetPNetXbb', '0'): double\n('ak8FatJetPNetXbb', '1'): double\n('ak8FatJetPNetXbb', '2'): double\n('ak8FatJetPNetXjj', '0'): double\n('ak8FatJetPNetXjj', '1'): double\n('ak8FatJetPNetXjj', '2'): double\n('ak8FatJetPNetQCD', '0'): double\n('ak8FatJetPNetQCD', '1'): double\n('ak8FatJetPNetQCD', '2'): double\n('ak8FatJetPNetMass', '0'): double\n('ak8FatJetPNetMass', '1'): double\n('ak8FatJetPNetMass', '2'): double\n('ak8FatJetPNetMassRaw', '0'): double\n('ak8FatJetPNetMassRaw', '1'): double\n('ak8FatJetPNetMassRaw', '2'): double\n('ak8FatJetTau2OverTau1', '0'): double\n('ak8FatJetTau2OverTau1', '1'): double\n('ak8FatJetTau2OverTau1', '2'): double\n('ak8FatJetTau3OverTau2', '0'): double\n('ak8FatJetTau3OverTau2', '1'): double\n('ak8FatJetTau3OverTau2', '2'): double\n('ak8FatJetrawFactor', '0'): double\n('ak8FatJetrawFactor', '1'): double\n('ak8FatJetrawFactor', '2'): double\n('leptonEta', '0'): double\n('leptonEta', '1'): double\n('leptonPhi', '0'): double\n('leptonPhi', '1'): double\n('leptonMass', '0'): double\n('leptonMass', '1'): double\n('leptonPt', '0'): double\n('leptonPt', '1'): double\n('leptonId', '0'): int64\n('leptonId', '1'): int64\n('weight', '0'): double\n__fragment_index: int32\n__batch_index: int32\n__last_in_fragment: bool\n__filename: string"
     ]
    }
   ],
   "source": [
    "# Load your dataset\n",
    "samples = {\n",
    "    \"muon\": [\n",
    "            \"Muon_Run2022E\",\n",
    "            \"Muon_Run2022F\",\n",
    "            \"Muon_Run2022G\",\n",
    "        ],\n",
    "}\n",
    "\n",
    "dirs = {path_to_dir: samples}\n",
    "\n",
    "filters = None\n",
    "\n",
    "# columns to load\n",
    "# the parquet files are too big so we can only load a few columns at a time without consumming much memory\n",
    "load_columns = [\n",
    "    (\"weight\", 1),\n",
    "    (\"ak8FatJetTau2OverTau1\", 2),\n",
    "    (\"ak8FatJetMsd\", 2),\n",
    "    (\"ak8FatJetPNetMass\", 2),\n",
    "    (\"ak8FatJetEta\", 2),\n",
    "    (\"ak8FatJetPhi\", 2),\n",
    "    (\"ak8FatJetPt\", 2),\n",
    "    (\"finalWeight\", 0),\n",
    "]\n",
    "# reformat into (\"column name\", \"idx\") format for reading multiindex columns\n",
    "columns = []\n",
    "for key, num_columns in load_columns:\n",
    "    for i in range(num_columns):\n",
    "        columns.append(f\"('{key}', '{i}')\")\n",
    "\n",
    "\n",
    "events_dict_data = {}\n",
    "for input_dir, samples in dirs.items():\n",
    "    events_dict_data = {\n",
    "        **events_dict,\n",
    "        # this function will load files (only the columns selected), apply filters and compute a weight per event\n",
    "        **utils.load_samples(input_dir, samples, year, filters=filters, columns=columns, reorder_legacy_txbb=False),\n",
    "    }\n",
    "\n",
    "samples_loaded = list(events_dict.keys())\n",
    "keys_loaded = list(events_dict[samples_loaded[0]].keys())\n",
    "print(f\"Keys in events_dict\")\n",
    "for i in keys_loaded:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f8bd48-ceeb-4a14-b16c-78c49d9e66bb",
   "metadata": {},
   "source": [
    "## Event cuts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa5e5f58-0e7d-4f22-9afd-434f718e1207",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut_on_W_mass(events, greater_than=60):\n",
    "    # get W jets per events\n",
    "    fatjets = make_vector(events, \"ak8FatJet\")\n",
    "    sort_by_fj_pt = np.argsort(fatjets.pt, axis=1)[:, ::-1]\n",
    "    fj_sorted = np.take_along_axis(fatjets, sort_by_fj_pt, axis=1)\n",
    "    leading_fj = fj_sorted[:, 0]\n",
    "    return events[leading_fj.M > greater_than]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31fe4907-a8e0-4b33-979c-b3d30a91fd2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Higgs candidate selection example\n",
    "events_data = events_dict_data['muon']\n",
    "events_data = cut_on_W_mass(events_data, greater_than=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "831da046-aecc-45eb-a9e4-b3bc1de4f90a",
   "metadata": {},
   "outputs": [],
   "source": [
    "events_mc = events_dict['tt']\n",
    "events_mc = cut_on_W_mass(events_mc, greater_than=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d069753-4883-4311-b826-2c02c7b99cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AK4OutsideJet pt cut\n",
    "# jets_outside_raw = make_vector(events_raw, \"ak4JetOutside\")\n",
    "# j3_raw = jets_outside_raw[:, 0]\n",
    "# j4_raw = jets_outside_raw[:, 1]\n",
    "# j3j4_pt_cut = (j3_raw.pt > 20) & (j4_raw.pt > 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb1fc09-6a39-49a0-80dc-13f2e276f06f",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(events_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb7e5531-1994-4cde-8f28-0b50eab04ab1",
   "metadata": {},
   "source": [
    "Before W mass cut: 96443\n",
    "\n",
    "After W mass cut: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "745ac4a4-05f0-464d-8b63-bc4006324703",
   "metadata": {},
   "source": [
    "## Define different matching categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c1398d3-3b52-460b-b99f-51b66a06ad26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# derive fatjet attributes\n",
    "# use != as XOR\n",
    "has_2_daughter_qs = np.array(events_mc['bbFatJetNumQMatchedTop1'] == 2) != np.array(events_mc['bbFatJetNumQMatchedTop2'] == 2)\n",
    "has_1_b = np.array(events_mc['bbFatJetNumBMatchedTop1'] == 1) != np.array(events_mc['bbFatJetNumBMatchedTop2'] == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b66038b-f308-4c84-b387-0b9d997f3fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_matched = (has_2_daughter_qs) & (has_1_b)\n",
    "W_matched = (has_2_daughter_qs) & (~has_1_b)\n",
    "unmatched = (~has_2_daughter_qs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "253ca949-703f-4ef5-819c-045f6664c77a",
   "metadata": {},
   "source": [
    "## Select Leading Fatjet by pT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4020231d-c3df-4a5c-a5bb-64e1dfd943b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fatjets_mc = make_vector(events_mc, \"ak8FatJet\")\n",
    "mc_sort_by_fj_pt = np.argsort(fatjets_mc.pt, axis=1)[:, ::-1]\n",
    "fj_sorted_mc = np.take_along_axis(fatjets_mc, mc_sort_by_fj_pt, axis=1)\n",
    "leading_fj_mc = fj_sorted_mc[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d2a372-adf6-49fc-843a-26a94dd8d4e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fatjets_data = make_vector(events_data, \"ak8FatJet\")\n",
    "data_sort_by_fj_pt = np.argsort(fatjets_data.pt, axis=1)[:, ::-1]\n",
    "fj_sorted_data = np.take_along_axis(fatjets_data, data_sort_by_fj_pt, axis=1)\n",
    "leading_fj_data = fj_sorted_data[:, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91fc089d-310b-48ca-821b-f4d2b0196b4a",
   "metadata": {},
   "source": [
    "## Sort leading fatjets tau21 into each category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4aaea10-ddac-4f6e-90ae-94e3da385951",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_matched_sorted = np.take_along_axis(top_matched, mc_sort_by_fj_pt, axis=1)\n",
    "leading_fj_mc_is_top_matched = top_matched_sorted[:, 0]\n",
    "leading_fj_mc_top = leading_fj_mc[leading_fj_mc_is_top_matched]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c927ef-f970-4817-8a12-13b5b69fe2c1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "events_mc.loc[leading_fj_mc_is_top_matched, 'leading_fj_tau21'] = leading_fj_mc_top['tau21']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e68a9fa-c62a-42a0-a17a-bd5f33f7951c",
   "metadata": {},
   "outputs": [],
   "source": [
    "W_matched_sorted = np.take_along_axis(W_matched, mc_sort_by_fj_pt, axis=1)\n",
    "leading_fj_mc_is_W_matched = W_matched_sorted[:, 0]\n",
    "leading_fj_mc_W = leading_fj_mc[leading_fj_mc_is_W_matched]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6092a93-6cde-4406-a6f2-8f3124b6cc63",
   "metadata": {},
   "outputs": [],
   "source": [
    "events_mc.loc[leading_fj_mc_is_W_matched, 'leading_fj_tau21'] = leading_fj_mc_W['tau21']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa8ae4d0-3750-4532-ad68-da54cf0b5af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "unmatched_sorted = np.take_along_axis(unmatched, mc_sort_by_fj_pt, axis=1)\n",
    "leading_fj_mc_is_unmatched = unmatched_sorted[:, 0]\n",
    "leading_fj_mc_unmatched = leading_fj_mc[leading_fj_mc_is_unmatched]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "210049bb-b160-40d8-b577-117bd1bf079b",
   "metadata": {},
   "outputs": [],
   "source": [
    "events_mc.loc[leading_fj_mc_is_unmatched, 'leading_fj_tau21'] = leading_fj_mc_unmatched['tau21']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b34862d-d581-4e14-b973-14fef32fcb20",
   "metadata": {},
   "outputs": [],
   "source": [
    "events_data.loc[:, 'leading_fj_tau21'] = leading_fj_data['tau21']\n",
    "events_data.loc[:, 'finalWeight'] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3d4b531-7714-422f-85a6-85c2a2e291df",
   "metadata": {},
   "source": [
    "## Define Events by their leading fj matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "491df2b4-c6d7-4a7e-be68-b727f1b586c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse the events df to a way that util can accept\n",
    "events_dict = {}\n",
    "events_dict['data'] = events_data\n",
    "events_dict['top_matched'] = events_mc[leading_fj_mc_is_top_matched]\n",
    "events_dict['W_matched'] = events_mc[leading_fj_mc_is_W_matched]\n",
    "events_dict['unmatched'] = events_mc[leading_fj_mc_is_unmatched]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ddc7b13-2664-4c6d-981c-3a9c431010eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "events_dict['top_matched']['leading_fj_tau21']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38fbdbb6-9e64-4d31-9cb6-363beeebb4fe",
   "metadata": {},
   "source": [
    "## Plot tau21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d44aa94-8d8e-4eed-ba4c-ae82c37e6089",
   "metadata": {},
   "outputs": [],
   "source": [
    "control_plot_vars = [\n",
    "    ShapeVar(var=\"leading_fj_tau21\", label=r\"tau21\", bins=list(np.arange(0, 1.05, 0.05)), reg=False),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a884fae3-9127-4555-83ba-a559af680ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ylims = {\n",
    "    \"2022\": 5e4,\n",
    "    \"2022EE\": 4e3,\n",
    "    \"2023-pre-BPix\": 4e5,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1cefbaa-b848-4824-a686-a5a1d620ef7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for year in [\"2022EE\"]:\n",
    "    hists = {}\n",
    "    for shape_var in control_plot_vars:\n",
    "        print(shape_var)\n",
    "        if shape_var.var not in hists:\n",
    "            hists[shape_var.var] = utils.singleVarHist(\n",
    "                events_dict,\n",
    "                shape_var,\n",
    "                weight_key=\"finalWeight\",\n",
    "            )\n",
    "\n",
    "        bkgs = [\"top_matched\", \"W_matched\", \"unmatched\"]\n",
    "        sigs = []\n",
    "\n",
    "        plotting.ratioHistPlot(\n",
    "            hists[shape_var.var],\n",
    "            year,\n",
    "            sigs,\n",
    "            bkgs,\n",
    "            name=\"test_wp_Wmass>60\",\n",
    "            show=True,\n",
    "            log=False,\n",
    "            bg_err=None,\n",
    "            bg_order = [\"top_matched\",\"W_matched\", \"unmatched\"],\n",
    "            plot_data=True,\n",
    "            plot_significance=False,\n",
    "            significance_dir=shape_var.significance_dir,\n",
    "            ylim=1.2e4,\n",
    "            ylim_low=0,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859a82e5-f555-48d1-b97a-c1549f418c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(events_dict['top_matched'][\"leading_fj_tau21\"], bins=list(np.arange(0, 1.05, 0.05)), weights=events_dict['top_matched'][\"finalWeight\"],label=\"top\", histtype='step')\n",
    "plt.hist(events_dict['W_matched'][\"leading_fj_tau21\"], bins=list(np.arange(0, 1.05, 0.05)), weights=events_dict['W_matched'][\"finalWeight\"],label=\"W\", histtype='step')\n",
    "plt.hist(events_dict['unmatched'][\"leading_fj_tau21\"], bins=list(np.arange(0, 1.05, 0.05)), weights=events_dict['unmatched'][\"finalWeight\"],label=\"unmatched\", histtype='step')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20fb538b-d4ea-4d61-957a-655dd3c49b18",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

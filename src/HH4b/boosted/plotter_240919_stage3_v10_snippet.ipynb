{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102265d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uproot\n",
    "import awkward as ak\n",
    "import numpy as np\n",
    "import sklearn.metrics as m\n",
    "import boost_histogram as bh\n",
    "import glob\n",
    "import os\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from cycler import cycler\n",
    "import mplhep as hep\n",
    "use_helvet = False  ## true: use helvetica for plots, make sure the system have the font installed\n",
    "if use_helvet:\n",
    "    CMShelvet = hep.style.CMS\n",
    "    CMShelvet['font.sans-serif'] = ['Helvetica', 'Arial']\n",
    "    plt.style.use(CMShelvet)\n",
    "else:\n",
    "    plt.style.use(hep.style.CMS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea65c807",
   "metadata": {},
   "source": [
    "# ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "411ba1af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getConfig(opt, pt='low', mass='higgs', year='2017'):\n",
    "    from types import SimpleNamespace\n",
    "    if pt=='lower':\n",
    "        ptmin, ptmax = 200, 400\n",
    "    elif pt=='low':\n",
    "        ptmin, ptmax = 400, 600\n",
    "    elif pt=='high':\n",
    "        ptmin, ptmax = 600, 1000\n",
    "    elif pt=='higher':\n",
    "        ptmin, ptmax = 1000, 100000\n",
    "    elif pt=='full':\n",
    "        ptmin, ptmax = 200, 100000\n",
    "\n",
    "    if mass=='higgs':\n",
    "        massmin, massmax = 60, 150\n",
    "    if mass=='wz':\n",
    "        massmin, massmax = 50, 140\n",
    "    elif mass=='x50':\n",
    "        massmin, massmax = 0, 80\n",
    "    elif mass=='x250':\n",
    "        massmin, massmax = 150, 300\n",
    "    elif mass=='x350':\n",
    "        massmin, massmax = 250, 400\n",
    "    elif mass=='full':\n",
    "        massmin, massmax = 50, 250\n",
    "    elif mass=='fullmax':\n",
    "        massmin, massmax = 50, 800\n",
    "    elif isinstance(mass, tuple):\n",
    "        massmin, massmax = mass\n",
    "\n",
    "    routine, sname, bname = opt.split(':')\n",
    "    routine_config = None\n",
    "    if ';' in routine:\n",
    "        routine, routine_config = routine.split(';')\n",
    "    cfg = SimpleNamespace(\n",
    "        year = year,\n",
    "        ptmin = ptmin, ptmax = ptmax,\n",
    "        filedir = None,\n",
    "        filelist = {\n",
    "            'sig': None,\n",
    "            'bkg': None,\n",
    "        },\n",
    "        base_cut = f'(fj_pt>{ptmin}) & (fj_pt<{ptmax}) & (abs(fj_eta)<2.4)',\n",
    "        mass_cut = f'(fj_sdmass>{massmin}) & (fj_sdmass<{massmax})',\n",
    "        subtitle = (r'$%d < p_{T} < %d$ GeV,  $|\\eta|<2.4$' % (ptmin, ptmax)) if ptmax!=100000 else r'$p_{T,j} > %d$ GeV,  $|\\eta_{j}|<2.4$' % (ptmin),\n",
    "        subtitle2 = r'$%d < m_{SD} < %d$ GeV' % (massmin, massmax),\n",
    "        label_list = [\n",
    "            'label_Top_bWcs', 'label_Top_bWqq', 'label_Top_bWc', 'label_Top_bWs', 'label_Top_bWq', 'label_Top_bWev', 'label_Top_bWmv', 'label_Top_bWtauev', 'label_Top_bWtaumv', 'label_Top_bWtauhv', 'label_Top_Wcs', 'label_Top_Wqq', 'label_Top_Wev', 'label_Top_Wmv', 'label_Top_Wtauev', 'label_Top_Wtaumv', 'label_Top_Wtauhv', 'label_H_bb', 'label_H_cc', 'label_H_ss', 'label_H_qq', 'label_H_bc', 'label_H_bs', 'label_H_cs', 'label_H_gg', 'label_H_ee', 'label_H_mm', 'label_H_tauhtaue', 'label_H_tauhtaum', 'label_H_tauhtauh', 'label_H_WW_cscs', 'label_H_WW_csqq', 'label_H_WW_qqqq', 'label_H_WW_csc', 'label_H_WW_css', 'label_H_WW_csq', 'label_H_WW_qqc', 'label_H_WW_qqs', 'label_H_WW_qqq', 'label_H_WW_csev', 'label_H_WW_qqev', 'label_H_WW_csmv', 'label_H_WW_qqmv', 'label_H_WW_cstauev', 'label_H_WW_qqtauev', 'label_H_WW_cstaumv', 'label_H_WW_qqtaumv', 'label_H_WW_cstauhv', 'label_H_WW_qqtauhv', 'label_H_WxWx_cscs', 'label_H_WxWx_csqq', 'label_H_WxWx_qqqq', 'label_H_WxWx_csc', 'label_H_WxWx_css', 'label_H_WxWx_csq', 'label_H_WxWx_qqc', 'label_H_WxWx_qqs', 'label_H_WxWx_qqq', 'label_H_WxWx_csev', 'label_H_WxWx_qqev', 'label_H_WxWx_csmv', 'label_H_WxWx_qqmv', 'label_H_WxWx_cstauev', 'label_H_WxWx_qqtauev', 'label_H_WxWx_cstaumv', 'label_H_WxWx_qqtaumv', 'label_H_WxWx_cstauhv', 'label_H_WxWx_qqtauhv', 'label_H_WxWxStar_cscs', 'label_H_WxWxStar_csqq', 'label_H_WxWxStar_qqqq', 'label_H_WxWxStar_csc', 'label_H_WxWxStar_css', 'label_H_WxWxStar_csq', 'label_H_WxWxStar_qqc', 'label_H_WxWxStar_qqs', 'label_H_WxWxStar_qqq', 'label_H_WxWxStar_csev', 'label_H_WxWxStar_qqev', 'label_H_WxWxStar_csmv', 'label_H_WxWxStar_qqmv', 'label_H_WxWxStar_cstauev', 'label_H_WxWxStar_qqtauev', 'label_H_WxWxStar_cstaumv', 'label_H_WxWxStar_qqtaumv', 'label_H_WxWxStar_cstauhv', 'label_H_WxWxStar_qqtauhv', 'label_H_ZZ_bbbb', 'label_H_ZZ_bbcc', 'label_H_ZZ_bbss', 'label_H_ZZ_bbqq', 'label_H_ZZ_cccc', 'label_H_ZZ_ccss', 'label_H_ZZ_ccqq', 'label_H_ZZ_ssss', 'label_H_ZZ_ssqq', 'label_H_ZZ_qqqq', 'label_H_ZZ_bbb', 'label_H_ZZ_bbc', 'label_H_ZZ_bbs', 'label_H_ZZ_bbq', 'label_H_ZZ_ccb', 'label_H_ZZ_ccc', 'label_H_ZZ_ccs', 'label_H_ZZ_ccq', 'label_H_ZZ_ssb', 'label_H_ZZ_ssc', 'label_H_ZZ_sss', 'label_H_ZZ_ssq', 'label_H_ZZ_qqb', 'label_H_ZZ_qqc', 'label_H_ZZ_qqs', 'label_H_ZZ_qqq', 'label_H_ZZ_bbee', 'label_H_ZZ_bbmm', 'label_H_ZZ_bbe', 'label_H_ZZ_bbm', 'label_H_ZZ_bee', 'label_H_ZZ_bmm', 'label_H_ZZ_bbtauhtaue', 'label_H_ZZ_bbtauhtaum', 'label_H_ZZ_bbtauhtauh', 'label_H_ZZ_btauhtaue', 'label_H_ZZ_btauhtaum', 'label_H_ZZ_btauhtauh', 'label_H_ZZ_ccee', 'label_H_ZZ_ccmm', 'label_H_ZZ_cce', 'label_H_ZZ_ccm', 'label_H_ZZ_cee', 'label_H_ZZ_cmm', 'label_H_ZZ_cctauhtaue', 'label_H_ZZ_cctauhtaum', 'label_H_ZZ_cctauhtauh', 'label_H_ZZ_ctauhtaue', 'label_H_ZZ_ctauhtaum', 'label_H_ZZ_ctauhtauh', 'label_H_ZZ_ssee', 'label_H_ZZ_ssmm', 'label_H_ZZ_sse', 'label_H_ZZ_ssm', 'label_H_ZZ_see', 'label_H_ZZ_smm', 'label_H_ZZ_sstauhtaue', 'label_H_ZZ_sstauhtaum', 'label_H_ZZ_sstauhtauh', 'label_H_ZZ_stauhtaue', 'label_H_ZZ_stauhtaum', 'label_H_ZZ_stauhtauh', 'label_H_ZZ_qqee', 'label_H_ZZ_qqmm', 'label_H_ZZ_qqe', 'label_H_ZZ_qqm', 'label_H_ZZ_qee', 'label_H_ZZ_qmm', 'label_H_ZZ_qqtauhtaue', 'label_H_ZZ_qqtauhtaum', 'label_H_ZZ_qqtauhtauh', 'label_H_ZZ_qtauhtaue', 'label_H_ZZ_qtauhtaum', 'label_H_ZZ_qtauhtauh', 'label_H_ZxZx_bbbb', 'label_H_ZxZx_bbcc', 'label_H_ZxZx_bbss', 'label_H_ZxZx_bbqq', 'label_H_ZxZx_cccc', 'label_H_ZxZx_ccss', 'label_H_ZxZx_ccqq', 'label_H_ZxZx_ssss', 'label_H_ZxZx_ssqq', 'label_H_ZxZx_qqqq', 'label_H_ZxZx_bbb', 'label_H_ZxZx_bbc', 'label_H_ZxZx_bbs', 'label_H_ZxZx_bbq', 'label_H_ZxZx_ccb', 'label_H_ZxZx_ccc', 'label_H_ZxZx_ccs', 'label_H_ZxZx_ccq', 'label_H_ZxZx_ssb', 'label_H_ZxZx_ssc', 'label_H_ZxZx_sss', 'label_H_ZxZx_ssq', 'label_H_ZxZx_qqb', 'label_H_ZxZx_qqc', 'label_H_ZxZx_qqs', 'label_H_ZxZx_qqq', 'label_H_ZxZx_bbee', 'label_H_ZxZx_bbmm', 'label_H_ZxZx_bbe', 'label_H_ZxZx_bbm', 'label_H_ZxZx_bee', 'label_H_ZxZx_bmm', 'label_H_ZxZx_bbtauhtaue', 'label_H_ZxZx_bbtauhtaum', 'label_H_ZxZx_bbtauhtauh', 'label_H_ZxZx_btauhtaue', 'label_H_ZxZx_btauhtaum', 'label_H_ZxZx_btauhtauh', 'label_H_ZxZx_ccee', 'label_H_ZxZx_ccmm', 'label_H_ZxZx_cce', 'label_H_ZxZx_ccm', 'label_H_ZxZx_cee', 'label_H_ZxZx_cmm', 'label_H_ZxZx_cctauhtaue', 'label_H_ZxZx_cctauhtaum', 'label_H_ZxZx_cctauhtauh', 'label_H_ZxZx_ctauhtaue', 'label_H_ZxZx_ctauhtaum', 'label_H_ZxZx_ctauhtauh', 'label_H_ZxZx_ssee', 'label_H_ZxZx_ssmm', 'label_H_ZxZx_sse', 'label_H_ZxZx_ssm', 'label_H_ZxZx_see', 'label_H_ZxZx_smm', 'label_H_ZxZx_sstauhtaue', 'label_H_ZxZx_sstauhtaum', 'label_H_ZxZx_sstauhtauh', 'label_H_ZxZx_stauhtaue', 'label_H_ZxZx_stauhtaum', 'label_H_ZxZx_stauhtauh', 'label_H_ZxZx_qqee', 'label_H_ZxZx_qqmm', 'label_H_ZxZx_qqe', 'label_H_ZxZx_qqm', 'label_H_ZxZx_qee', 'label_H_ZxZx_qmm', 'label_H_ZxZx_qqtauhtaue', 'label_H_ZxZx_qqtauhtaum', 'label_H_ZxZx_qqtauhtauh', 'label_H_ZxZx_qtauhtaue', 'label_H_ZxZx_qtauhtaum', 'label_H_ZxZx_qtauhtauh', 'label_H_ZxZxStar_bbbb', 'label_H_ZxZxStar_bbcc', 'label_H_ZxZxStar_bbss', 'label_H_ZxZxStar_bbqq', 'label_H_ZxZxStar_cccc', 'label_H_ZxZxStar_ccss', 'label_H_ZxZxStar_ccqq', 'label_H_ZxZxStar_ssss', 'label_H_ZxZxStar_ssqq', 'label_H_ZxZxStar_qqqq', 'label_H_ZxZxStar_bbb', 'label_H_ZxZxStar_bbc', 'label_H_ZxZxStar_bbs', 'label_H_ZxZxStar_bbq', 'label_H_ZxZxStar_ccb', 'label_H_ZxZxStar_ccc', 'label_H_ZxZxStar_ccs', 'label_H_ZxZxStar_ccq', 'label_H_ZxZxStar_ssb', 'label_H_ZxZxStar_ssc', 'label_H_ZxZxStar_sss', 'label_H_ZxZxStar_ssq', 'label_H_ZxZxStar_qqb', 'label_H_ZxZxStar_qqc', 'label_H_ZxZxStar_qqs', 'label_H_ZxZxStar_qqq', 'label_H_ZxZxStar_bbee', 'label_H_ZxZxStar_bbmm', 'label_H_ZxZxStar_bbe', 'label_H_ZxZxStar_bbm', 'label_H_ZxZxStar_bee', 'label_H_ZxZxStar_bmm', 'label_H_ZxZxStar_bbtauhtaue', 'label_H_ZxZxStar_bbtauhtaum', 'label_H_ZxZxStar_bbtauhtauh', 'label_H_ZxZxStar_btauhtaue', 'label_H_ZxZxStar_btauhtaum', 'label_H_ZxZxStar_btauhtauh', 'label_H_ZxZxStar_ccee', 'label_H_ZxZxStar_ccmm', 'label_H_ZxZxStar_cce', 'label_H_ZxZxStar_ccm', 'label_H_ZxZxStar_cee', 'label_H_ZxZxStar_cmm', 'label_H_ZxZxStar_cctauhtaue', 'label_H_ZxZxStar_cctauhtaum', 'label_H_ZxZxStar_cctauhtauh', 'label_H_ZxZxStar_ctauhtaue', 'label_H_ZxZxStar_ctauhtaum', 'label_H_ZxZxStar_ctauhtauh', 'label_H_ZxZxStar_ssee', 'label_H_ZxZxStar_ssmm', 'label_H_ZxZxStar_sse', 'label_H_ZxZxStar_ssm', 'label_H_ZxZxStar_see', 'label_H_ZxZxStar_smm', 'label_H_ZxZxStar_sstauhtaue', 'label_H_ZxZxStar_sstauhtaum', 'label_H_ZxZxStar_sstauhtauh', 'label_H_ZxZxStar_stauhtaue', 'label_H_ZxZxStar_stauhtaum', 'label_H_ZxZxStar_stauhtauh', 'label_H_ZxZxStar_qqee', 'label_H_ZxZxStar_qqmm', 'label_H_ZxZxStar_qqe', 'label_H_ZxZxStar_qqm', 'label_H_ZxZxStar_qee', 'label_H_ZxZxStar_qmm', 'label_H_ZxZxStar_qqtauhtaue', 'label_H_ZxZxStar_qqtauhtaum', 'label_H_ZxZxStar_qqtauhtauh', 'label_H_ZxZxStar_qtauhtaue', 'label_H_ZxZxStar_qtauhtaum', 'label_H_ZxZxStar_qtauhtauh', 'label_QCD_bb', 'label_QCD_cc', 'label_QCD_b', 'label_QCD_c', 'label_QCD_others',\n",
    "            'btaue', 'btaum', 'btauh', 'aa', 'x5', 'x6', 'x7', 'x8', 'x9', 'x10', 'x11', 'x12', 'x13', 'x14', 'x15', 'x16', 'x17', 'x18', 'x19', 'x20', 'x21', 'x22', 'x23', 'x24', 'x25', 'x26', 'x27', 'x28', 'x29', 'x30',\n",
    "            'aabb', 'aacc', 'aass', 'aaqq', 'aabc', 'aacs', 'aabq', 'aacq', 'aasq', 'aagg', 'aaee', 'aamm', 'aatauhtaue', 'aatauhtaum', 'aatauhtauh', 'aab', 'aac', 'aas', 'aaq', 'aag', 'aae', 'aam', 'aataue', 'aataum', 'aatauh', 'abb', 'acc', 'ass', 'aqq', 'abc', 'acs', 'abq', 'acq', 'asq', 'agg', 'aee', 'amm', 'atauhtaue', 'atauhtaum', 'atauhtauh',\n",
    "            ] # this is the idx-name mapping from dnntuples, not the actual label for tagger training\n",
    "    )\n",
    "    cfg.label_idx = {lab: i for i, lab in enumerate(cfg.label_list)}\n",
    "\n",
    "    if routine == 'v3':\n",
    "        # cfg.label = 'GloParT 3'\n",
    "        cfg.label = 'GloParT'\n",
    "        cfg.filedir = '/ceph/cms/store/user/woodson/glopart-plotter/predict/ak8_MD_inclv10beta4_ul_manual.nlayer10.vispart_as_resid.ddp4-bs640-lr1p2e-3.nepoch100.farm221.best_epoch'\n",
    "\n",
    "    # previous versions\n",
    "    elif routine == 'v2':\n",
    "        cfg.label = f'GloParT 2'\n",
    "        cfg.filedir = '/ceph/cms/store/user/woodson/glopart-plotter/predict/ak8_MD_inclv8_part_addltphp_wmeasonly_manual.useamp.large.gm5.ddp-bs256-lr2e-3/new'\n",
    "    \n",
    "    elif routine == 'PNetMD':\n",
    "        # cfg.label = 'ParticleNet-MD (legacy)'\n",
    "        cfg.label = 'ParticleNet'\n",
    "        cfg.filedir = '/ceph/cms/store/user/woodson/glopart-plotter/predict/ak8_MD_inclv10beta4_ul_manual.nlayer10.vispart_as_resid.ddp4-bs640-lr1p2e-3.nepoch100.farm221.best_epoch'\n",
    "\n",
    "    else:\n",
    "        raise RuntimeError('wrong opt')\n",
    "\n",
    "    # determine which file to use\n",
    "    year_file_id = {\n",
    "        '2017': '',\n",
    "        '2023': 'run3_2023_',\n",
    "        '2023BPix': 'run3_2023bpix_',\n",
    "        '2023FixLTS': 'run3_2023_fixlts_',\n",
    "        '2017PUPPIv18': 'run2_repuppi_',\n",
    "    }[year]\n",
    "    file_regex_map = {\n",
    "        'QCD': f'pred_{year_file_id}qcd[0-9]*.root', # always read split QCD files\n",
    "        'QCDLO': f'pred_{year_file_id}qcd470to600.root', # always read split QCD files\n",
    "        'QCDHI': f'pred_{year_file_id}qcd1000to1400.root', # always read split QCD files\n",
    "        'HIGLO': f'pred_{year_file_id}higlo*.root', # possible to have split files (part1, part2, ...)\n",
    "        'HIGHI': f'pred_{year_file_id}highi*.root',\n",
    "        'HWWLO': f'pred_{year_file_id}hwwlo*.root',\n",
    "        'HWWHI': f'pred_{year_file_id}hwwhi*.root',\n",
    "        'SMTTBARSL': f'pred_{year_file_id}ofcttbarsl.root',\n",
    "        **{n: f'pred_{year_file_id}{n.lower()}.root' for n in ['HIGGS2P', 'HWW', 'TTBARINCL', 'TTBAR', 'WLO', 'WHI', 'ZLO', 'ZHI']},\n",
    "    }\n",
    "    name_choices = ['HIGLO', 'HIGHI', 'HWWLO', 'HWWHI', 'HIGGS2P', 'HWW', 'QCDLO', 'QCDHI', 'QCD', 'SMTTBARSL', 'TTBARINCL', 'TTBAR', 'WLO', 'WHI', 'ZLO', 'ZHI']\n",
    "    cfg.filelist['sig'] = glob.glob([os.path.join(cfg.filedir, file_regex_map[n]) for n in name_choices if sname.startswith(n)][0])\n",
    "    cfg.filelist['bkg'] = glob.glob([os.path.join(cfg.filedir, file_regex_map[n]) for n in name_choices if bname.startswith(n)][0])\n",
    "    sname = sname.replace('QCDLO','QCD').replace('QCDHI','QCD').replace('HIGLO','HIG').replace('HIGHI','HIG').replace('HWWLO','HWW').replace('HWWHI','HWW').replace('WLO','W').replace('WHI','W').replace('ZLO','Z').replace('ZHI','Z')\n",
    "    bname = bname.replace('QCDLO','QCD').replace('QCDHI','QCD').replace('HIGLO','HIG').replace('HIGHI','HIG').replace('HWWLO','HWW').replace('HWWHI','HWW').replace('WLO','W').replace('WHI','W').replace('ZLO','Z').replace('ZHI','Z')\n",
    "\n",
    "    # deal with variables\n",
    "    variable_dict = {\n",
    "        'QCD': ['label_QCD_bb', 'label_QCD_cc', 'label_QCD_b', 'label_QCD_c', 'label_QCD_others'],\n",
    "        **{f'HIG{n}': [f'label_H_{n}'] for n in ['bb', 'cc', 'qq', 'ss', 'bc', 'cs', 'bs', 'gg', 'ee', 'mm', 'tauhtaue', 'tauhtaum', 'tauhtauh']},\n",
    "        **{f'HIGGS2P{n}': [f'label_H_{n}'] for n in ['bb', 'cc', 'qq', 'ss', 'bc', 'cs', 'bs', 'gg', 'ee', 'mm', 'tauhtaue', 'tauhtaum', 'tauhtauh']},\n",
    "        'HIGll': [f'label_H_{n}' for n in ['ss', 'qq']],\n",
    "        **{f'HWW{n}': [f'label_H_WW_{n}'] for n in ['cscs', 'csqq', 'qqqq', 'csc', 'css', 'csq', 'qqc', 'qqs', 'qqq', 'csev', 'qqev', 'csmv', 'qqmv', 'cstauev', 'qqtauev', 'cstaumv', 'qqtaumv', 'cstauhv', 'qqtauhv']},\n",
    "        **{f'TTBAR{n}': [f'label_Top_{n}'] for n in ['bWcs', 'bWqq', 'bWc', 'bWs', 'bWq', 'bWev', 'bWmv', 'bWtauev', 'bWtaumv', 'bWtauhv', 'Wcs', 'Wqq', 'Wev', 'Wmv', 'Wtauev', 'Wtaumv', 'Wtauhv']},\n",
    "        **{f'W{n}': [f'label_H_{n}'] for n in ['qq', 'cs']},\n",
    "        **{f'Z{n}': [f'label_H_{n}'] for n in ['bb', 'cc', 'qq', 'ss']},\n",
    "        'HWWQQQQ': [f'label_H_WW_{n}' for n in ['cscs', 'csqq', 'qqqq']],\n",
    "        'HWWQQQ': [f'label_H_WW_{n}' for n in ['csc', 'css', 'csq', 'qqc', 'qqs', 'qqq']],\n",
    "        'HWWQQev': [f'label_H_WW_{n}' for n in ['csev', 'qqev']],\n",
    "        'HWWQQmv': [f'label_H_WW_{n}' for n in ['csmv', 'qqmv']],\n",
    "        'HWWQQtauev': [f'label_H_WW_{n}' for n in ['cstauev', 'qqtauev']],\n",
    "        'HWWQQtaumv': [f'label_H_WW_{n}' for n in ['cstaumv', 'qqtaumv']],\n",
    "        'HWWQQtauhv': [f'label_H_WW_{n}' for n in ['cstauhv', 'qqtauhv']],\n",
    "        'HWWQQta': [f'label_H_WW_{n}' for n in ['cstauev', 'qqtauev', 'cstaumv', 'qqtaumv', 'cstauhv', 'qqtauhv']],\n",
    "        # 'HWWel': [f'label_H_WW_{n}' for n in ['csev', 'cstauev', 'qqev', 'qqtauev']],\n",
    "        # 'HWWmu': [f'label_H_WW_{n}' for n in ['csmv', 'cstaumv', 'qqmv', 'qqtaumv']],\n",
    "        'TTBARbWall': [f'label_Top_{n}' for n in ['bWcs', 'bWqq', 'bWc', 'bWs', 'bWq', 'bWev', 'bWmv', 'bWtauev', 'bWtaumv', 'bWtauhv']],\n",
    "        'TTBARbWhad': [f'label_Top_{n}' for n in ['bWcs', 'bWqq', 'bWc', 'bWs', 'bWq']],\n",
    "        'TTBARbWQQ': [f'label_Top_{n}' for n in ['bWcs', 'bWqq']],\n",
    "        'TTBARbWta': [f'label_Top_{n}' for n in ['bWtauev', 'bWtaumv', 'bWtauhv']],\n",
    "        'TTBARbWtauhv': [f'label_Top_{n}' for n in ['bWtauhv']],\n",
    "        'TTBARall': [f'label_Top_{n}' for n in ['bWcs', 'bWqq', 'bWc', 'bWs', 'bWq', 'bWev', 'bWmv', 'bWtauev', 'bWtaumv', 'bWtauhv', 'Wcs', 'Wqq', 'Wev', 'Wmv', 'Wtauev', 'Wtaumv', 'Wtauhv']],\n",
    "        'WQQ': [f'label_H_{n}' for n in ['cs', 'qq']],\n",
    "        'ZQQ': [f'label_H_{n}' for n in ['bb', 'cc', 'ss', 'qq']],\n",
    "        'Zll': [f'label_H_{n}' for n in ['ss', 'qq']],\n",
    "        'SMTTBARSLQQ': [f'label_Top_W{n}' for n in ['cs', 'qq']],\n",
    "    }\n",
    "    variable_dict.update({k.replace('TTBAR', 'SMTTBARSL', 1): v for k, v in variable_dict.items() if k.startswith('TTBAR')})\n",
    "\n",
    "    label_dict = {\n",
    "        'QCD': 'QCD',\n",
    "        'HWWQQQQ': r'H$\\rightarrow$WW 4q', 'HWWQQQ': r'H$\\rightarrow$WW 3q', 'HWWQQev': r'H$\\rightarrow$WW $e\\nu qq$', 'HWWQQmv': r'H$\\rightarrow$WW $\\mu\\nu qq$', 'HWWQQta': r'H$\\rightarrow$WW $\\tau\\nu qq$', 'HWWQQtauev': r'H$\\rightarrow$WW $\\tau_e\\nu qq$', 'HWWQQtaumv': r'H$\\rightarrow$WW $\\tau_\\mu\\nu qq$', 'HWWQQtauhv': r'H$\\rightarrow$WW $\\tau_h\\nu qq$',\n",
    "        'HIGbb': r'H$\\rightarrow$bb', 'HIGcc': r'H$\\rightarrow$cc', 'HIGss': r'H$\\rightarrow$ss', 'HIGqq': r'H$\\rightarrow$qq', 'HIGbc': r'$H^\\pm \\rightarrow$bc', 'HIGcs': r'$H^\\pm \\rightarrow$cs', 'HIGbs': r'$H\\rightarrow$bs', 'HIGgg': r'$H\\rightarrow$gg', 'HIGee': r'$H\\rightarrow$ee', 'HIGmm': r'$H\\rightarrow \\mu\\mu$', 'HIGtauhvtauev': r'H$\\rightarrow\\tau_h\\tau_e$', 'HIGtauhvtaumv': r'H$\\rightarrow\\tau_h\\tau_\\mu$', 'HIGtauhvtauhv': r'H$\\rightarrow\\tau_h\\tau_h$', \n",
    "        'HIGll': r'H$\\rightarrow$qq (q=u/d/s)', \n",
    "        'HIGtauhtaue': r'H$\\rightarrow\\tau_h\\tau_e$', 'HIGtauhtaum': r'H$\\rightarrow\\tau_h\\tau_\\mu$', 'HIGtauhtauh': r'H$\\rightarrow\\tau_h\\tau_h$', \n",
    "        'HIGGS2Pbb': r'H$\\rightarrow$bb', 'HIGGS2Pcc': r'H$\\rightarrow$cc', 'HIGGS2Pss': r'H$\\rightarrow$ss', 'HIGGS2Pqq': r'H$\\rightarrow$qq', 'HIGGS2Pbc': r'$H^\\pm \\rightarrow$bc', 'HIGGS2Pcs': r'$H^\\pm \\rightarrow$cs', 'HIGGS2Pbs': r'$H\\rightarrow$bs', 'HIGGS2Pgg': r'$H\\rightarrow$gg', 'HIGGS2Pee': r'$H\\rightarrow$ee', 'HIGGS2Pmm': r'$H\\rightarrow \\mu\\mu$', 'HIGGS2Ptauhvtauev': r'H$\\rightarrow\\tau_h\\tau_e$', 'HIGGS2Ptauhvtaumv': r'H$\\rightarrow\\tau_h\\tau_\\mu$', 'HIGGS2Ptauhvtauhv': r'H$\\rightarrow\\tau_h\\tau_h$', \n",
    "        'HIGGS2Ptauhtaue': r'H$\\rightarrow\\tau_h\\tau_e$', 'HIGGS2Ptauhtaum': r'H$\\rightarrow\\tau_h\\tau_\\mu$', 'HIGGS2Ptauhtauh': r'H$\\rightarrow\\tau_h\\tau_h$', \n",
    "        'TTBARbWall': r't$\\rightarrow$bW all', 'TTBARbWhad': r't$\\rightarrow$bW had.', 'TTBARbWQQ': r't$\\rightarrow bW \\rightarrow bqq$', 'TTBARbWev': r't$\\rightarrow bW \\rightarrow be\\nu$', 'TTBARbWmv': r't$\\rightarrow bW \\rightarrow b\\mu\\nu$', 'TTBARbWta': r't$\\rightarrow bW \\rightarrow b\\tau\\nu$', 'TTBARbWtauhv': r't$\\rightarrow bW \\rightarrow b\\tau_h\\nu$',\n",
    "        'TTBARINCLall': r't$\\rightarrow$bW all (incl.)', 'TTBARINCLhad': r't$\\rightarrow$bW had. (incl.)', 'TTBARINCLel': r't$\\rightarrow bW \\rightarrow be\\nu$ (incl.)', 'TTBARINCLmu': r't$\\rightarrow bW \\rightarrow b\\mu\\nu$ (incl.)', \n",
    "        'SMTTBARSLbWall': r't$\\rightarrow$bW all', 'SMTTBARSLbWhad': r't$\\rightarrow$bW had.', 'SMTTBARSLbWQQ': r't$\\rightarrow bW \\rightarrow bqq$', 'SMTTBARSLbWev': r't$\\rightarrow bW \\rightarrow be\\nu$', 'SMTTBARSLbWmv': r't$\\rightarrow bW \\rightarrow b\\mu\\nu$', 'SMTTBARSLbWta': r't$\\rightarrow bW \\rightarrow b\\tau\\nu$',\n",
    "        'SMTTBARSLbWcs': r't$\\rightarrow bW \\rightarrow bcs$', 'SMTTBARSLbWqq': r't$\\rightarrow bW \\rightarrow bqq$', 'SMTTBARSLQQ': r'W$\\rightarrow$qq (from $t\\overline{t}$)', \n",
    "        'XBCbc': r'$H\\prime\\rightarrow$bc', \n",
    "        'Wcs': r'W$\\rightarrow$cs', 'Wqq': r'W$\\rightarrow$qq', 'Zbb': r'Z$\\rightarrow$bb', 'Zcc': r'Z$\\rightarrow$cc', 'Zqq': r'Z$\\rightarrow$qq', 'Zss': r'Z$\\rightarrow$ss', 'Zll': r'Z$\\rightarrow$qq (q=u/d/s)', \n",
    "        'WQQ': r'W$\\rightarrow$qq (all)', 'ZQQ': r'Z$\\rightarrow$qq (all)',\n",
    "    }\n",
    "    cfg.y_sig_flag = ' | '.join([f'(fj_label == {cfg.label_idx[lab]})' for lab in variable_dict[sname]])\n",
    "    cfg.y_bkg_flag = ' | '.join([f'(fj_label == {cfg.label_idx[lab]})' for lab in variable_dict[bname]])\n",
    "\n",
    "    cfg.y_score_sig = ' + '.join([f'score_{lab}' for lab in variable_dict[sname]])\n",
    "    cfg.y_score_bkg = ' + '.join([f'score_{lab}' for lab in variable_dict[bname]])\n",
    "    cfg.y_score = f'({cfg.y_score_sig}) / (({cfg.y_score_sig}) + ({cfg.y_score_bkg}))'\n",
    "\n",
    "    cfg.title = f'{label_dict[sname]} vs {label_dict[bname]}'\n",
    "\n",
    "    # special treatment\n",
    "    import re\n",
    "    cfg.y_sig_flag = cfg.y_sig_flag + ' '\n",
    "    cfg.y_bkg_flag = cfg.y_bkg_flag + ' '\n",
    "    cfg.y_score = cfg.y_score + ' '\n",
    "\n",
    "    # speical treatment on variables\n",
    "    if routine == 'PNetMD':\n",
    "        exist_variable_dict = {\n",
    "            'QCD': ' + '.join([f'pfMassDecorrelatedParticleNetJetTags_probQCD{n}' for n in ['b', 'bb', 'c', 'cc', 'others']]),\n",
    "            **{f'HIGGS2P{n}': f'pfMassDecorrelatedParticleNetJetTags_probX{n}' for n in ['bb', 'cc', 'qq']},\n",
    "            **{f'HIG{n}': f'pfMassDecorrelatedParticleNetJetTags_probX{n}' for n in ['bb', 'cc', 'qq']},\n",
    "            **{f'Z{n}': f'pfMassDecorrelatedParticleNetJetTags_probX{n}' for n in ['bb', 'cc', 'qq']},\n",
    "            'ZQQ': ' + '.join([f'pfMassDecorrelatedParticleNetJetTags_probX{n}' for n in ['bb', 'cc', 'qq']]),\n",
    "            'Zll': ' + '.join([f'pfMassDecorrelatedParticleNetJetTags_probX{n}' for n in ['qq']]),\n",
    "            'WQQ': ' + '.join([f'pfMassDecorrelatedParticleNetJetTags_probX{n}' for n in ['cc', 'qq']]), # W->qq tagger: use cc+qq\n",
    "            'Wcs': ' + '.join([f'pfMassDecorrelatedParticleNetJetTags_probX{n}' for n in ['cc']]), # W->cs tagger: use cc\n",
    "            'Wqq': ' + '.join([f'pfMassDecorrelatedParticleNetJetTags_probX{n}' for n in ['qq']]),\n",
    "            'SMTTBARSLQQ': ' + '.join([f'pfMassDecorrelatedParticleNetJetTags_probX{n}' for n in ['cc', 'qq']]), # W->qq tagger: use cc+qq\n",
    "        }\n",
    "        cfg.y_score = f'({exist_variable_dict[sname]}) / (({exist_variable_dict[sname]}) + ({exist_variable_dict[bname]}))'\n",
    "    if routine == 'PNetRun3MD':\n",
    "        exist_variable_dict = {\n",
    "            ('HIGbb', 'QCD'): 'pfParticleNetFromMiniAODAK8DiscriminatorsJetTags_HbbvsQCD',\n",
    "            ('HIGcc', 'QCD'): 'pfParticleNetFromMiniAODAK8DiscriminatorsJetTags_HccvsQCD',\n",
    "            ('HIGcc', 'HIGbb'): '(pfParticleNetFromMiniAODAK8DiscriminatorsJetTags_HccvsQCD / (1 - pfParticleNetFromMiniAODAK8DiscriminatorsJetTags_HccvsQCD)) / (pfParticleNetFromMiniAODAK8DiscriminatorsJetTags_HccvsQCD / (1 - pfParticleNetFromMiniAODAK8DiscriminatorsJetTags_HccvsQCD) + pfParticleNetFromMiniAODAK8DiscriminatorsJetTags_HbbvsQCD / (1 - pfParticleNetFromMiniAODAK8DiscriminatorsJetTags_HbbvsQCD) + 1e-8)',\n",
    "            ('HIGtauhtaue', 'QCD'): 'pfParticleNetFromMiniAODAK8DiscriminatorsJetTags_HtevsQCD',\n",
    "            ('HIGtauhtaum', 'QCD'): 'pfParticleNetFromMiniAODAK8DiscriminatorsJetTags_HtmvsQCD',\n",
    "            ('HIGtauhtauh', 'QCD'): 'pfParticleNetFromMiniAODAK8DiscriminatorsJetTags_HttvsQCD',\n",
    "            ('HIGtauhtauh', 'HIGll'): '(pfParticleNetFromMiniAODAK8DiscriminatorsJetTags_HttvsQCD / (1 - pfParticleNetFromMiniAODAK8DiscriminatorsJetTags_HttvsQCD + 1e-8)) / (pfParticleNetFromMiniAODAK8DiscriminatorsJetTags_HttvsQCD / (1 - pfParticleNetFromMiniAODAK8DiscriminatorsJetTags_HttvsQCD + 1e-8) + pfParticleNetFromMiniAODAK8DiscriminatorsJetTags_HqqvsQCD / (1 - pfParticleNetFromMiniAODAK8DiscriminatorsJetTags_HqqvsQCD + 1e-8) + 1e-8)',\n",
    "            ('HIGtauhtauh', 'HIGbb'): '(pfParticleNetFromMiniAODAK8DiscriminatorsJetTags_HttvsQCD / (1 - pfParticleNetFromMiniAODAK8DiscriminatorsJetTags_HttvsQCD + 1e-8)) / (pfParticleNetFromMiniAODAK8DiscriminatorsJetTags_HttvsQCD / (1 - pfParticleNetFromMiniAODAK8DiscriminatorsJetTags_HttvsQCD + 1e-8) + pfParticleNetFromMiniAODAK8DiscriminatorsJetTags_HbbvsQCD / (1 - pfParticleNetFromMiniAODAK8DiscriminatorsJetTags_HbbvsQCD + 1e-8) + 1e-8)',\n",
    "        }\n",
    "        cfg.y_score = exist_variable_dict[(sname, bname)]\n",
    "    elif routine == 'PNet':\n",
    "        # for non-MD ParticleNet\n",
    "        exist_variable_dict = {\n",
    "            'QCD': ' + '.join([f'pfParticleNetJetTags_probQCD{n}' for n in ['b', 'bb', 'c', 'cc', 'others']]),\n",
    "            **{f'TTBAR{n}': f'pfParticleNetJetTags_probT{n}' for n in ['bc', 'bcq', 'bel', 'bmu', 'bq', 'bqq', 'bta']},\n",
    "            'TTBARhad': ' + '.join([f'pfParticleNetJetTags_probT{n}' for n in ['bcq', 'bqq', 'bc', 'bq']]),\n",
    "            'TTBARel': ' + '.join([f'pfParticleNetJetTags_probT{n}' for n in ['bel']]),\n",
    "            'TTBARmu': ' + '.join([f'pfParticleNetJetTags_probT{n}' for n in ['bmu']]),\n",
    "            'TTBARta': ' + '.join([f'pfParticleNetJetTags_probT{n}' for n in ['bta']]),\n",
    "            'TTBARbWall': ' + '.join([f'pfParticleNetJetTags_prob{n}' for n in ['Tbc', 'Tbcq', 'Tbel', 'Tbmu', 'Tbq', 'Tbqq', 'Tbta']]),\n",
    "            'TTBARbWhad': ' + '.join([f'pfParticleNetJetTags_probT{n}' for n in ['bcq', 'bqq', 'bc', 'bq']]),\n",
    "            'TTBARbWQQ': ' + '.join([f'pfParticleNetJetTags_probT{n}' for n in ['bcq', 'bqq']]),\n",
    "            'TTBARbWev': ' + '.join([f'pfParticleNetJetTags_probT{n}' for n in ['bel']]),\n",
    "            'TTBARbWmv': ' + '.join([f'pfParticleNetJetTags_probT{n}' for n in ['bmu']]),\n",
    "            'TTBARbWta': ' + '.join([f'pfParticleNetJetTags_probT{n}' for n in ['bta']]),\n",
    "            'TTBARbWtauhv': ' + '.join([f'pfParticleNetJetTags_probT{n}' for n in ['bta']]), ## special\n",
    "            'ZQQ': ' + '.join([f'pfParticleNetJetTags_probZ{n}' for n in ['bb', 'cc', 'qq']]),\n",
    "            'WQQ': ' + '.join([f'pfParticleNetJetTags_probW{n}' for n in ['cq', 'qq']]),\n",
    "        }   \n",
    "        exist_variable_dict.update({k.replace('TTBAR', 'SMTTBARSL'): v for k, v in exist_variable_dict.items() if k.startswith('TTBAR')})\n",
    "        cfg.y_score = f'({exist_variable_dict[sname]}) / (({exist_variable_dict[sname]}) + ({exist_variable_dict[bname]}))'\n",
    "    elif routine == 'GloParT1':\n",
    "        exist_variable_dict = {\n",
    "            'QCD': ' + '.join([f'pfMassDecorrelatedInclParticleTransformerV1JetTags_probQCD{n}' for n in ['b', 'bb', 'c', 'cc', 'others']]),\n",
    "            **{f'HIGGS2P{n}': f'pfMassDecorrelatedInclParticleTransformerV1JetTags_probH{n}' for n in ['bb', 'cc', 'ss', 'qq', 'tauhtaue', 'tauhtaum', 'tauhtauh']},\n",
    "            **{f'HIG{n}': f'pfMassDecorrelatedInclParticleTransformerV1JetTags_probH{n}' for n in ['bb', 'cc', 'ss', 'qq', 'tauhtaue', 'tauhtaum', 'tauhtauh']},\n",
    "            'HWWQQQQ': 'pfMassDecorrelatedInclParticleTransformerV1JetTags_probH{n}0c + pfMassDecorrelatedInclParticleTransformerV1JetTags_probH{n}1c + pfMassDecorrelatedInclParticleTransformerV1JetTags_probH{n}2c'.format(n='WqqWqq'),\n",
    "            'HWWQQQ':  'pfMassDecorrelatedInclParticleTransformerV1JetTags_probH{n}0c + pfMassDecorrelatedInclParticleTransformerV1JetTags_probH{n}1c + pfMassDecorrelatedInclParticleTransformerV1JetTags_probH{n}2c'.format(n='WqqWq'),\n",
    "            'HWWQQev': 'pfMassDecorrelatedInclParticleTransformerV1JetTags_probH{n}0c + pfMassDecorrelatedInclParticleTransformerV1JetTags_probH{n}1c'.format(n='WqqWev'),\n",
    "            'HWWQQmv': 'pfMassDecorrelatedInclParticleTransformerV1JetTags_probH{n}0c + pfMassDecorrelatedInclParticleTransformerV1JetTags_probH{n}1c'.format(n='WqqWmv'),\n",
    "            'HWWQQtauev': 'pfMassDecorrelatedInclParticleTransformerV1JetTags_probH{n}0c + pfMassDecorrelatedInclParticleTransformerV1JetTags_probH{n}1c'.format(n='WqqWtauev'),\n",
    "            'HWWQQtaumv': 'pfMassDecorrelatedInclParticleTransformerV1JetTags_probH{n}0c + pfMassDecorrelatedInclParticleTransformerV1JetTags_probH{n}1c'.format(n='WqqWtaumv'),\n",
    "            'HWWQQtauhv': 'pfMassDecorrelatedInclParticleTransformerV1JetTags_probH{n}0c + pfMassDecorrelatedInclParticleTransformerV1JetTags_probH{n}1c'.format(n='WqqWtauhv'),\n",
    "            'HWWQQta': ' + '.join([f'pfMassDecorrelatedInclParticleTransformerV1JetTags_probH{n}' for n in ['WqqWtauev0c', 'WqqWtauev1c', 'WqqWtaumv0c', 'WqqWtaumv1c', 'WqqWtauhv0c', 'WqqWtauhv1c']]),\n",
    "            'TTBARbWall': ' + '.join([f'pfMassDecorrelatedInclParticleTransformerV1JetTags_probTop{n}' for n in ['bWqq0c', 'bWqq1c', 'bWq0c', 'bWq1c', 'bWev', 'bWmv', 'bWtauev', 'bWtaumv', 'bWtauhv']]),\n",
    "            'TTBARbWhad': ' + '.join([f'pfMassDecorrelatedInclParticleTransformerV1JetTags_probTop{n}' for n in ['bWqq0c', 'bWqq1c', 'bWq0c', 'bWq1c']]),\n",
    "            'TTBARbWQQ': ' + '.join([f'pfMassDecorrelatedInclParticleTransformerV1JetTags_probTop{n}' for n in ['bWqq0c', 'bWqq1c']]),\n",
    "            'TTBARbWev': ' + '.join([f'pfMassDecorrelatedInclParticleTransformerV1JetTags_probTop{n}' for n in ['bWev']]),\n",
    "            'TTBARbWmv': ' + '.join([f'pfMassDecorrelatedInclParticleTransformerV1JetTags_probTop{n}' for n in ['bWmv']]),\n",
    "            'TTBARbWta': ' + '.join([f'pfMassDecorrelatedInclParticleTransformerV1JetTags_probTop{n}' for n in ['bWtauev', 'bWtaumv', 'bWtauhv']]),\n",
    "            'TTBARbWtauhv': ' + '.join([f'pfMassDecorrelatedInclParticleTransformerV1JetTags_probTop{n}' for n in ['bWtauhv']]),\n",
    "            'TTBARall': ' + '.join([f'pfMassDecorrelatedInclParticleTransformerV1JetTags_probTop{n}' for n in ['bWqq0c', 'bWqq1c', 'bWq0c', 'bWq1c', 'bWev', 'bWmv', 'bWtauev', 'bWtaumv', 'bWtauhv']]),\n",
    "        }\n",
    "        exist_variable_dict.update({k.replace('TTBAR', 'SMTTBARSL'): v for k, v in exist_variable_dict.items() if k.startswith('TTBAR')})\n",
    "        cfg.y_score = f'({exist_variable_dict[sname]}) / (({exist_variable_dict[sname]}) + ({exist_variable_dict[bname]}))'\n",
    "    elif routine == 'GloParT2':\n",
    "        exist_variable_dict = {\n",
    "            'QCD': ' + '.join([f'pfMassDecorrelatedInclParticleTransformerV2HidLayerJetTags_probQCD{n}' for n in ['b', 'bb', 'c', 'cc', 'others']]),\n",
    "            **{f'HIGGS2P{n}': f'pfMassDecorrelatedInclParticleTransformerV2HidLayerJetTags_probH{n}' for n in ['bb', 'cc', 'qq', 'ss', 'bc', 'cs', 'bs', 'gg', 'ee', 'mm', 'tauhtaue', 'tauhtaum', 'tauhtauh']},\n",
    "            **{f'HIG{n}': f'pfMassDecorrelatedInclParticleTransformerV2HidLayerJetTags_probH{n}' for n in ['bb', 'cc', 'qq', 'ss', 'bc', 'cs', 'bs', 'gg', 'ee', 'mm', 'tauhtaue', 'tauhtaum', 'tauhtauh']},\n",
    "        }\n",
    "        cfg.y_score = f'({exist_variable_dict[sname]}) / (({exist_variable_dict[sname]}) + ({exist_variable_dict[bname]}))'\n",
    "    elif routine.endswith('_nonmd'):\n",
    "        if sname.startswith('TTBAR'):\n",
    "            # existing top class defination is fine\n",
    "            pass\n",
    "        if sname == 'ZQQ':\n",
    "            cfg.y_score_sig = 'score_label_Z_bb + score_label_Z_cc + score_label_Z_ss + score_label_Z_qq'\n",
    "            cfg.y_score = f'({cfg.y_score_sig}) / (({cfg.y_score_sig}) + ({cfg.y_score_bkg}))'\n",
    "        elif sname == 'WQQ':\n",
    "            cfg.y_score_sig = 'score_label_W_cs + score_label_W_qq'\n",
    "            cfg.y_score = f'({cfg.y_score_sig}) / (({cfg.y_score_sig}) + ({cfg.y_score_bkg}))'\n",
    "        else:\n",
    "            raise RuntimeError('wrong opt for _nonmd routine')\n",
    "    \n",
    "    # special treatment for XX and X*X* variables\n",
    "    if routine_config == 'WW':\n",
    "        cfg.label += r' ($H\\to W W^*$ discr.)'\n",
    "    elif routine_config == 'WxWx':\n",
    "        cfg.y_score = re.sub(r'H_WW', 'H_WxWx', cfg.y_score)\n",
    "        cfg.label += r' ($H\\to W_x W_x$ discr.)'\n",
    "    elif routine_config == 'WxWxStar':\n",
    "        cfg.y_score = re.sub(r'H_WW', 'H_WxWxStar', cfg.y_score)\n",
    "        cfg.label += r' ($H\\to W_x^* W_x^{(*)}$ discr.)'\n",
    "    elif routine_config == 'WWallmodes':\n",
    "        y_score_sig_2 = re.sub(r'H_WW', 'H_WxWx', cfg.y_score_sig)\n",
    "        y_score_sig_3 = re.sub(r'H_WW', 'H_WxWxStar', cfg.y_score_sig)\n",
    "        cfg.y_score = f'({cfg.y_score_sig} + {y_score_sig_2} + {y_score_sig_3}) / (({cfg.y_score_sig} + {y_score_sig_2} + {y_score_sig_3}) + ({cfg.y_score_bkg}))'\n",
    "        cfg.label += r' ($H\\to WW$ all-mode discr.)'\n",
    "\n",
    "    # special weight parameters for ZQQ and WQQ tagging\n",
    "    if routine in ['v2', 'v3']:\n",
    "        if sname == 'ZQQ':\n",
    "            cfg.y_score_sig = 'score_label_H_bb + score_label_H_cc + score_label_H_ss + 2 * score_label_H_qq' # H_qq score * 2\n",
    "            cfg.y_score = f'({cfg.y_score_sig}) / (({cfg.y_score_sig}) + ({cfg.y_score_bkg}))'\n",
    "        elif sname == 'Zll':\n",
    "            cfg.y_score_sig = 'score_label_H_ss + 2 * score_label_H_qq' # H_qq score * 2\n",
    "            cfg.y_score = f'({cfg.y_score_sig}) / (({cfg.y_score_sig}) + ({cfg.y_score_bkg}))'\n",
    "        elif sname == 'WQQ':# or sname == 'SMTTBARSLQQ':\n",
    "            cfg.y_score_sig = 'score_label_H_cs + (score_label_H_ss + 2*score_label_H_qq) * (1/3)' # use scores constructed from stored Nano branches\n",
    "            # cfg.y_score_sig = 'score_label_H_cs + score_label_H_qq'\n",
    "            cfg.y_score = f'({cfg.y_score_sig}) / (({cfg.y_score_sig}) + ({cfg.y_score_bkg}))'\n",
    "        elif sname == 'TTBARbWhad':\n",
    "            cfg.y_score_sig = 'score_label_Top_bWcs + score_label_Top_bWqq + 1 * (score_label_Top_bWc + score_label_Top_bWs + 2 * score_label_Top_bWq)'\n",
    "            cfg.y_score = f'({cfg.y_score_sig}) / (({cfg.y_score_sig}) + ({cfg.y_score_bkg}))'\n",
    "\n",
    "    # special beta3+ class splitting\n",
    "    if routine.startswith('v3beta3') or routine.startswith('v3beta4') or routine == 'v3':\n",
    "        cfg.y_score = re.sub(r'score_label_Top_bW([a-zA-Z0-9_]+)', r'(score_label_Top_bWp\\1 + score_label_Top_bWm\\1)', cfg.y_score)\n",
    "        cfg.y_score = re.sub(r'score_label_Top_W([a-zA-Z0-9_]+)', r'(score_label_Top_Wp\\1 + score_label_Top_Wm\\1)', cfg.y_score)\n",
    "        cfg.y_score = re.sub(r'score_label_H_bc', r'(score_label_Hp_bc + score_label_Hm_bc)', cfg.y_score)\n",
    "        cfg.y_score = re.sub(r'score_label_H_cs', r'(score_label_Hp_cs + score_label_Hm_cs)', cfg.y_score)\n",
    "    \n",
    "    # for testing W jets from SM ttbar sample: truth W jets have Top_W labels\n",
    "    if sname == 'SMTTBARSLQQ':\n",
    "        cfg.y_sig_flag = '(fj_label == 10) | (fj_label == 11)'\n",
    "\n",
    "    # for testing gg final states:\n",
    "    if sname == 'HIGgg':\n",
    "        if routine_config is None:\n",
    "            cfg.label += ' (Hgg vs QCD)'\n",
    "        elif routine_config == 'ggonly':\n",
    "            cfg.y_score = f'(score_label_H_gg)'\n",
    "            cfg.label += ' (Hgg)'\n",
    "        elif routine_config == '1mqcdothers':\n",
    "            cfg.y_score = f'(1 - score_label_QCD_others)'\n",
    "            cfg.label += ' (1 - QCDothers)'\n",
    "        elif routine_config == 'ggvsQCDf':\n",
    "            cfg.y_score = f'(score_label_H_gg) / ((score_label_H_gg) + (score_label_QCD_bb + score_label_QCD_cc + score_label_QCD_b + score_label_QCD_c))'\n",
    "            cfg.label += ' (Hgg vs QCD:bb+cc+b+c)'\n",
    "        elif routine_config == '1':\n",
    "            cfg.y_sig1 = 'score_label_H_gg + 0.2*score_label_H_WW_qqqq'\n",
    "            cfg.y_bkg1 = 'score_label_QCD_bb + score_label_QCD_cc + score_label_QCD_b + score_label_QCD_c + score_label_QCD_others'\n",
    "            cfg.y_score = f'({cfg.y_sig1}) / (({cfg.y_sig1}) + ({cfg.y_bkg1}))'\n",
    "            cfg.label += ' (Hgg+4q vs QCD)'\n",
    "    return cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a03a7556",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc_curve(sname, bname, samples, pt='low', mass='higgs', xmin=0, ymin=1e-4, xtext=0.5, store_plot=False, subdir='', genm=None, year='2017', plot_kwargs_list=None):\n",
    "    colorlist = ['blue', 'red', 'green', 'darkorange', 'darkviolet', 'cyan']\n",
    "    mpl.rcParams['axes.prop_cycle'] = cycler(color=colorlist)\n",
    "    f, ax = plt.subplots()\n",
    "    year_legend_map = {\n",
    "        '2017': '2017 (UL)',\n",
    "        '2017PUPPIv18': '2017 (UL PUPPIv18)',\n",
    "        '2023': '2023',\n",
    "        '2023BPix': '2023BPix',\n",
    "        '2023FixLTS': '2023FixLTS',\n",
    "    }\n",
    "    hep.cms.label(data=False, loc=1, rlabel='{year} ({com} TeV)'.format(year=year_legend_map[year], com='13.6' if any(y in year for y in ['2022', '2023']) else '13'), ax=ax, fontname='sans-serif')\n",
    "    from scipy.interpolate import interp1d\n",
    "\n",
    "    # create dataframe\n",
    "    for isam, sam in enumerate(samples):\n",
    "        opt = f'{sam}:{sname}:{bname}'\n",
    "        config = getConfig(opt, pt=pt, mass=mass, year=year)\n",
    "\n",
    "        print(opt)\n",
    "        print(\n",
    "            config.filelist['sig'][0].rsplit('/', 1)[0],\n",
    "            [l.split('/')[-1] for l in config.filelist['sig']], [l.split('/')[-1] for l in config.filelist['bkg']],\n",
    "            config.y_sig_flag, config.y_bkg_flag, config.y_score,\n",
    "            config.base_cut, config.mass_cut\n",
    "        )\n",
    "\n",
    "        dfs = uproot.lazy(config.filelist['sig'])\n",
    "        dfb = uproot.lazy(config.filelist['bkg'])\n",
    "        # apply final cut to the dataset\n",
    "        dfs = dfs[ak.numexpr.evaluate(f\"({config.y_sig_flag}) & ({config.base_cut}) & ({config.mass_cut})\", dfs)]\n",
    "        dfb = dfb[ak.numexpr.evaluate(f\"({config.y_bkg_flag}) & ({config.base_cut}) & ({config.mass_cut})\", dfb)]\n",
    "\n",
    "        y_score_s = ak.numexpr.evaluate(config.y_score, dfs)\n",
    "        y_score_b = ak.numexpr.evaluate(config.y_score, dfb)\n",
    "        y_score = ak.concatenate([y_score_s, y_score_b])\n",
    "\n",
    "        if genm is not None:\n",
    "            genm_cut_str = f'abs((fj_gen_mass / {genm}) - 1) < 1e-3'\n",
    "            y_score_s = y_score_s[ak.numexpr.evaluate(genm_cut_str, dfs)]\n",
    "            if bname.startswith('HIG') or bname.startswith('HWW'):\n",
    "                y_score_b = y_score_b[ak.numexpr.evaluate(genm_cut_str, dfb)]\n",
    "            y_score = ak.concatenate([y_score_s, y_score_b])\n",
    "        \n",
    "        # compute quantile on bkg\n",
    "        qs = np.array([1e-1, 1e-2, 1e-3, 1e-4])\n",
    "        thres = np.quantile(y_score_b, 1-qs)\n",
    "        print('quantile thresholds', thres)\n",
    "        print('n_left_signal', [ak.sum(y_score_s > t) for t in thres])\n",
    "\n",
    "        # ## make plots\n",
    "        # f0, ax0 = plt.subplots(figsize=(10, 10))\n",
    "        # nbin, xmin, xmax = 1000, 0., 1.\n",
    "        # hist = bh.Histogram(bh.axis.Regular(nbin, xmin, xmax), storage=bh.storage.Weight())\n",
    "        # hist.fill(y_score_s)\n",
    "        # content, yerr = hist.view().value, np.sqrt(hist.view().variance)\n",
    "        # hep.histplot(content / sum(content), bins=hist.axes[0].edges, yerr=yerr / sum(content), label=sname)\n",
    "        # hist.fill(y_score_b)\n",
    "        # content, yerr = hist.view().value, np.sqrt(hist.view().variance)\n",
    "        # hep.histplot(content / sum(content), bins=hist.axes[0].edges, yerr=yerr / sum(content), label=bname)\n",
    "        # ax0.set_xlabel(f'{sam} {sname} vs {bname} discr.', ha='right', x=1.0); ax0.set_ylabel('A.U.', ha='right', y=1.0)\n",
    "        # ax0.legend()\n",
    "        # ax0.set_xlim(0, 1)\n",
    "        # ax0.set_ylim(1e-6, 1e1), ax0.set_yscale('log')\n",
    "        # ###\n",
    "\n",
    "        y_true = ak.concatenate([ak.ones_like(y_score_s, dtype=bool), ak.zeros_like(y_score_b, dtype=bool)])\n",
    "        print(ak.sum(y_true), ak.sum(~y_true))\n",
    "\n",
    "        fpr, tpr, _thres = m.roc_curve(y_true, y_score)\n",
    "        auc = m.auc(fpr, tpr)\n",
    "        ax.plot(tpr, fpr, label=config.label + r' $\\bf{(AUC: %.4f)}$' % auc, **(plot_kwargs_list[isam] if plot_kwargs_list is not None else {}))\n",
    "        # draw 1% and 0.1% lines\n",
    "        func = interp1d(fpr, tpr)\n",
    "        ax.plot([0, 1], [0.01, 0.01], ':', color='grey')\n",
    "        ax.plot([func(0.01), func(0.01)], [0, 0.01], ':', color='grey')\n",
    "        ax.plot([0, 1], [0.001, 0.001], '-.', color='darkgrey')\n",
    "        ax.plot([func(0.001), func(0.001)], [0, 0.001], '-.', color='darkgrey')\n",
    "\n",
    "\n",
    "    ax.legend(loc='upper right', labelspacing=0.8, prop={'size': 19})# , bbox_to_anchor=(0.03, 0.6)) #prop={'size': 22}, \n",
    "    ax.set_yscale('log'); ax.set_xlim(xmin, 1); ax.set_ylim(ymin, 1)\n",
    "    ax.set_xlabel('Signal efficiency', ha='right', x=1.0); ax.set_ylabel('Background efficiency', ha='right', y=1.0); \n",
    "    x_text, y_text = 0.0, 0.65\n",
    "    # x_text, y_text = xtext, 0.05\n",
    "    if genm is not None:\n",
    "        ax.text(x_text+0.03, y_text+0.18, config.title, fontsize=22, fontweight='bold', transform=ax.transAxes)\n",
    "        ax.text(x_text+0.03, y_text+0.12, r'$m_{H} = %d$ GeV' % genm, fontsize=18, fontweight='bold', transform=ax.transAxes)\n",
    "        ax.text(x_text+0.03, y_text+0.06, config.subtitle, fontsize=18, transform=ax.transAxes)\n",
    "        ax.text(x_text+0.03, y_text+0.00, config.subtitle2, fontsize=18, transform=ax.transAxes)\n",
    "    else:\n",
    "        ax.text(x_text+0.03, y_text+0.13, config.title, fontsize=22, fontweight='bold', transform=ax.transAxes)\n",
    "        ax.text(x_text+0.03, y_text+0.06, config.subtitle, fontsize=18, transform=ax.transAxes)\n",
    "        ax.text(x_text+0.03, y_text+0.00, config.subtitle2, fontsize=18, transform=ax.transAxes)\n",
    "    if store_plot:\n",
    "        os.makedirs(f'./plots/{subdir}', exist_ok=True)\n",
    "        plt.savefig(f'./plots/{subdir}/roc_{sname}_{bname}_{\"-\".join(samples).replace(\";\",\"\")}_{pt}_{mass}_{year}_{genm}.pdf', bbox_inches='tight')\n",
    "        plt.savefig(f'./plots/{subdir}/roc_{sname}_{bname}_{\"-\".join(samples).replace(\";\",\"\")}_{pt}_{mass}_{year}_{genm}.png', bbox_inches='tight')\n",
    "        print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a270fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "year = '2023'\n",
    "for pt, ptsig, mass, genm in [('low', 'LO', 'higgs', 125)]:\n",
    "# # for pt, ptsig, mass, genm in [('high', 'HI', 'higgs', 125)]:\n",
    "    # plot_roc_curve(f'HIG{ptsig}bb', f'QCD', samples=['PNetMD', 'v2', 'v3'], pt=pt, mass=mass, year=year, store_plot=True, subdir='v3beta4_hqq', xtext=0.5, genm=genm)\n",
    "    plot_roc_curve(f'HIG{ptsig}bb', f'QCD', samples=['PNetMD', 'v3'], pt=pt, mass=mass, year=year, store_plot=True, subdir='v3beta4_hqq', xtext=0.5, genm=genm, plot_kwargs_list=[{\"ls\":\"--\"},{\"ls\":\"-\"}])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9374a789",
   "metadata": {},
   "source": [
    "# Mass regression (Hbb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "757a112a",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dict = {\n",
    "    'QCD': 'QCD',\n",
    "    'XQQbb': r'H$\\rightarrow$bb', 'XQQcc': r'H$\\rightarrow$cc', 'XQQss': r'H$\\rightarrow$ss', 'XQQqq': r'H$\\rightarrow$qq (u/d/s)', 'XQQtauhtaue': r'H$\\rightarrow\\tau_h\\tau_e$', 'XQQtauhtaum': r'H$\\rightarrow\\tau_h\\tau_\\mu$', 'XQQtauhtauh': r'H$\\rightarrow\\tau_h\\tau_h$', \n",
    "}\n",
    "samples = { # (label, path)\n",
    "    'sd': ('Soft-drop', '/ceph/cms/store/user/woodson/glopart-plotter/predict/ak8_MD_inclv10beta4_ul_manual.nlayer10.vispart_as_resid.ddp4-bs640-lr1p2e-3.nepoch100.farm221.best_epoch'),\n",
    "    'pnetofc': ('ParticleNet', '/ceph/cms/store/user/woodson/glopart-plotter/predict/ak8_MD_inclv10beta4_ul_manual.nlayer10.vispart_as_resid.ddp4-bs640-lr1p2e-3.nepoch100.farm221.best_epoch'),\n",
    "    # 'v3.modevisible': ('GloParT 3 (generic)', '/ceph/cms/store/user/woodson/glopart-plotter/predict/ak8_MD_inclv10beta4_ul_manual.nlayer10.vispart_as_resid.ddp4-bs640-lr1p2e-3.nepoch100.farm221.best_epoch'),\n",
    "    'v3.modex2p': ('GloParT', '/ceph/cms/store/user/woodson/glopart-plotter/predict/ak8_MD_inclv10beta4_ul_manual.nlayer10.vispart_as_resid.ddp4-bs640-lr1p2e-3.nepoch100.farm221.best_epoch'),\n",
    "}\n",
    "\n",
    "# discr_sigeff = 30\n",
    "# for discr_sigeff in [30, 100]:\n",
    "#     for year in ['2017', '2017PUPPIv18', '2023', '2023BPix']:\n",
    "#         for genm in [50, 125, 250, 350]:\n",
    "for discr_sigeff in [30]:\n",
    "    for year in ['2023']:\n",
    "        for genm in [125]:\n",
    "            gen_mode = 'vispart'\n",
    "\n",
    "            year_file_id = {\n",
    "                '2017': '',\n",
    "                '2023': 'run3_2023_',\n",
    "                '2023BPix': 'run3_2023bpix_',\n",
    "                '2017PUPPIv18': 'run2_repuppi_',\n",
    "            }[year]\n",
    "            year_legend_map = {\n",
    "                '2017': '2017 (UL)',\n",
    "                '2017PUPPIv18': '2017 (UL PUPPIv18)',\n",
    "                '2023': '2023',\n",
    "                '2023BPix': '2023BPix',\n",
    "            }\n",
    "\n",
    "            # for computing the discr value\n",
    "            dff = uproot.lazy(glob.glob(f'/ceph/cms/store/user/woodson/glopart-plotter/predict/ak8_MD_inclv10beta4_ul_manual.nlayer10.vispart_as_resid.ddp4-bs640-lr1p2e-3.nepoch100.farm221.best_epoch/pred_{year_file_id}higlo*.root'))\n",
    "            dff = dff[dff.fj_gen_mass == genm]\n",
    "            dff = dff[ak.numexpr.evaluate('(fj_pt>200) & (fj_pt<2500)', dff)]\n",
    "            pnet_discr = lambda s: f'(pfMassDecorrelatedParticleNetJetTags_probX{s}) / ((pfMassDecorrelatedParticleNetJetTags_probX{s}) + (pfMassDecorrelatedParticleNetJetTags_probQCDb + pfMassDecorrelatedParticleNetJetTags_probQCDbb + pfMassDecorrelatedParticleNetJetTags_probQCDc + pfMassDecorrelatedParticleNetJetTags_probQCDcc + pfMassDecorrelatedParticleNetJetTags_probQCDothers))'\n",
    "            glopart3_discr = lambda s: f'(score_label_H_{s}) / ((score_label_H_{s}) + (score_label_QCD_b + score_label_QCD_bb + score_label_QCD_c + score_label_QCD_cc + score_label_QCD_others))'\n",
    "\n",
    "            truth_selection = {\n",
    "                'H_bb': '(fj_label == 17)',\n",
    "                'H_cc': '(fj_label == 18)',\n",
    "                'H_qq': '(fj_label == 19) | (fj_label == 20)',\n",
    "                'H_tauhtaue': '(fj_label == 27)',\n",
    "                'H_tauhtaum': '(fj_label == 28)',\n",
    "                'H_tauhtauh': '(fj_label == 29)',\n",
    "            }\n",
    "            categories = {\n",
    "                'H_bb': ['H_bb'],\n",
    "                'H_cc': ['H_cc'],\n",
    "                'H_qq': ['H_qq'],\n",
    "                'H_tauhtaue': ['H_tauhtaue'],\n",
    "            }\n",
    "            categories_2p = {\n",
    "                'H_bb': ['H_bb','H_cc','H_ss','H_qq','Hp_cs','Hm_cs'],\n",
    "                'H_cc': ['H_bb','H_cc','H_ss','H_qq','Hp_cs','Hm_cs'],\n",
    "                'H_qq': ['H_bb','H_cc','H_ss','H_qq','Hp_cs','Hm_cs'],\n",
    "            }\n",
    "\n",
    "            ## define GloParT 3 reg computing utilities\n",
    "            weighted = lambda values, weights: np.sum(values * weights, axis=0) / np.sum(weights, axis=0)\n",
    "            get_values = lambda df_, categories_: np.array([ak.numexpr.evaluate(f'output_target_res_mass_factor_label_{l}', df_) for l in categories_])\n",
    "            # get_weights = lambda df_, categories_: np.array([ak.numexpr.evaluate(f'score_label_{l}', df_) for l in categories_])\n",
    "            get_weights = lambda df_, categories_: np.array([ak.numexpr.evaluate(f'score_label_{l}', df_) * (2. if l == 'H_qq' else 1.) for l in categories_])\n",
    "\n",
    "            if genm == 50:\n",
    "                nbin, xmin, xmax = 100, 0, 100\n",
    "            elif genm == 125:\n",
    "                nbin, xmin, xmax = 50, 0, 250\n",
    "            elif genm == 250 or genm == 350:\n",
    "                nbin, xmin, xmax = 200, 0, 500\n",
    "\n",
    "            colorlist = ['black', 'blue', 'red', 'green', 'darkorange', 'darkviolet', 'cyan', 'greenyellow']\n",
    "            mpl.rcParams['axes.prop_cycle'] = cycler(color=colorlist)\n",
    "\n",
    "            # for ch in ['H_bb', 'H_cc', 'H_qq']:\n",
    "            for ch in ['H_bb']:\n",
    "                # first compute the discr value\n",
    "                dff_truth = dff[ak.numexpr.evaluate(truth_selection[ch], dff)]\n",
    "                val = ak.numexpr.evaluate(pnet_discr(ch[2:]), dff_truth) # H_bb, H_cc, H_qq\n",
    "                discr_thres = np.quantile(val, 1-discr_sigeff/100)\n",
    "                print(ch, f'{discr_sigeff=}, {discr_thres=}')\n",
    "\n",
    "                # no SD cut!\n",
    "                preselection = {\n",
    "                    'H_bb': f\"(abs(fj_eta)<2.4) & (fj_pt>200) & (fj_pt<2500) & ({pnet_discr('bb')} > {discr_thres})\",\n",
    "                    'H_cc': f\"(abs(fj_eta)<2.4) & (fj_pt>200) & (fj_pt<2500) & ({pnet_discr('cc')} > {discr_thres})\",\n",
    "                    'H_qq': f\"(abs(fj_eta)<2.4) & (fj_pt>200) & (fj_pt<2500) & ({pnet_discr('qq')} > {discr_thres})\",\n",
    "                    # 'H_tauhtaue': f\"(fj_pt>200) & (fj_pt<2500) & ({pnet_discr('tauhtaue')} > {discr_thres})\",\n",
    "                }\n",
    "\n",
    "                f, ax = plt.subplots(figsize=(10,10))\n",
    "                hep.cms.label(data=False, loc=1, rlabel='{year} ({com} TeV)'.format(year=year_legend_map[year], com='13.6' if any(y in year for y in ['2022', '2023']) else '13'), ax=ax, fontname='sans-serif')\n",
    "\n",
    "                for n, (lab, path) in samples.items():\n",
    "                    df = uproot.lazy(glob.glob(path + f'/pred_{year_file_id}higlo*.root'))\n",
    "                    df = df[df.fj_gen_mass == genm]\n",
    "                    df = df[ak.numexpr.evaluate(preselection[ch], df)]\n",
    "\n",
    "                    _df = df[ak.numexpr.evaluate(truth_selection[ch], df)]\n",
    "                    print(f'{len(_df)=}')\n",
    "\n",
    "                    if n == 'sd':\n",
    "                        var = 'fj_sdmass'\n",
    "                        array = ak.numexpr.evaluate(var, _df)\n",
    "                        ls = \"-.\"\n",
    "                    elif n == 'pnetofc':\n",
    "                        var = 'pfParticleNetMassRegressionJetTags_mass'\n",
    "                        array = ak.numexpr.evaluate(var, _df)\n",
    "                        ls = \"--\"\n",
    "                    elif n == 'v1':\n",
    "                        var = 'pfMassDecorrelatedInclParticleTransformerV1JetTags_mass'\n",
    "                        array = ak.numexpr.evaluate(var, _df)\n",
    "                    elif n == 'v2':\n",
    "                        var = 'output_target_res_mass_factor * fj_mass' if gen_mode == 'res' else 'output_target_parts_mass_factor * fj_mass'\n",
    "                        array = ak.numexpr.evaluate(var, _df)\n",
    "                    elif n.startswith('v3'): # multiple modes!!\n",
    "                        if n == 'v3.modexbb':\n",
    "                            categories_map = categories\n",
    "                        elif n == 'v3.modex2p':\n",
    "                            categories_map = categories_2p\n",
    "                            ls = \"-\"\n",
    "                        if n in ['v3.modexbb', 'v3.modex2p']:\n",
    "                            # factor = weighted(get_values(_df, categories_mode[n.split('.')[-1]]), get_weights(_df, categories_mode[n.split('.')[-1]]))\n",
    "                            factor = weighted(get_values(_df, categories_map[ch]), get_weights(_df, categories_map[ch]))\n",
    "                            array = factor * _df.fj_mass\n",
    "                            # vispart_as_resid\n",
    "                            array = array + ak.numexpr.evaluate('output_target_parts_mass_factor * fj_mass', _df)\n",
    "                            var = 'weighted: %s, vispart_as_resid' % str(categories_map[ch])\n",
    "                        elif n == 'v3.modevisible':\n",
    "                            var = 'output_target_parts_mass_factor * fj_mass'\n",
    "                            array = ak.numexpr.evaluate(var, _df)\n",
    "                    \n",
    "                    print(ch, n, var)\n",
    "\n",
    "                    hist = bh.Histogram(bh.axis.Regular(nbin, xmin, xmax), storage=bh.storage.Weight())\n",
    "                    hist.fill(array)\n",
    "                    # content, yerr = hist.view().value / sum(hist.view().value), np.sqrt(hist.view().variance) / sum(hist.view().value)\n",
    "                    content, yerr = hist.view().value, np.sqrt(hist.view().variance)\n",
    "\n",
    "                    # calculate guassian KDE metric\n",
    "                    from scipy.stats import gaussian_kde\n",
    "                    array = ak.to_numpy(array)\n",
    "                    kde = gaussian_kde(array, bw_method=0.2)\n",
    "                    x_grid = np.linspace(xmin, xmax, 10001)\n",
    "                    y = kde.evaluate(x_grid)\n",
    "                    halfmax = y.max() / 2\n",
    "                    maxpos = y.argmax()\n",
    "                    leftpos = (np.abs(y[:maxpos] - halfmax)).argmin()\n",
    "                    rightpos = (np.abs(y[maxpos:] - halfmax)).argmin() + maxpos\n",
    "                    peak_value = x_grid[maxpos]\n",
    "                    fwhm = x_grid[rightpos] - x_grid[leftpos]\n",
    "                    # print(f'Peak value: {peak_value}', f'FWHM: {fwhm}')\n",
    "                    if n == 'pnetofc' and genm in [50, 250, 350]:\n",
    "                        fwhm = 'N/A'\n",
    "\n",
    "                    # hep.histplot(content, bins=hist.axes[0].edges, yerr=yerr, label=lab + r'  $\\bf{(\\mu=%.1f,\\,\\sigma=%.1f,\\,\\epsilon_{%d\\pm\\! 10}=%.1f\\%% )}$' % (np.mean(array), np.std(array), genm, sum((array > genm-10) & (array < genm+10)) / len(array) * 100))\n",
    "                    hep.histplot(content/np.sum(content), ls=ls, bins=hist.axes[0].edges, yerr=yerr/np.sum(content), label=lab + r' $\\bf{(m_{peak}=%.1f,\\,FWHM=%s)}$' % (peak_value, f'{fwhm:.1f}' if not isinstance(fwhm, str) else fwhm))\n",
    "                    \n",
    "\n",
    "                ax.legend(loc=\"upper right\", labelspacing=0.4, prop={'size': 18},  bbox_to_anchor=(1.0, 0.9))\n",
    "                ax.set_xlabel(r'$m_{reco}$ [GeV]', ha='right', x=1.0); ax.set_ylabel('A.U.', ha='right', y=1.0);\n",
    "\n",
    "                ax.set_xlim(xmin, xmax); ax.set_ylim(0, ax.get_ylim()[1]*1.5)\n",
    "                ytext = 0.4\n",
    "                ax.text(0.03, 0.27+ytext, label_dict[f'XQQ{ch[2:]}'], fontsize=22, fontweight='bold', transform=ax.transAxes)\n",
    "                ax.text(0.03, 0.22+ytext, r'$m_{H} = %d$ GeV' % genm, fontsize=18, fontweight='bold', transform=ax.transAxes)\n",
    "                ax.text(0.03, 0.16+ytext, r'$\\epsilon_{sig} = %d$%s selected' % (discr_sigeff, '%'), fontsize=18, transform=ax.transAxes)\n",
    "                ax.text(0.03, 0.11+ytext, r'by ParticleNet', fontsize=18, transform=ax.transAxes)\n",
    "                ax.text(0.03, 0.04+ytext, r'$p_T > 200$ GeV, $|\\eta|$ < 2.4', fontsize=18, transform=ax.transAxes)\n",
    "                # ax.text(0.03, 0.04+ytext, r'$p_T > 200$ GeV, $m_{SD}$ > 0, $\\sigma_{m_{reco}} > 20$ GeV', fontsize=18, transform=ax.transAxes)\n",
    "                os.makedirs('./plots/v3beta4_reg', exist_ok=True)\n",
    "                plt.savefig(f'./plots/v3beta4_reg/regmass_hqq_{ch}_m{genm}_sigeff{discr_sigeff}_{year}.pdf', bbox_inches='tight')\n",
    "                plt.savefig(f'./plots/v3beta4_reg/regmass_hqq_{ch}_m{genm}_sigeff{discr_sigeff}_{year}.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1290bb9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b58c2ce-e3e8-4fee-9d2b-9253c0a9731d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

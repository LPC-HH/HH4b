{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Misc Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import vector\n",
    "import os\n",
    "from xgboost import XGBClassifier\n",
    "from pathlib import Path\n",
    "\n",
    "import HH4b.utils as utils\n",
    "from HH4b.utils import ShapeVar\n",
    "import HH4b.plotting as plotting\n",
    "from HH4b.postprocessing import PostProcess, Region\n",
    "import HH4b.postprocessing as postprocessing\n",
    "from HH4b.hh_vars import samples, years, samples_run3\n",
    "\n",
    "import hist\n",
    "import matplotlib.pyplot as plt\n",
    "import mplhep as hep\n",
    "import matplotlib.ticker as mticker\n",
    "import importlib\n",
    "\n",
    "formatter = mticker.ScalarFormatter(useMathText=True)\n",
    "formatter.set_powerlimits((-3, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# automatically reloads imported files on edits\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAIN_DIR = Path(\"../../../\")\n",
    "plot_dir = MAIN_DIR / \"../plots/PostProcess/24Apr24Legacy\"\n",
    "plot_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "data_dir = \"/eos/uscms/store/user/rkansal/bbbb/skimmer/24Apr19LegacyFixes_v12_private_signal/\"\n",
    "dirs = {data_dir: samples}\n",
    "\n",
    "bdt_model_name = \"24Apr21_legacy_vbf_vars\"\n",
    "bdt_config = \"24Apr21_legacy_vbf_vars\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_process_run3_samples(data_dir, year, samples_run3):\n",
    "    events_dict = postprocessing.load_run3_samples(data_dir, year, True, samples_run3)\n",
    "    legacy_label = \"Legacy\"\n",
    "\n",
    "    # define BDT model\n",
    "    bdt_model = XGBClassifier()\n",
    "    bdt_model.load_model(fname=f\"../boosted/bdt_trainings_run3/{bdt_model_name}/trained_bdt.model\")\n",
    "    # get function\n",
    "    make_bdt_dataframe = importlib.import_module(\n",
    "        f\".{bdt_config}\", package=\"HH4b.boosted.bdt_trainings_run3\"\n",
    "    )\n",
    "\n",
    "    # inference and assign score\n",
    "    events_dict_postprocess = {}\n",
    "    for key in events_dict:\n",
    "        bdt_events = make_bdt_dataframe.bdt_dataframe(events_dict[key])\n",
    "        preds = bdt_model.predict_proba(bdt_events)\n",
    "        PostProcess.add_bdt_scores(bdt_events, preds)\n",
    "        bdt_events[\"weight\"] = events_dict[key][\"finalWeight\"].to_numpy()\n",
    "        bdt_events[\"H2TXbb\"] = events_dict[key][f\"bbFatJetPNetTXbb{legacy_label}\"].to_numpy()[:, 1]\n",
    "        bdt_events[\"H2PNetMass\"] = events_dict[key][f\"bbFatJetPNetMass{legacy_label}\"].to_numpy()[\n",
    "            :, 1\n",
    "        ]\n",
    "        events_dict[key] = bdt_events\n",
    "\n",
    "    return events_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bg_keys = [\"ttbar\", \"vhtobb\", \"gghtobb\"]\n",
    "processes = [\"data\"] + [\"hh4b\"] + bg_keys\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "samples_run3 = deepcopy(samples_run3)\n",
    "\n",
    "for year in samples_run3:\n",
    "    for key in list(samples_run3[year].keys()):\n",
    "        if key not in processes:\n",
    "            samples_run3[year].pop(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bdt_training_keys = PostProcess.get_bdt_training_keys(\"24Apr21_legacy_vbf_vars\")\n",
    "\n",
    "events_dict_postprocess = {}\n",
    "cutflows = {}\n",
    "for year in years:\n",
    "    print(f\"\\n{year}\")\n",
    "    events_dict_postprocess[year] = load_process_run3_samples(data_dir, year, samples_run3)\n",
    "\n",
    "print(\"Loaded all years\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events_combined = PostProcess.combine_run3_samples(events_dict_postprocess, processes, bg_keys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## S/B optimization using the ABCD method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nevents_sidebands(events, cut, mass, mass_window):\n",
    "    mw_size = mass_window[1] - mass_window[0]\n",
    "\n",
    "    # get yield in left sideband\n",
    "    cut_mass_0 = (events[mass] < mass_window[0]) & (events[mass] > (mass_window[0] - mw_size / 2))\n",
    "\n",
    "    # get yield in right sideband\n",
    "    cut_mass_1 = (events[mass] < mass_window[1] + mw_size / 2) & (events[mass] > mass_window[1])\n",
    "\n",
    "    return np.sum(events[\"weight\"][(cut_mass_0 | cut_mass_1) & cut])\n",
    "\n",
    "\n",
    "def get_nevents_signal(events, cut, mass, mass_window):\n",
    "    cut_mass = (events[mass] >= mass_window[0]) & (events[mass] <= mass_window[1])\n",
    "\n",
    "    # get yield in Higgs mass window\n",
    "    return np.sum(events[\"weight\"][cut & cut_mass])\n",
    "\n",
    "\n",
    "def get_nevents_nosignal(events, cut, mass, mass_window):\n",
    "    cut_mass = (events[mass] >= mass_window[0]) & (events[mass] <= mass_window[1])\n",
    "\n",
    "    # get yield in Higgs mass window\n",
    "    return np.sum(events[\"weight\"][cut & ~cut_mass])\n",
    "\n",
    "\n",
    "def get_s_b(events_dict, cut_dict, mass, mass_window):\n",
    "    s = get_nevents_signal(events_dict[\"hh4b\"], cut_dict[\"hh4b\"], mass, mass_window)\n",
    "    bd = get_nevents_sidebands(events_dict[\"data\"], cut_dict[\"data\"], mass, mass_window)\n",
    "\n",
    "    bgmcb = 0\n",
    "    bgmcs = 0\n",
    "    for key in bg_keys:\n",
    "        bgmcb += get_nevents_sidebands(events_dict[key], cut_dict[key], mass, mass_window)\n",
    "        bgmcs += get_nevents_signal(events_dict[key], cut_dict[key], mass, mass_window)\n",
    "\n",
    "    b = bd - bgmcb + bgmcs\n",
    "    return s, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def abcd(events_dict, txbb_cut, bdt_cut, mass, mass_window):\n",
    "    dicts = {\"data\": [], **{key: [] for key in bg_keys}}\n",
    "\n",
    "    for key in [\"hh4b\", \"data\"] + bg_keys:\n",
    "        events = events_dict[key]\n",
    "        cut = (events[\"bdt_score\"] > bdt_cut) & (events[\"H2TXbb\"] > txbb_cut)\n",
    "\n",
    "        if key == \"hh4b\":\n",
    "            s = get_nevents_signal(events, cut, mass, mass_window)\n",
    "            continue\n",
    "\n",
    "        # region A\n",
    "        if key == \"data\":\n",
    "            dicts[key].append(0)\n",
    "        else:\n",
    "            dicts[key].append(get_nevents_signal(events, cut, mass, mass_window))\n",
    "\n",
    "        # region B\n",
    "        dicts[key].append(get_nevents_nosignal(events, cut, mass, mass_window))\n",
    "\n",
    "        cut = (events[\"bdt_score\"] < 0.6) & (events[\"H2TXbb\"] < 0.8)\n",
    "        # region C\n",
    "        dicts[key].append(get_nevents_signal(events, cut, mass, mass_window))\n",
    "        # region D\n",
    "        dicts[key].append(get_nevents_nosignal(events, cut, mass, mass_window))\n",
    "\n",
    "    bg_tots = np.sum([dicts[key] for key in bg_keys], axis=0)\n",
    "    dmt = np.array(dicts[\"data\"]) - bg_tots\n",
    "    bqcd = dmt[2] * dmt[1] / dmt[3]\n",
    "    # print(dicts)\n",
    "\n",
    "    return s, bqcd + bg_tots[0], dicts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the optimization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mass = \"H2PNetMass\"\n",
    "mass_window = [115, 135]\n",
    "\n",
    "txbb_cut_list = []\n",
    "bdt_cut_list = []\n",
    "s_list = []\n",
    "b_list = []\n",
    "b_vs_s_list = []\n",
    "nevents_regionB_list = []\n",
    "d_list = []\n",
    "for txbb_cut in np.arange(0.95, 1, 0.002):\n",
    "    for bdt_cut in np.arange(0.90, 1, 0.005):\n",
    "        s, b, d = abcd(events_combined, txbb_cut, bdt_cut, mass, mass_window)\n",
    "\n",
    "        # derive values\n",
    "        nevents_regionB = d[\"data\"][1]\n",
    "        nevents_regionB_list.append(nevents_regionB)\n",
    "\n",
    "        txbb_cut_list.append(txbb_cut)\n",
    "        bdt_cut_list.append(bdt_cut)\n",
    "        s_list.append(s)\n",
    "        b_list.append(b)\n",
    "        b_vs_s_list.append(b / s)\n",
    "        d_list.append(d)\n",
    "\n",
    "s, tot, dicts = abcd(events_combined, 0.99, 0.955, mass, mass_window)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### add bg_tots 0, 1 to derive b_smooth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bg_tots_list = []\n",
    "\n",
    "for d in d_list:\n",
    "    bg_tots = np.sum([d[key] for key in bg_keys], axis=0)\n",
    "    bg_tots_list.append(bg_tots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bg_tots_arr = np.array(bg_tots_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_array = np.array(b_list)\n",
    "s_array = np.array(s_list)\n",
    "nevents_regionB_array = np.array(nevents_regionB_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2√(B+sigma_B^2)/S\n",
    "# sigma_B = B/sqrt(total data in the A + B regions)\n",
    "# total data in A region = b\n",
    "# total data in B region: nevents_regionB_array\n",
    "sigma_B = b_array / np.sqrt(b_array + nevents_regionB_array)\n",
    "double_sqrtBPlusVarB_vs_s = 2 * np.sqrt(b_array + np.square(sigma_B)) / s_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2*sqrt(B)/S\n",
    "double_sqrtB_vs_s = 2 * np.sqrt(b_array) / s_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asimov = np.sqrt(2 * ((s_array + b_array) * np.log(1 + s_array / b_array) - s_array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_billy = pd.DataFrame(\n",
    "    {\n",
    "        \"txbb_cut\": txbb_cut_list,\n",
    "        \"bdt_cut\": bdt_cut_list,\n",
    "        \"s\": s_list,\n",
    "        \"b\": b_list,\n",
    "        \"b_vs_s\": b_vs_s_list,\n",
    "        \"2*sqrt(B)/S\": double_sqrtB_vs_s,\n",
    "        \"2*sqrt(B+sigma_B^2)/S\": double_sqrtBPlusVarB_vs_s,\n",
    "        \"nevents_regionB\": nevents_regionB,\n",
    "        \"asimov\": asimov,\n",
    "        \"bg_tots_0\": bg_tots_arr[:, 0],\n",
    "        \"bg_tots_1\": bg_tots_arr[:, 1],\n",
    "    }\n",
    ")\n",
    "\n",
    "df_billy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate smoothed nevents_regionB_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import gammainc, gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = [1.11458993, 1.21115674, 0.68137886, 0.70183846]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Txbb = np.array(df_billy[\"txbb_cut\"])\n",
    "BDT = np.array(df_billy[\"bdt_cut\"])\n",
    "Txbb_BDT_rows = np.concatenate([Txbb.reshape(-1, 1), BDT.reshape(-1, 1)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit data\n",
    "def one_minus_cdf_2d(x, a, b, scale1, scale2):\n",
    "    x1 = x[:, 0]\n",
    "    x2 = x[:, 1]\n",
    "\n",
    "    sx1 = x1 / scale1\n",
    "    sx2 = x2 / scale2\n",
    "\n",
    "    arg1 = sx1**3 + (sx1) ** 2\n",
    "    arg2 = sx2**3 + (sx2) ** 2\n",
    "\n",
    "    cdf_1 = gammainc(a, arg1) / gamma(a)\n",
    "    cdf_2 = gammainc(b, arg2) / gamma(b)\n",
    "\n",
    "    return (1 - cdf_1) * (1 - cdf_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nevents_regionB_pred = one_minus_cdf_2d(Txbb_BDT_rows, *params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_billy[\"nevents_regionB_pred\"] = nevents_regionB_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate b_smooth in region A using the smooth nevents_regionB_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf = df_billy\n",
    "b_smooth = (pdf[\"b\"] - pdf[\"bg_tots_0\"]) * (pdf[\"nevents_regionB_pred\"] - pdf[\"bg_tots_1\"]) / (\n",
    "    pdf[\"nevents_regionB\"] - pdf[\"bg_tots_1\"]\n",
    ") + pdf[\"bg_tots_0\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf[\"b_smooth\"] = b_smooth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate FoM using b_smooth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "double_sqrtBSmooth_vs_s = 2 * np.sqrt(b_smooth) / s_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf[\"double_sqrtBSmooth_vs_s\"] = double_sqrtBSmooth_vs_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_greater_0pt6 = df_billy[\"s\"] > 0.6\n",
    "s_greater_0pt7 = df_billy[\"s\"] > 0.7\n",
    "s_greater_1 = df_billy[\"s\"] > 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "best_row_s_greater_1 = df_billy[s_greater_1][\"double_sqrtBSmooth_vs_s\"].argmin()\n",
    "df_billy[s_greater_1].iloc[best_row_s_greater_1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "best_row_s_greater_0pt7 = df_billy[s_greater_0pt7][\"double_sqrtBSmooth_vs_s\"].argmin()\n",
    "df_billy[s_greater_0pt7].iloc[best_row_s_greater_0pt7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_row_s_greater_0pt6 = df_billy[s_greater_0pt6][\"double_sqrtBSmooth_vs_s\"].argmin()\n",
    "df_billy[s_greater_0pt6].iloc[best_row_s_greater_0pt6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_row = df_billy[\"double_sqrtBSmooth_vs_s\"].argmin()\n",
    "df_billy.iloc[best_row]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_greater_1 = df_billy[\"b\"] > 1\n",
    "best_row_b_greater_1 = df_billy[b_greater_1][\"double_sqrtBSmooth_vs_s\"].argmin()\n",
    "df_billy[b_greater_1].iloc[best_row_b_greater_1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_greater_2 = df_billy[\"b\"] > 2\n",
    "best_row_b_greater_2 = df_billy[b_greater_2][\"double_sqrtBSmooth_vs_s\"].argmin()\n",
    "df_billy[b_greater_2].iloc[best_row_b_greater_2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_greater_2pt8 = df_billy[\"b\"] > 2.8\n",
    "best_row_b_greater_2pt8 = df_billy[b_greater_2pt8][\"double_sqrtBSmooth_vs_s\"].argmin()\n",
    "df_billy[b_greater_2pt8].iloc[best_row_b_greater_2pt8]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

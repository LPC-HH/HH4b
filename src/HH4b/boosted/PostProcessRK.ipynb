{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Misc Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import importlib\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mticker\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "import HH4b.plotting as plotting\n",
    "import HH4b.postprocessing as postprocessing\n",
    "from HH4b.hh_vars import samples, samples_run3, years\n",
    "from HH4b.postprocessing import PostProcess\n",
    "\n",
    "formatter = mticker.ScalarFormatter(useMathText=True)\n",
    "formatter.set_powerlimits((-3, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# automatically reloads imported files on edits\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAIN_DIR = Path(\"../../../\")\n",
    "plot_dir = MAIN_DIR / \"../plots/PostProcess/24Apr24Legacy\"\n",
    "plot_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "data_dir = \"/ceph/cms/store/user/rkansal/bbbb/skimmer/24Apr19LegacyFixes_v12_private_signal/\"\n",
    "dirs = {data_dir: samples}\n",
    "\n",
    "bdt_model_name = \"24Apr21_legacy_vbf_vars\"\n",
    "bdt_config = \"24Apr21_legacy_vbf_vars\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_process_run3_samples(data_dir, year, samples_run3):\n",
    "    events_dict = postprocessing.load_run3_samples(data_dir, year, True, samples_run3)\n",
    "    legacy_label = \"Legacy\"\n",
    "\n",
    "    # define BDT model\n",
    "    bdt_model = XGBClassifier()\n",
    "    bdt_model.load_model(fname=f\"../boosted/bdt_trainings_run3/{bdt_model_name}/trained_bdt.model\")\n",
    "    # get function\n",
    "    make_bdt_dataframe = importlib.import_module(\n",
    "        f\".{bdt_config}\", package=\"HH4b.boosted.bdt_trainings_run3\"\n",
    "    )\n",
    "\n",
    "    # inference and assign score\n",
    "    events_dict_postprocess = {}\n",
    "    for key in events_dict:\n",
    "        bdt_events = make_bdt_dataframe.bdt_dataframe(events_dict[key])\n",
    "        preds = bdt_model.predict_proba(bdt_events)\n",
    "        PostProcess.add_bdt_scores(bdt_events, preds)\n",
    "        bdt_events[\"weight\"] = events_dict[key][\"finalWeight\"].to_numpy()\n",
    "        bdt_events[\"H2TXbb\"] = events_dict[key][f\"bbFatJetPNetTXbb{legacy_label}\"].to_numpy()[:, 1]\n",
    "        bdt_events[\"H2PNetMass\"] = events_dict[key][f\"bbFatJetPNetMass{legacy_label}\"].to_numpy()[\n",
    "            :, 1\n",
    "        ]\n",
    "        events_dict[key] = bdt_events\n",
    "\n",
    "    return events_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processes = [\"data\"] + [\"hh4b\"] + [\"ttbar\"]\n",
    "\n",
    "for year in samples_run3:\n",
    "    for key in list(samples_run3[year].keys()):\n",
    "        if key not in processes:\n",
    "            samples_run3[year].pop(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bdt_training_keys = PostProcess.get_bdt_training_keys(\"24Apr21_legacy_vbf_vars\")\n",
    "\n",
    "events_dict_postprocess = {}\n",
    "cutflows = {}\n",
    "for year in years:\n",
    "    print(f\"\\n{year}\")\n",
    "    events_dict_postprocess[year] = load_process_run3_samples(data_dir, year, samples_run3)\n",
    "\n",
    "print(\"Loaded all years\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events_combined = PostProcess.combine_run3_samples(\n",
    "    events_dict_postprocess, processes, [\"qcd\", \"ttbar\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## S/B optimization using the ABCD method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nevents_sidebands(events, cut, mass, mass_window):\n",
    "    mw_size = mass_window[1] - mass_window[0]\n",
    "\n",
    "    # get yield in left sideband\n",
    "    cut_mass_0 = (events[mass] < mass_window[0]) & (events[mass] > (mass_window[0] - mw_size / 2))\n",
    "\n",
    "    # get yield in right sideband\n",
    "    cut_mass_1 = (events[mass] < mass_window[1] + mw_size / 2) & (events[mass] > mass_window[1])\n",
    "\n",
    "    return np.sum(events[\"weight\"][(cut_mass_0 | cut_mass_1) & cut])\n",
    "\n",
    "\n",
    "def get_nevents_signal(events, cut, mass, mass_window):\n",
    "    cut_mass = (events[mass] >= mass_window[0]) & (events[mass] <= mass_window[1])\n",
    "\n",
    "    # get yield in Higgs mass window\n",
    "    return np.sum(events[\"weight\"][cut & cut_mass])\n",
    "\n",
    "\n",
    "def get_nevents_nosignal(events, cut, mass, mass_window):\n",
    "    cut_mass = (events[mass] >= mass_window[0]) & (events[mass] <= mass_window[1])\n",
    "\n",
    "    # get yield in Higgs mass window\n",
    "    return np.sum(events[\"weight\"][cut & ~cut_mass])\n",
    "\n",
    "\n",
    "def get_s_b(events_dict, cut_dict, mass, mass_window):\n",
    "    s = get_nevents_signal(events_dict[\"hh4b\"], cut_dict[\"hh4b\"], mass, mass_window)\n",
    "    bd = get_nevents_sidebands(events_dict[\"data\"], cut_dict[\"data\"], mass, mass_window)\n",
    "    bt = get_nevents_sidebands(events_dict[\"ttbar\"], cut_dict[\"ttbar\"], mass, mass_window)\n",
    "    ts = get_nevents_sidebands(events_dict[\"ttbar\"], cut_dict[\"ttbar\"], mass, mass_window)\n",
    "    b = bd - bt + ts\n",
    "    return s, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_tt(events_dict, cut_dict, mass, mass_window):\n",
    "    s = get_nevents_signal(events_dict[\"data\"], cut_dict[\"data\"], mass, mass_window)\n",
    "    b = get_nevents_sidebands(events_dict[\"ttbar\"], cut_dict[\"ttbar\"], mass, mass_window)\n",
    "    return s, b\n",
    "\n",
    "\n",
    "def abcd(events_dict, txbb_cut, bdt_cut, mass, mass_window):\n",
    "    dicts = {\"data\": [], \"ttbar\": []}\n",
    "\n",
    "    for key in [\"hh4b\", \"data\", \"ttbar\"]:\n",
    "        events = events_dict[key]\n",
    "        cut = (events[\"bdt_score\"] > bdt_cut) & (events[\"H2TXbb\"] > txbb_cut)\n",
    "\n",
    "        if key == \"hh4b\":\n",
    "            s = get_nevents_signal(events, cut, mass, mass_window)\n",
    "            continue\n",
    "\n",
    "        # region A\n",
    "        dicts[key].append(get_nevents_signal(events, cut, mass, mass_window))\n",
    "        # region B\n",
    "        dicts[key].append(get_nevents_nosignal(events, cut, mass, mass_window))\n",
    "\n",
    "        cut = (events[\"bdt_score\"] < 0.6) & (events[\"H2TXbb\"] < 0.8)\n",
    "        # region C\n",
    "        dicts[key].append(get_nevents_signal(events, cut, mass, mass_window))\n",
    "        # region D\n",
    "        dicts[key].append(get_nevents_nosignal(events, cut, mass, mass_window))\n",
    "\n",
    "    dmt = np.array(dicts[\"data\"]) - np.array(dicts[\"ttbar\"])\n",
    "    bqcd = dmt[2] * dmt[1] / dmt[3]\n",
    "    # print(dicts)\n",
    "\n",
    "    return s, bqcd + dicts[\"ttbar\"][0], dicts[\"ttbar\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the optimization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mass = \"H2PNetMass\"\n",
    "mass_window = [115, 135]\n",
    "\n",
    "for txbb_cut in np.arange(0.96, 1.0, 0.005):\n",
    "    for bdt_cut in np.arange(0.9, 1.0, 0.01):\n",
    "        s, b, bt = abcd(events_combined, txbb_cut, bdt_cut, mass, mass_window)\n",
    "        print(txbb_cut, bdt_cut, s, b, bt, s / b)\n",
    "\n",
    "# abcd(events_combined, 0.99, 0.97, mass, mass_window)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Old stuff:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig_samples = {\"hh4b\": samples[year][\"hh4b\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events = pd.read_parquet(\n",
    "    Path(data_dir) / \"2022EE\" / \"GluGlutoHHto4B_kl-1p00_kt-1p00_c2-0p00_TuneCP5_13p6TeV\" / \"parquet\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = [\"qcd\", \"ttbar\"]\n",
    "mass = \"bbFatJetMsd\"\n",
    "tagger = \"bbFatJetPNetTXbbLegacy\"\n",
    "i = 1\n",
    "\n",
    "for sample in samples:\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.title(sample)\n",
    "    for cut in [0, 0.8, 0.9, 0.95]:\n",
    "        cut_mask = events_dict[sample][tagger][i] >= cut\n",
    "        plt.hist(\n",
    "            events_dict[sample][mass][i][cut_mask],\n",
    "            np.arange(60, 251, 10),\n",
    "            weights=events_dict[sample][\"finalWeight\"][cut_mask],\n",
    "            histtype=\"step\",\n",
    "            label=rf\"$T_{{Xbb}} \\geq {cut}$\",\n",
    "            density=True,\n",
    "        )\n",
    "\n",
    "    plt.xlabel(f\"Jet {i+1} {mass} (GeV)\")\n",
    "    plt.legend()\n",
    "    plt.savefig(plot_dir / f\"{sample}_{mass}{i}_{tagger}_sculpting.pdf\", bbox_inches=\"tight\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BDT ROC Curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tt ROC curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jet = 1\n",
    "tagger = \"bbFatJetPNetTXbbLegacy\"\n",
    "sig_jets_score = events_dict[\"hh4b\"][tagger][jet]\n",
    "bg_jets_score = {\n",
    "    \"qcd\": events_dict[\"qcd\"][tagger][jet],\n",
    "    \"ttbar\": events_dict[\"ttbar\"][tagger][jet],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "bg_skip = 1\n",
    "sig_key = \"hh4b\"\n",
    "weight_key = \"finalWeight\"\n",
    "rocs = {}\n",
    "\n",
    "for bg_key in [\"qcd\", \"ttbar\"]:\n",
    "    print(bg_key)\n",
    "    y_true = np.concatenate(\n",
    "        [\n",
    "            np.ones(len(sig_jets_score)),\n",
    "            np.zeros((len(bg_jets_score[bg_key]) - 1) // bg_skip + 1),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    weights = np.concatenate(\n",
    "        [\n",
    "            events_dict[sig_key][weight_key].to_numpy(),\n",
    "            events_dict[bg_key][weight_key].to_numpy()[::bg_skip],\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    scores = np.concatenate((sig_jets_score, bg_jets_score[bg_key][::bg_skip]))\n",
    "\n",
    "    fpr, tpr, thresholds = roc_curve(y_true, scores, sample_weight=weights)\n",
    "\n",
    "    rocs[bg_key] = {\n",
    "        \"fpr\": fpr,\n",
    "        \"tpr\": tpr,\n",
    "        \"thresholds\": thresholds,\n",
    "        \"label\": plotting.label_by_sample[bg_key],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_nearest(array, value):\n",
    "    array = np.asarray(array)\n",
    "    idx = (np.abs(array - value)).argmin()\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting.multiROCCurveGrey(\n",
    "    {\"test\": rocs},\n",
    "    [0.2, 0.5],\n",
    "    xlim=[0, 0.8],\n",
    "    ylim=[1e-5, 1],\n",
    "    plot_dir=plot_dir,\n",
    "    name=f\"{tagger}_ROCs\",\n",
    "    show=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "coffea",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

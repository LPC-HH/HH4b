{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b003fdb7-5d91-4742-b23e-099459ad23b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import hist\n",
    "import pickle\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "import HH4b.utils as utils\n",
    "import HH4b.plotting as plotting\n",
    "import postprocessing\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import mplhep as hep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f828eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# automatically reloads imported files on edits\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deabb526-29f4-4163-9feb-4131d6b9e538",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your dataset\n",
    "samples = {\n",
    "    \"qcd\": [\n",
    "        \"QCD_HT-200to400\",\n",
    "        # \"QCD_HT-400to600\",\n",
    "        \"QCD_HT-600to800\",\n",
    "        \"QCD_HT-800to1000\",\n",
    "        \"QCD_HT-1000to1200\",\n",
    "        \"QCD_HT-1200to1500\",\n",
    "        \"QCD_HT-1500to2000\",\n",
    "        \"QCD_HT-2000\",\n",
    "    ],\n",
    "    \"ttbar\": [\n",
    "        \"TTto4Q\",\n",
    "        \"TTtoLNu2Q\",\n",
    "    ],\n",
    "    \"hh4b\": [\n",
    "        \"GluGlutoHHto4B_kl-1p00_kt-1p00_c2-0p00_TuneCP5_13p6TeV\",\n",
    "    ],\n",
    "    \"vbfhh4b\": [\n",
    "        \"VBFHHto4B_CV_1_C2V_1_C3_1_TuneCP5_13p6TeV_madgraph-pythia8\",\n",
    "    ],\n",
    "    \"vhbb\": [\"ZH_Hto2B_Zto2Q_M-125\", \"WplusH_Hto2B_Wto2Q_M-125\", \"WminusH_Hto2B_Wto2Q_M-125\"],\n",
    "}\n",
    "\n",
    "MAIN_DIR = \"../../../\"\n",
    "year = \"2022EE\"\n",
    "dir_name = \"24Jan18_v12\"\n",
    "# path_to_dir = f\"/eos/uscms/store/user/dprim7/bbbb/skimmer/{dir_name}/\"\n",
    "path_to_dir = f\"{MAIN_DIR}/../data/skimmer/{dir_name}/\"\n",
    "dirs = {path_to_dir: samples}\n",
    "\n",
    "# columns to load\n",
    "load_columns = [\n",
    "    (\"weight\", 1),\n",
    "    (\"MET_pt\", 1),\n",
    "    (\"nFatJets\", 1),\n",
    "    (\"ak8FatJetPt\", 2),\n",
    "    (\"ak8FatJetEta\", 2),\n",
    "    (\"ak8FatJetPhi\", 2),\n",
    "    (\"ak8FatJetMsd\", 2),\n",
    "    (\"ak8FatJetPNetMass\", 2),\n",
    "    (\"ak8FatJetPNetXbb\", 2),\n",
    "    (\"ak8FatJetTau3OverTau2\", 2),\n",
    "]\n",
    "# reformat into (\"column name\", \"idx\") format for reading multiindex columns\n",
    "columns = []\n",
    "for key, num_columns in load_columns:\n",
    "    for i in range(num_columns):\n",
    "        columns.append(f\"('{key}', '{i}')\")\n",
    "\n",
    "filters = [\n",
    "    [\n",
    "        (\"('ak8FatJetPt', '0')\", \">=\", 300),\n",
    "        (\"('ak8FatJetPt', '1')\", \">=\", 300),\n",
    "        (\"('ak8FatJetMsd', '0')\", \"<=\", 250),\n",
    "        (\"('ak8FatJetMsd', '1')\", \"<=\", 250),\n",
    "        (\"('ak8FatJetMsd', '0')\", \">=\", 50),\n",
    "        (\"('ak8FatJetMsd', '1')\", \">=\", 50),\n",
    "        (\"('MET_pt', '0')\", \"<=\", 1000),\n",
    "    ],\n",
    "    # [\n",
    "    #    (\"('ak8FatJetPt', '0')\", \">=\", 300),\n",
    "    #    (\"('ak8FatJetPt', '1')\", \">=\", 300),\n",
    "    #    (\"('ak8FatJetPNetMass', '0')\", \"<=\", 250),\n",
    "    #    (\"('ak8FatJetPNetMass', '1')\", \"<=\", 250),\n",
    "    #    (\"('ak8FatJetPNetMass', '0')\", \">=\", 50),\n",
    "    #    (\"('ak8FatJetPNetMass', '1')\", \">=\", 50),\n",
    "    #    (\"('MET_pt', '0')\", \"<=\", 1000),\n",
    "    # ],\n",
    "]\n",
    "\n",
    "events_dict = {}\n",
    "for input_dir, samples in dirs.items():\n",
    "    events_dict = {\n",
    "        **events_dict,\n",
    "        # this function will load files (only the columns selected), apply filters and compute a weight per event\n",
    "        **utils.load_samples(input_dir, samples, year, filters=filters, columns_mc=columns),\n",
    "    }\n",
    "\n",
    "\n",
    "print(\"Keys:\")\n",
    "print(events_dict.keys())\n",
    "for key in events_dict:\n",
    "    print(key, len(events_dict[key]))\n",
    "\n",
    "samples_loaded = list(events_dict.keys())\n",
    "keys_loaded = list(events_dict[samples_loaded[0]].keys())\n",
    "print(keys_loaded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c92c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b59edb29",
   "metadata": {},
   "outputs": [],
   "source": [
    "events_dict[\"hh4b\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d90a9ee",
   "metadata": {},
   "source": [
    "The h candidates are the first two fatjets (ordered by Xbb):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f37890",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this mask assumes that only two jets are loaded and the 3rd jet is not relevant\n",
    "# TODO: sort jets in skimmer\n",
    "bb_masks = postprocessing.bb_assignment(events_dict)\n",
    "\n",
    "events_dict_bdt = {}\n",
    "\n",
    "for key, events in events_dict.items():\n",
    "    # all the features that start with \"bb\" will apply this mask\n",
    "    bb_mask = bb_masks[key]\n",
    "\n",
    "    # for feat in [\"Pt\",\"Eta\",\"Phi\",\"PNetMass\"]:\n",
    "    #    for i in range(2):\n",
    "    #         events[f\"bb{i}FatJet{feat}\"] = utils.get_feat(events, f\"bb{i}FatJet{feat}\", bb_masks[key])\n",
    "\n",
    "    # take PNetMass to form the 4-vector\n",
    "    # this function will take the bb_mask into account automatically\n",
    "    # h1 = utils.make_vector(events, \"bb0FatJet\", bb_mask=bb_mask, mstring=\"PNetMass\")\n",
    "    # h2 = utils.make_vector(events, \"bb1FatJet\", bb_mask=bb_mask, mstring=\"PNetMass\")\n",
    "\n",
    "    # take mSD to form the 4-vector\n",
    "    h1 = utils.make_vector(events, \"bb0FatJet\", bb_mask=bb_mask, mstring=\"Msd\")\n",
    "    h2 = utils.make_vector(events, \"bb1FatJet\", bb_mask=bb_mask, mstring=\"Msd\")\n",
    "\n",
    "    # dihiggs candidate object\n",
    "    hh = h1 + h2\n",
    "\n",
    "    # bdt variables\n",
    "    df = pd.DataFrame(\n",
    "        {\n",
    "            # dihiggs system\n",
    "            \"HHlogPt\": np.log(hh.pt),\n",
    "            \"HHeta\": hh.eta,\n",
    "            \"HHmass\": hh.mass,\n",
    "            # met in the event\n",
    "            \"MET\": events.MET_pt[0],\n",
    "            # fatjet tau32\n",
    "            \"H1T32\": utils.get_feat(events, \"bb0FatJetTau3OverTau2\", bb_mask),\n",
    "            \"H2T32\": utils.get_feat(events, \"bb1FatJetTau3OverTau2\", bb_mask),\n",
    "            # fatjet mass\n",
    "            \"H1Msd\": utils.get_feat(events, \"bb0FatJetMsd\", bb_mask),\n",
    "            \"H1PNetMass\": utils.get_feat(events, \"bb0FatJetPNetMass\", bb_mask),\n",
    "            \"H2Msd\": utils.get_feat(events, \"bb1FatJetMsd\", bb_mask),\n",
    "            \"H2PNetMass\": utils.get_feat(events, \"bb0FatJetPNetMass\", bb_mask),\n",
    "            # fatjet kinematics\n",
    "            \"H1logPt\": np.log(h1.pt),\n",
    "            \"H2logPt\": np.log(h2.pt),\n",
    "            \"H1eta\": h1.eta,\n",
    "            \"H2eta\": h2.eta,\n",
    "            \"H1_dRH2\": h1.deltaR(h2),\n",
    "            \"H1_dPhiH2\": h1.deltaphi(h2),\n",
    "            # xbb\n",
    "            \"H1Xbb\": utils.get_feat(events, \"bb0FatJetPNetXbb\", bb_mask),\n",
    "            \"H2Xbb\": utils.get_feat(events, \"bb1FatJetPNetXbb\", bb_mask),\n",
    "            # ratios\n",
    "            \"H1Pt_HHmass\": h1.pt / hh.mass,\n",
    "            \"H2Pt_HHmass\": h2.pt / hh.mass,\n",
    "            \"H1Pt/H2Pt\": h1.pt / h2.pt,\n",
    "            # --- additional features to consider? -----\n",
    "            # number of fatjets in the event\n",
    "            # add VBF jet information?\n",
    "            # cos(theta_star)\n",
    "        }\n",
    "    )\n",
    "\n",
    "    df.replace(np.inf, 10000, inplace=True)\n",
    "    df.replace(-np.inf, 10000, inplace=True)\n",
    "\n",
    "    events_dict_bdt[key] = df\n",
    "\n",
    "variables_not_in_bdt = [\n",
    "    # not use PnetMass until we debug it\n",
    "    \"H1PNetMass\",\n",
    "    # not use H2 mass to avoid correlations\n",
    "    \"H2Msd\",\n",
    "    \"H2PNetMass\",\n",
    "    # not use H1Xbb so that we can further cut on it\n",
    "    \"H1Xbb\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a4d9fdc",
   "metadata": {},
   "source": [
    "Now we plot the BDT variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af245d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "bb_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b355bf46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0241342e",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_rows = len(events_dict_bdt[\"hh4b\"].columns)\n",
    "\n",
    "fig, axes = plt.subplots(num_rows, 1, figsize=(12, 4 * num_rows))\n",
    "for i, col in enumerate(events_dict_bdt[\"hh4b\"].columns):\n",
    "    for key, events in events_dict_bdt.items():\n",
    "        # axes[i].hist(events[col].dropna(), bins=50, alpha=0.3, density=True, label=key)\n",
    "        axes[i].hist(events[col].dropna(), bins=50, alpha=0.3, label=key)\n",
    "    axes[i].set_title(f\"{col}\")\n",
    "    axes[i].set_xlabel(col)\n",
    "    axes[i].set_ylabel(\"Events\")\n",
    "    axes[i].legend(fontsize=10)\n",
    "    axes[i].set_yscale(\"log\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db83ad36-5089-4488-af17-cb64a5f919f5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "events = pd.concat(\n",
    "    [events_dict_bdt[\"hh4b\"], events_dict_bdt[\"qcd\"], events_dict_bdt[\"ttbar\"]],\n",
    "    keys=[\"hh4b\", \"qcd\", \"ttbar\"],\n",
    ")\n",
    "events[\"target\"] = 0  # Default to 0 (background)\n",
    "events.loc[\"hh4b\", \"target\"] = 1  # Set to 1 for 'hh4b' samples (signal)\n",
    "\n",
    "# Define target\n",
    "target = events[\"target\"]\n",
    "\n",
    "# load features into pandas df\n",
    "features = events\n",
    "features.drop(columns=[\"target\"], inplace=True)\n",
    "features.drop(columns=variables_not_in_bdt, inplace=True)\n",
    "\n",
    "# Splitting the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    features, target, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b13e673",
   "metadata": {},
   "outputs": [],
   "source": [
    "features.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "906a8c6a-d227-4f63-b528-23f11ba4b0f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the BDT model\n",
    "bdt_model = XGBClassifier(\n",
    "    n_estimators=196, max_depth=17, learning_rate=0.1, subsample=0.5, random_state=42\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "bdt_model.fit(X_train, y_train)\n",
    "\n",
    "# Save the model\n",
    "model_file = \"boostedBDT.json\"\n",
    "bdt_model.save_model(model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96565b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine importance of the features\n",
    "importances = bdt_model.feature_importances_\n",
    "\n",
    "feature_names = events.columns\n",
    "feature_importance = sorted(zip(feature_names, importances), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "for feature in feature_importance:\n",
    "    print(f\"{feature[0]}: {feature[1]:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a3f1a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "predictions = bdt_model.predict(X_test)\n",
    "probabilities = bdt_model.predict_proba(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "roc_auc = roc_auc_score(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e7a903",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot scores\n",
    "y_scores = bdt_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_scores)\n",
    "roc_auc = auc(fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a82c759",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9384dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plottting ROC curve\n",
    "plt.figure()\n",
    "plt.plot(tpr, fpr, color=\"darkorange\", lw=2, label=\"ROC curve (area = %0.2f)\" % roc_auc)\n",
    "plt.xlabel(\"Signal (HH)\")\n",
    "plt.ylabel(\"Background (QCD&ttbar)\")\n",
    "plt.title(\"ROC\")\n",
    "plt.legend(loc=\"upper left\")\n",
    "# plt.yscale('log')\n",
    "plt.ylim(0, 0.002)\n",
    "plt.xlim(0, 0.25)\n",
    "plt.savefig(f\"{MAIN_DIR}/../data/boosted-bdt/ROC_BDT.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c21d45a9-9fae-4e43-8b34-100feb411632",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "hh4b_scores = bdt_model.predict_proba(X_test.loc[\"hh4b\"])[:, 1]\n",
    "qcd_scores = bdt_model.predict_proba(X_test.loc[\"qcd\"])[:, 1]\n",
    "ttbar_scores = bdt_model.predict_proba(X_test.loc[\"ttbar\"])[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d15a1a42-eb7e-489b-b3fa-cdba4cc35bb5",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.hist(hh4b_scores, bins=40, histtype=\"step\", linewidth=1.5, color=\"darkblue\")\n",
    "plt.hist(qcd_scores, bins=40, histtype=\"step\", linewidth=1.5, color=\"red\")\n",
    "plt.hist(ttbar_scores, bins=40, histtype=\"step\", linewidth=1.5, color=\"darkgreen\")\n",
    "plt.legend([\"hh4b\", \"qcd\", \"ttbar\"])\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.xlabel(\"Prediction Score\")\n",
    "plt.title(\"Model Predictions Histogram\")\n",
    "plt.yscale(\"log\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "819b9619",
   "metadata": {},
   "source": [
    "Predict on other samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d5fe279",
   "metadata": {},
   "outputs": [],
   "source": [
    "bdt_vbfhh4b = events_dict_bdt[\"vbfhh4b\"].drop(columns=variables_not_in_bdt)\n",
    "bdt_vhbb = events_dict_bdt[\"vhbb\"].drop(columns=variables_not_in_bdt)\n",
    "vbfhh4b_scores = bdt_model.predict_proba(bdt_vbfhh4b)[:, 1]\n",
    "vhbb_scores = bdt_model.predict_proba(bdt_vhbb)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f8526d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.hist(hh4b_scores, bins=40, histtype=\"step\", linewidth=1.5, color=\"darkblue\")\n",
    "plt.hist(vbfhh4b_scores, bins=40, histtype=\"step\", linewidth=1.5, color=\"red\")\n",
    "plt.hist(vhbb_scores, bins=40, histtype=\"step\", linewidth=1.5, color=\"darkgreen\")\n",
    "plt.legend([\"hh4b\", \"vbf hh4b\", \"vhbb\"])\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.xlabel(\"Prediction Score\")\n",
    "plt.title(\"Model Predictions Histogram\")\n",
    "plt.yscale(\"log\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "effd8e27",
   "metadata": {},
   "source": [
    "Plot h2 mass after BDT cuts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe4e1c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "bdt_qcd = events_dict_bdt[\"qcd\"].drop(columns=variables_not_in_bdt)\n",
    "bdt_hh4b = events_dict_bdt[\"hh4b\"].drop(columns=variables_not_in_bdt)\n",
    "qcd_scores = bdt_model.predict_proba(bdt_qcd)[:, 1]\n",
    "hh4b_scores = bdt_model.predict_proba(bdt_hh4b)[:, 1]\n",
    "\n",
    "scores_dict = {\n",
    "    \"qcd\": qcd_scores,\n",
    "    \"hh4b\": hh4b_scores,\n",
    "    \"vbfhh4b\": vbfhh4b_scores,\n",
    "    \"vhbb\": vhbb_scores,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e50fd214",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_axis = hist.axis.StrCategory([], name=\"Sample\", growth=True)\n",
    "cut_axis = hist.axis.StrCategory([], name=\"Cut\", growth=True)\n",
    "h2_mass_axis = hist.axis.Regular(40, 0, 300, name=\"mass\", label=r\"Higgs 2 mass [GeV]\")\n",
    "\n",
    "hist_h2 = hist.Hist(h2_mass_axis, cut_axis, cat_axis)\n",
    "bdt_cuts = [0, 0.2, 0.4]\n",
    "\n",
    "for key in [\"qcd\", \"hh4b\"]:\n",
    "    scores = scores_dict[key]\n",
    "    events = events_dict_bdt[key]\n",
    "    h2_mass = events[\"H2Msd\"]\n",
    "\n",
    "    for cut in bdt_cuts:\n",
    "        mask = scores >= cut\n",
    "        hist_h2.fill(h2_mass[mask], str(cut), key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e877ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in [\"qcd\", \"hh4b\"]:\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(12, 4))\n",
    "    for cut in bdt_cuts:\n",
    "        hep.histplot(\n",
    "            hist_h2[{\"Sample\": key, \"Cut\": str(cut)}], density=True, lw=2, label=f\"BDT > {cut}\"\n",
    "        )\n",
    "    ax.legend()\n",
    "    ax.set_ylabel(\"Density\")\n",
    "    ax.set_title(key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8e3f7c9",
   "metadata": {},
   "source": [
    "### Compare with old BDT (trained in Run 2 data)\n",
    "\n",
    "- The problem with this comparison is that the BDT used variables that are no longer available in Run2 data `fatJet1PNetQCDb`, `fatJet1PNetQCDbb`, `fatJet1PNetQCDOthers`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b59cb2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from https://github.com/LPC-HH/HHLooper/blob/master/python/xgboost/append_xgboost_discriminator_to_tree_withSystematics_MC_2018.py\n",
    "_model_name = (\n",
    "    f\"{MAIN_DIR}/../data/model_xgboost_training_weights_qcd_and_ttbar_Run2_bdt_enhanced_v8p2.pkl\"\n",
    ")\n",
    "\n",
    "with open(_model_name, \"rb\") as pkl_file:\n",
    "    model_run2 = pickle.load(pkl_file)\n",
    "\n",
    "variables = [\n",
    "    # branche name, BDT name\n",
    "    [\"hh_pt\", \"hh_pt\", \"$p_{T}^{HH}$ (GeV)\", 40, 0, 5000],\n",
    "    [\"hh_eta\", \"hh_eta\", \"$\\eta^{HH}$\", 40, -5.0, 5.0],\n",
    "    [\"hh_mass\", \"hh_mass\", \"$m_{HH}$ (GeV)\", 40, 0, 1500],\n",
    "    [\"met\", \"met\", \"$MET$ (GeV)\", 60, 0, 600],\n",
    "    [\"fatJet1Tau3OverTau2\", \"fatJet1Tau3OverTau2\", \"fatJet1Tau3OverTau2\", 50, 0.0, 1.0],\n",
    "    [\"fatJet2Tau3OverTau2\", \"fatJet2Tau3OverTau2\", \"fatJet2Tau3OverTau2\", 50, 0.0, 1.0],\n",
    "    [\"fatJet1MassSD\", \"j1_mass_sd\", \"$M_{j1}$ (GeV)\", 40, 0.0, 5000.0],\n",
    "    [\"fatJet1Pt\", \"j1_pt\", \"$p_{T}^{j1}$ (GeV)\", 40, 0.0, 5000.0],\n",
    "    [\"fatJet1Eta\", \"j1_eta\", \"$\\eta^{j1}$\", 40, -2.5, 2.5],\n",
    "    [\"fatJet1PNetXbb\", \"fatJet1PNetXbb\", \"fatJet1PNetXbb\", 40, -100, 100],\n",
    "    [\"fatJet1PNetQCDb\", \"fatJet1PNetQCDb\", \"fatJet1PNetQCDb\", 40, -100, 100],\n",
    "    [\"fatJet1PNetQCDbb\", \"fatJet1PNetQCDbb\", \"fatJet1PNetQCDbb\", 40, -100, 100],\n",
    "    [\"fatJet1PNetQCDothers\", \"fatJet1PNetQCDothers\", \"fatJet1PNetQCDothers\", 40, -100, 100],\n",
    "    [\"fatJet2Pt\", \"j2_pt\", \"$p_{T}^{j2}$ (GeV)\", 40, 0.0, 500.0],\n",
    "    [\"fatJet1PtOverMHH\", \"ptj1Omhh\", \"$p_{T}^{j1}/m_{HH}$\", 40, 0.0, 1.0],\n",
    "    [\"fatJet2PtOverMHH\", \"ptj2Omhh\", \"$p_{T}^{j2}/m_{HH}$\", 40, 0.0, 0.7],\n",
    "    [\"ptj2_over_ptj1\", \"ptj2Optj1\", \"$p_{T}^{j2}/p_{T}^{j1}$\", 40, 0.5, 1.0],\n",
    "]\n",
    "var_names = [x[0] for x in variables]\n",
    "\n",
    "\n",
    "def bdt_dataframe(key):\n",
    "    events = events_dict[key]\n",
    "    bb_mask = bb_masks[key]\n",
    "    events_bdt = pd.DataFrame()\n",
    "    events_bdt[\"fatJet1Pt\"] = utils.get_feat(events, \"bb0FatJetPt\", bb_mask)\n",
    "    events_bdt[\"fatJet1Eta\"] = utils.get_feat(events, \"bb0FatJetEta\", bb_mask)\n",
    "    events_bdt[\"fatJet1Phi\"] = utils.get_feat(events, \"bb0FatJetPhi\", bb_mask)\n",
    "    events_bdt[\"fatJet1Mass\"] = utils.get_feat(events, \"bb0FatJetMsd\", bb_mask)\n",
    "\n",
    "    events_bdt[\"fatJet2Pt\"] = utils.get_feat(events, \"bb1FatJetPt\", bb_mask)\n",
    "    events_bdt[\"fatJet2Eta\"] = utils.get_feat(events, \"bb1FatJetEta\", bb_mask)\n",
    "    events_bdt[\"fatJet2Phi\"] = utils.get_feat(events, \"bb1FatJetPhi\", bb_mask)\n",
    "    events_bdt[\"fatJet2Mass\"] = utils.get_feat(events, \"bb1FatJetMsd\", bb_mask)\n",
    "\n",
    "    events_bdt[\"fatJet1PNetXbb\"] = utils.get_feat(events, \"bb0FatJetPNetXbb\", bb_mask)\n",
    "    # these variables do not exist in Run 3 ntuples\n",
    "    events_bdt[\"fatJet1PNetQCDb\"] = utils.get_feat(events, \"bb0FatJetPNetXbb\", bb_mask)  # RUN3\n",
    "    events_bdt[\"fatJet1PNetQCDbb\"] = utils.get_feat(events, \"bb0FatJetPNetXbb\", bb_mask)  # RUN3\n",
    "    events_bdt[\"fatJet1PNetQCDothers\"] = utils.get_feat(events, \"bb0FatJetPNetXbb\", bb_mask)  # RUN3\n",
    "    # events_bdt[\"fatJet1PNetQCDb\"] = utils.get_feat(events, \"bb0FatJetPNetQCDb\", bb_mask)\n",
    "    # events_bdt[\"fatJet1PNetQCDbb\"] = utils.get_feat(events, \"bb0FatJetPNetQCDbb\", bb_mask)\n",
    "    # events_bdt[\"fatJet1PNetQCDothers\"] = utils.get_feat(events, \"bb0FatJetPNetQCDothers\", bb_mask)\n",
    "\n",
    "    events_bdt[\"fatJet1MassSD\"] = utils.get_feat(events, \"bb0FatJetMsd\", bb_mask)\n",
    "\n",
    "    h1 = utils.make_vector(events, \"bb0FatJet\", bb_mask=bb_mask, mstring=\"Msd\")\n",
    "    h2 = utils.make_vector(events, \"bb1FatJet\", bb_mask=bb_mask, mstring=\"Msd\")\n",
    "    hh = h1 + h2\n",
    "    events_bdt[\"hh_pt\"] = hh.pt\n",
    "    events_bdt[\"hh_eta\"] = hh.eta\n",
    "    events_bdt[\"hh_mass\"] = hh.mass\n",
    "    events_bdt[\"met\"] = utils.get_feat(events, \"MET_pt\")\n",
    "    events_bdt[\"fatJet1Tau3OverTau2\"] = utils.get_feat(events, \"bb0FatJetTau3OverTau2\", bb_mask)\n",
    "    events_bdt[\"fatJet2Tau3OverTau2\"] = utils.get_feat(events, \"bb1FatJetTau3OverTau2\", bb_mask)\n",
    "    events_bdt[\"fatJet1PtOverMHH\"] = events_bdt[\"fatJet1Pt\"] / (hh.mass)\n",
    "    events_bdt[\"fatJet2PtOverMHH\"] = events_bdt[\"fatJet2Pt\"] / (hh.mass)\n",
    "    events_bdt[\"ptj2_over_ptj1\"] = events_bdt[\"fatJet2Pt\"] / events_bdt[\"fatJet1Pt\"]\n",
    "\n",
    "    events_bdt = events_bdt[var_names]\n",
    "    # getting a numpy array from two pandas data frames\n",
    "    x_test = events_bdt.values\n",
    "    # creating numpy array for target variables\n",
    "    y_test = np.zeros(len(events_bdt))\n",
    "    # predict\n",
    "    y_pred = model_run2.predict_proba(x_test)[:, 1]\n",
    "\n",
    "    events_bdt[\"bdt_prediction\"] = y_pred\n",
    "\n",
    "    events_bdt[\"fatJet1PNetMass\"] = utils.get_feat(events, \"bb0FatJetPNetMass\", bb_mask)\n",
    "    events_bdt[\"fatJet2PNetMass\"] = utils.get_feat(events, \"bb1FatJetPNetMass\", bb_mask)\n",
    "    events_bdt[\"weight\"] = utils.get_feat(events, \"weight\")\n",
    "    events_bdt[\"fatJet2PNetXbb\"] = utils.get_feat(events, \"bb1FatJetPNetXbb\", bb_mask)\n",
    "\n",
    "    return events_bdt\n",
    "\n",
    "\n",
    "# predict run2 bdt\n",
    "events_bdt_run2_dict = {}\n",
    "for key in [\"hh4b\", \"qcd\", \"ttbar\", \"vhbb\", \"vbfhh4b\"]:\n",
    "    print(key)\n",
    "    events_bdt_run2_dict[key] = bdt_dataframe(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "019a2188",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.hist(hh4b_scores, bins=40, histtype=\"step\", linewidth=1.5, color=\"darkblue\")\n",
    "plt.hist(\n",
    "    events_bdt_run2_dict[\"hh4b\"][\"bdt_prediction\"],\n",
    "    bins=40,\n",
    "    histtype=\"step\",\n",
    "    linewidth=1.5,\n",
    "    color=\"red\",\n",
    ")\n",
    "plt.legend([\"hh4b run3-bdt\", \"hh4b run2-bdt\"])\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.xlabel(\"Prediction Score\")\n",
    "plt.title(\"Model Predictions Histogram\")\n",
    "plt.yscale(\"log\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5574c65",
   "metadata": {},
   "source": [
    "## BDT tasks\n",
    "\n",
    "### Different variations\n",
    "- Consider event weight in training?\n",
    "- Other variables to include?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d612aa",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import uproot\n",
    "import numpy as np\n",
    "import pickle\n",
    "import vector\n",
    "\n",
    "from HH4b.postprocessing import bb_assignment\n",
    "from HH4b.utils import ShapeVar, CUT_MAX_VAL, load_samples\n",
    "from HH4b.utils import get_feat, make_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# automatically reloads imported files on edits\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Run2 HH4b sample (v9_privatepfnano)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAIN_DIR = \"../../../\"\n",
    "path_to_dir = f\"{MAIN_DIR}/../data/skimmer/23Nov16_v9_privatepfnano/\"\n",
    "year = \"2018\"\n",
    "date = \"24Feb2_2018\"\n",
    "\n",
    "plot_dir = f\"{MAIN_DIR}/plots/PostProcessing/{date}/{year}\"\n",
    "_ = os.system(f\"mkdir -p {plot_dir}\")\n",
    "\n",
    "samples = {\"hh4b\": [\"GluGlutoHHto4B_cHHH1_TuneCP5_PSWeights_13TeV-powheg-pythia8\"]}\n",
    "sample_dirs = {path_to_dir: samples}\n",
    "\n",
    "filters = [\n",
    "    [\n",
    "        (\"('ak8FatJetPt', '0')\", \">=\", 300),\n",
    "        (\"('ak8FatJetPt', '1')\", \">=\", 300),\n",
    "        (\"('ak8FatJetMsd', '0')\", \">=\", 50),\n",
    "        (\"('ak8FatJetMsd', '1')\", \">=\", 50),\n",
    "        (\"('ak8FatJetPNetXbb', '0')\", \">=\", 0.8),\n",
    "    ],\n",
    "    [\n",
    "        (\"('ak8FatJetPt', '0')\", \">=\", 300),\n",
    "        (\"('ak8FatJetPt', '1')\", \">=\", 300),\n",
    "        (\"('ak8FatJetMsd', '0')\", \">=\", 50),\n",
    "        (\"('ak8FatJetMsd', '1')\", \">=\", 50),\n",
    "        (\"('ak8FatJetPNetXbb', '1')\", \">=\", 0.8),\n",
    "    ],\n",
    "    [\n",
    "        (\"('ak8FatJetPt', '0')\", \">=\", 300),\n",
    "        (\"('ak8FatJetPt', '1')\", \">=\", 300),\n",
    "        (\"('ak8FatJetPNetMass', '0')\", \">=\", 50),\n",
    "        (\"('ak8FatJetPNetMass', '1')\", \">=\", 50),\n",
    "        (\"('ak8FatJetPNetXbb', '0')\", \">=\", 0.8),\n",
    "    ],\n",
    "    [\n",
    "        (\"('ak8FatJetPt', '0')\", \">=\", 300),\n",
    "        (\"('ak8FatJetPt', '1')\", \">=\", 300),\n",
    "        (\"('ak8FatJetPNetMass', '0')\", \">=\", 50),\n",
    "        (\"('ak8FatJetPNetMass', '1')\", \">=\", 50),\n",
    "        (\"('ak8FatJetPNetXbb', '1')\", \">=\", 0.8),\n",
    "    ],\n",
    "]\n",
    "\n",
    "# columns to load\n",
    "load_columns = [\n",
    "    (\"run\", 1),\n",
    "    (\"lumi\", 1),\n",
    "    (\"event\", 1),\n",
    "    (\"weight\", 1),\n",
    "    (\"ak8FatJetPt\", 2),\n",
    "    (\"ak8FatJetEta\", 2),\n",
    "    (\"ak8FatJetPhi\", 2),\n",
    "    (\"ak8FatJetMsd\", 2),\n",
    "    (\"ak8FatJetPNetQCDb\", 2),\n",
    "    (\"ak8FatJetPNetQCDbb\", 2),\n",
    "    (\"ak8FatJetPNetQCDothers\", 2),\n",
    "    (\"ak8FatJetPNetXbb\", 2),\n",
    "    (\"ak8FatJetTau3OverTau2\", 2),\n",
    "    (\"GenHiggsPt\", 2),\n",
    "    (\"GenHiggsEta\", 2),\n",
    "    (\"GenHiggsPhi\", 2),\n",
    "]\n",
    "# reformat into (\"column name\", \"idx\") format for reading multiindex columns\n",
    "columns = []\n",
    "for key, num_columns in load_columns:\n",
    "    for i in range(num_columns):\n",
    "        columns.append(f\"('{key}', '{i}')\")\n",
    "\n",
    "# dictionary that will contain all information (from all samples)\n",
    "events_dict = {}\n",
    "for input_dir, samples in sample_dirs.items():\n",
    "    events_dict = {\n",
    "        **events_dict,\n",
    "        # this function will load files (only the columns selected), apply filters and compute a weight per event\n",
    "        **load_samples(\n",
    "            input_dir,\n",
    "            samples,\n",
    "            year,\n",
    "            filters=filters,\n",
    "            columns_mc=columns,\n",
    "        ),\n",
    "    }\n",
    "\n",
    "bb_masks = bb_assignment(events_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(events_dict[\"hh4b\"].columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Run2 HH4b sample (directly from old skimmer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From lxplus: /eos/cms/store/group/phys_susy/razor/Run2Analysis/HH/HHTo4BNtupler/20230207/option5/combined/BDT/2018/\n",
    "# From lxplus: /eos/cms/store/group/phys_susy/razor/Run2Analysis/HH/HHTo4BNtupler/20211209_regression/option5/combined/BDT/2018/\n",
    "\n",
    "# path_to_dir_run2 = f\"{MAIN_DIR}/../data/skimmer/20230207_BDT/\"\n",
    "path_to_dir_run2 = f\"{MAIN_DIR}/../data/skimmer/20211209_regression/\"\n",
    "samples_run2 = {\n",
    "    \"hh4b_run2\": [\n",
    "        \"GluGluToHHTo4B_node_cHHH1_TuneCP5_PSWeights_13TeV-powheg-pythia8_1pb_weighted_Testing_BDTs.root\"\n",
    "    ],\n",
    "}\n",
    "\n",
    "columns = [\n",
    "    \"run\",\n",
    "    \"luminosityBlock\",\n",
    "    \"event\",\n",
    "    \"fatJet1Pt\",\n",
    "    \"fatJet1Eta\",\n",
    "    \"fatJet1Phi\",\n",
    "    \"fatJet1Mass\",\n",
    "    \"fatJet1MassSD\",\n",
    "    \"fatJet1PNetXbb\",\n",
    "    \"fatJet1PNetQCDb\",\n",
    "    \"fatJet1PNetQCDbb\",\n",
    "    \"fatJet1PNetQCDothers\",\n",
    "    \"fatJet1Tau3OverTau2\",\n",
    "    \"fatJet2Pt\",\n",
    "    \"fatJet2Eta\",\n",
    "    \"fatJet2Phi\",\n",
    "    \"fatJet2Mass\",\n",
    "    \"fatJet2MassSD\",\n",
    "    \"fatJet2PNetXbb\",\n",
    "    \"fatJet2PNetQCDb\",\n",
    "    \"fatJet2PNetQCDbb\",\n",
    "    \"fatJet2PNetQCDothers\",\n",
    "    \"fatJet2Tau3OverTau2\",\n",
    "    \"fatJet1PtOverMHH\",\n",
    "    \"fatJet2PtOverMHH\",\n",
    "    # \"fatJet1MassSD_noJMS\",\n",
    "    \"ptj2_over_ptj1\",\n",
    "    \"hh_pt\",\n",
    "    \"hh_eta\",\n",
    "    \"hh_mass\",\n",
    "    \"met\",\n",
    "    \"genHiggs1Pt\",\n",
    "    \"genHiggs1Eta\",\n",
    "    \"genHiggs1Phi\",\n",
    "    \"disc_qcd_and_ttbar_Run2_enhanced_v8p2\",\n",
    "]\n",
    "for key, datasets in samples_run2.items():\n",
    "    for dset in datasets:\n",
    "        pdf = uproot.open(f\"{path_to_dir_run2}/{year}/{dset}:Events\").arrays(columns, library=\"pd\")\n",
    "        events_dict[key] = pdf.rename(columns={\"luminosityBlock\": \"lumi\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(events_dict[\"hh4b_run2\"].columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf = events_dict[\"hh4b_run2\"]\n",
    "df_ev_run2 = pdf[pdf.event == 877647]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf = events_dict[\"hh4b\"]\n",
    "df_ev = pdf[(pdf.event == 877647).to_numpy().squeeze()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ev[\"ak8FatJetPNetXbb\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ev[\"ak8FatJetPt\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ev_run2[\"fatJet1Pt\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ev_run2[\"fatJet1PNetXbb\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load BDT from run2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_model_name = (\n",
    "    f\"{MAIN_DIR}/../data/model_xgboost_training_weights_qcd_and_ttbar_Run2_bdt_enhanced_v8p2.pkl\"\n",
    ")\n",
    "\n",
    "with open(_model_name, \"rb\") as pkl_file:\n",
    "    model = pickle.load(pkl_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.get_booster().feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = [\n",
    "    # branche name, BDT name\n",
    "    [\"hh_pt\", \"hh_pt\", \"$p_{T}^{HH}$ (GeV)\", 40, 0, 5000],\n",
    "    [\"hh_eta\", \"hh_eta\", \"$\\eta^{HH}$\", 40, -5.0, 5.0],\n",
    "    [\"hh_mass\", \"hh_mass\", \"$m_{HH}$ (GeV)\", 40, 0, 1500],\n",
    "    [\"met\", \"met\", \"$MET$ (GeV)\", 60, 0, 600],\n",
    "    [\"fatJet1Tau3OverTau2\", \"fatJet1Tau3OverTau2\", \"fatJet1Tau3OverTau2\", 50, 0.0, 1.0],\n",
    "    [\"fatJet2Tau3OverTau2\", \"fatJet2Tau3OverTau2\", \"fatJet2Tau3OverTau2\", 50, 0.0, 1.0],\n",
    "    [\"fatJet1MassSD\", \"j1_mass_sd\", \"$M_{j1}$ (GeV)\", 40, 0.0, 5000.0],\n",
    "    [\"fatJet1Pt\", \"j1_pt\", \"$p_{T}^{j1}$ (GeV)\", 40, 0.0, 5000.0],\n",
    "    [\"fatJet1Eta\", \"j1_eta\", \"$\\eta^{j1}$\", 40, -2.5, 2.5],\n",
    "    [\"fatJet1PNetXbb\", \"fatJet1PNetXbb\", \"fatJet1PNetXbb\", 40, -100, 100],\n",
    "    [\"fatJet1PNetQCDb\", \"fatJet1PNetQCDb\", \"fatJet1PNetQCDb\", 40, -100, 100],\n",
    "    [\"fatJet1PNetQCDbb\", \"fatJet1PNetQCDbb\", \"fatJet1PNetQCDbb\", 40, -100, 100],\n",
    "    [\"fatJet1PNetQCDothers\", \"fatJet1PNetQCDothers\", \"fatJet1PNetQCDothers\", 40, -100, 100],\n",
    "    [\"fatJet2Pt\", \"j2_pt\", \"$p_{T}^{j2}$ (GeV)\", 40, 0.0, 500.0],\n",
    "    [\"fatJet1PtOverMHH\", \"ptj1Omhh\", \"$p_{T}^{j1}/m_{HH}$\", 40, 0.0, 1.0],\n",
    "    [\"fatJet2PtOverMHH\", \"ptj2Omhh\", \"$p_{T}^{j2}/m_{HH}$\", 40, 0.0, 0.7],\n",
    "    [\"ptj2_over_ptj1\", \"ptj2Optj1\", \"$p_{T}^{j2}/p_{T}^{j1}$\", 40, 0.5, 1.0],\n",
    "]\n",
    "var_names = [x[0] for x in variables]\n",
    "\n",
    "\n",
    "def bdt_dataframe(key):\n",
    "    events = events_dict[key]\n",
    "    bb_mask = bb_masks[key]\n",
    "    events_bdt = pd.DataFrame()\n",
    "    events_bdt[\"fatJet1Pt\"] = get_feat(events, \"bb0FatJetPt\", bb_mask)\n",
    "    events_bdt[\"fatJet1Eta\"] = get_feat(events, \"bb0FatJetEta\", bb_mask)\n",
    "    events_bdt[\"fatJet1Phi\"] = get_feat(events, \"bb0FatJetPhi\", bb_mask)\n",
    "    events_bdt[\"fatJet1Mass\"] = get_feat(events, \"bb0FatJetMsd\", bb_mask)\n",
    "\n",
    "    events_bdt[\"fatJet2Pt\"] = get_feat(events, \"bb1FatJetPt\", bb_mask)\n",
    "    events_bdt[\"fatJet2Eta\"] = get_feat(events, \"bb1FatJetEta\", bb_mask)\n",
    "    events_bdt[\"fatJet2Phi\"] = get_feat(events, \"bb1FatJetPhi\", bb_mask)\n",
    "    events_bdt[\"fatJet2Mass\"] = get_feat(events, \"bb1FatJetMsd\", bb_mask)\n",
    "\n",
    "    events_bdt[\"fatJet1PNetXbb\"] = get_feat(events, \"bb0FatJetPNetXbb\", bb_mask)\n",
    "    events_bdt[\"fatJet1PNetQCDb\"] = get_feat(events, \"bb0FatJetPNetQCDb\", bb_mask)\n",
    "    events_bdt[\"fatJet1PNetQCDbb\"] = get_feat(events, \"bb0FatJetPNetQCDbb\", bb_mask)\n",
    "    events_bdt[\"fatJet1PNetQCDothers\"] = get_feat(events, \"bb0FatJetPNetQCDothers\", bb_mask)\n",
    "\n",
    "    events_bdt[\"fatJet1MassSD\"] = get_feat(events, \"bb0FatJetMsd\", bb_mask)\n",
    "\n",
    "    h1 = make_vector(events, \"bb0FatJet\", bb_mask=bb_mask, mstring=\"Msd\")\n",
    "    h2 = make_vector(events, \"bb1FatJet\", bb_mask=bb_mask, mstring=\"Msd\")\n",
    "    hh = h1 + h2\n",
    "    events_bdt[\"hh_pt\"] = hh.pt\n",
    "    events_bdt[\"hh_eta\"] = hh.eta\n",
    "    events_bdt[\"hh_mass\"] = hh.mass\n",
    "\n",
    "    events_bdt[\"met\"] = get_feat(events, \"MET_pt\")\n",
    "    events_bdt[\"fatJet1Tau3OverTau2\"] = get_feat(events, \"bb0FatJetTau3OverTau2\", bb_mask)\n",
    "    events_bdt[\"fatJet2Tau3OverTau2\"] = get_feat(events, \"bb1FatJetTau3OverTau2\", bb_mask)\n",
    "    events_bdt[\"fatJet1PtOverMHH\"] = events_bdt[\"fatJet1Pt\"] / (hh.mass)\n",
    "    events_bdt[\"fatJet2PtOverMHH\"] = events_bdt[\"fatJet2Pt\"] / (hh.mass)\n",
    "    events_bdt[\"ptj2_over_ptj1\"] = events_bdt[\"fatJet2Pt\"] / events_bdt[\"fatJet1Pt\"]\n",
    "\n",
    "    events_bdt = events_bdt[var_names]\n",
    "    # getting a numpy array from two pandas data frames\n",
    "    x_test = events_bdt.values\n",
    "    # creating numpy array for target variables\n",
    "    y_test = np.zeros(len(events_bdt))\n",
    "    # predict\n",
    "    y_pred = model.predict_proba(x_test)[:, 1]\n",
    "\n",
    "    events_bdt[\"bdt_prediction\"] = y_pred\n",
    "    events_bdt[\"event\"] = get_feat(events, \"event\")\n",
    "\n",
    "    return events_bdt\n",
    "\n",
    "\n",
    "# same function w/o bb masks\n",
    "def bdt_dataframe_nobb(key):\n",
    "    events = events_dict[key]\n",
    "    events_bdt = pd.DataFrame()\n",
    "    events_bdt[\"fatJet1Pt\"] = events[\"bbFatJetPt0\"]\n",
    "    events_bdt[\"fatJet1Eta\"] = events[\"bbFatJetEta0\"]\n",
    "    events_bdt[\"fatJet1Phi\"] = events[\"bbFatJetPhi0\"]\n",
    "    events_bdt[\"fatJet1Mass\"] = events[\"bbFatJetMsd0\"]\n",
    "\n",
    "    events_bdt[\"fatJet2Pt\"] = events[\"bbFatJetPt1\"]\n",
    "    events_bdt[\"fatJet2Eta\"] = events[\"bbFatJetEta1\"]\n",
    "    events_bdt[\"fatJet2Phi\"] = events[\"bbFatJetPhi1\"]\n",
    "    events_bdt[\"fatJet2Mass\"] = events[\"bbFatJetMsd1\"]\n",
    "\n",
    "    events_bdt[\"fatJet1PNetXbb\"] = events[\"bbFatJetPNetXbb0\"]\n",
    "    events_bdt[\"fatJet1PNetQCDb\"] = events[\"bbFatJetPNetQCDb0\"]\n",
    "    events_bdt[\"fatJet1PNetQCDbb\"] = events[\"bbFatJetPNetQCDbb0\"]\n",
    "    events_bdt[\"fatJet1PNetQCDothers\"] = events[\"bbFatJetPNetQCDothers0\"]\n",
    "\n",
    "    events_bdt[\"fatJet1MassSD\"] = events[\"bbFatJetMsd0\"]\n",
    "\n",
    "    h1 = vector.array(\n",
    "        {\n",
    "            \"pt\": events_bdt[\"fatJet1Pt\"],\n",
    "            \"phi\": events_bdt[\"fatJet1Phi\"],\n",
    "            \"eta\": events_bdt[\"fatJet1Eta\"],\n",
    "            \"M\": events_bdt[\"fatJet1Mass\"],\n",
    "        }\n",
    "    )\n",
    "    h2 = vector.array(\n",
    "        {\n",
    "            \"pt\": events_bdt[\"fatJet2Pt\"],\n",
    "            \"phi\": events_bdt[\"fatJet2Phi\"],\n",
    "            \"eta\": events_bdt[\"fatJet2Eta\"],\n",
    "            \"M\": events_bdt[\"fatJet2Mass\"],\n",
    "        }\n",
    "    )\n",
    "\n",
    "    hh = h1 + h2\n",
    "    events_bdt[\"hh_pt\"] = hh.pt\n",
    "    events_bdt[\"hh_eta\"] = hh.eta\n",
    "    events_bdt[\"hh_mass\"] = hh.mass\n",
    "\n",
    "    events_bdt[\"met\"] = events[\"MET_pt\"]\n",
    "    events_bdt[\"fatJet1Tau3OverTau2\"] = events[\"bbFatJetTau3OverTau20\"]\n",
    "    events_bdt[\"fatJet2Tau3OverTau2\"] = events[\"bbFatJetTau3OverTau21\"]\n",
    "    events_bdt[\"fatJet1PtOverMHH\"] = events_bdt[\"fatJet1Pt\"] / (hh.mass)\n",
    "    events_bdt[\"fatJet2PtOverMHH\"] = events_bdt[\"fatJet2Pt\"] / (hh.mass)\n",
    "    events_bdt[\"ptj2_over_ptj1\"] = events_bdt[\"fatJet2Pt\"] / events_bdt[\"fatJet1Pt\"]\n",
    "\n",
    "    events_bdt = events_bdt[var_names]\n",
    "    # getting a numpy array from two pandas data frames\n",
    "    x_test = events_bdt.values\n",
    "    # creating numpy array for target variables\n",
    "    y_test = np.zeros(len(events_bdt))\n",
    "    # predict\n",
    "    y_pred = model.predict_proba(x_test)[:, 1]\n",
    "\n",
    "    events_bdt[\"bdt_prediction\"] = y_pred\n",
    "    events_bdt[\"event\"] = get_feat(events, \"event\")\n",
    "\n",
    "    return events_bdt\n",
    "\n",
    "\n",
    "def bdt_dataframe_run2(key):\n",
    "    events = events_dict[key]\n",
    "    events_bdt = pd.DataFrame()\n",
    "    events_bdt[\"fatJet1Pt\"] = events[\"fatJet1Pt\"]\n",
    "    events_bdt[\"fatJet1Eta\"] = events[\"fatJet1Eta\"]\n",
    "    events_bdt[\"fatJet1Phi\"] = events[\"fatJet1Phi\"]\n",
    "    events_bdt[\"fatJet1Mass\"] = events[\"fatJet1Mass\"]\n",
    "\n",
    "    events_bdt[\"fatJet2Pt\"] = events[\"fatJet2Pt\"]\n",
    "    events_bdt[\"fatJet2Eta\"] = events[\"fatJet2Eta\"]\n",
    "    events_bdt[\"fatJet2Phi\"] = events[\"fatJet2Phi\"]\n",
    "    events_bdt[\"fatJet2Mass\"] = events[\"fatJet2Mass\"]\n",
    "\n",
    "    events_bdt[\"fatJet1PNetXbb\"] = events[\"fatJet1PNetXbb\"]\n",
    "    events_bdt[\"fatJet1PNetQCDb\"] = events[\"fatJet1PNetQCDb\"]\n",
    "    events_bdt[\"fatJet1PNetQCDbb\"] = events[\"fatJet1PNetQCDbb\"]\n",
    "    events_bdt[\"fatJet1PNetQCDothers\"] = events[\"fatJet1PNetQCDothers\"]\n",
    "\n",
    "    events_bdt[\"fatJet1MassSD\"] = events[\"fatJet1MassSD\"]\n",
    "    # events_bdt[\"fatJet1MassSD\"] = events[\"fatJet1MassSD_noJMS\"]\n",
    "\n",
    "    h1 = vector.array(\n",
    "        {\n",
    "            \"pt\": events[\"fatJet1Pt\"],\n",
    "            \"phi\": events[\"fatJet1Phi\"],\n",
    "            \"eta\": events[\"fatJet1Eta\"],\n",
    "            \"M\": events[\"fatJet1MassSD\"],\n",
    "        }\n",
    "    )\n",
    "    h2 = vector.array(\n",
    "        {\n",
    "            \"pt\": events[\"fatJet2Pt\"],\n",
    "            \"phi\": events[\"fatJet2Phi\"],\n",
    "            \"eta\": events[\"fatJet2Eta\"],\n",
    "            \"M\": events[\"fatJet2MassSD\"],\n",
    "        }\n",
    "    )\n",
    "\n",
    "    hh = h1 + h2\n",
    "    events_bdt[\"hh_pt\"] = hh.pt\n",
    "    events_bdt[\"hh_eta\"] = hh.eta\n",
    "    events_bdt[\"hh_mass\"] = hh.mass\n",
    "\n",
    "    events_bdt[\"hh_pt\"] = events[\"hh_pt\"]\n",
    "    events_bdt[\"hh_eta\"] = events[\"hh_eta\"]\n",
    "    events_bdt[\"hh_mass\"] = events[\"hh_mass\"]\n",
    "\n",
    "    events_bdt[\"met\"] = events[\"met\"]\n",
    "    events_bdt[\"fatJet1Tau3OverTau2\"] = events[\"fatJet1Tau3OverTau2\"]\n",
    "    events_bdt[\"fatJet2Tau3OverTau2\"] = events[\"fatJet2Tau3OverTau2\"]\n",
    "    # events_bdt[\"fatJet1PtOverMHH\"] = events[\"fatJet1PtOverMHH\"]\n",
    "    # events_bdt[\"fatJet2PtOverMHH\"] = events[\"fatJet2PtOverMHH\"]\n",
    "    # events_bdt[\"ptj2_over_ptj1\"] = events[\"ptj2_over_ptj1\"]\n",
    "    events_bdt[\"fatJet1PtOverMHH\"] = events_bdt[\"fatJet1Pt\"] / (hh.mass)\n",
    "    events_bdt[\"fatJet2PtOverMHH\"] = events_bdt[\"fatJet2Pt\"] / (hh.mass)\n",
    "    events_bdt[\"ptj2_over_ptj1\"] = events_bdt[\"fatJet2Pt\"] / events_bdt[\"fatJet1Pt\"]\n",
    "\n",
    "    events_bdt = events_bdt[var_names]\n",
    "    # getting a numpy array from two pandas data frames\n",
    "    x_test = events_bdt.values\n",
    "    # creating numpy array for target variables\n",
    "    y_test = np.zeros(len(events_bdt))\n",
    "    # predict\n",
    "    y_pred = model.predict_proba(x_test)[:, 1]\n",
    "\n",
    "    events_bdt[\"bdt_prediction\"] = y_pred\n",
    "    events_bdt[\"event\"] = get_feat(events, \"event\")\n",
    "\n",
    "    events_bdt[\"disc_qcd_and_ttbar_Run2_enhanced_v8p2\"] = events[\n",
    "        \"disc_qcd_and_ttbar_Run2_enhanced_v8p2\"\n",
    "    ]\n",
    "\n",
    "    return events_bdt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events_bdt_dict = {}\n",
    "# events_bdt_dict[\"hh4b\"] = bdt_dataframe(\"hh4b\")\n",
    "events_bdt_dict[\"hh4b_run2\"] = bdt_dataframe_run2(\"hh4b_run2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test if inference in Run2 HH4b (skimmer )== Run 2 HH4b (old skimmer)\n",
    "- Tricky because kinematics don't agree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ev_bdt = events_bdt_dict[\"hh4b\"]\n",
    "df_ev_bdt[(df_ev_bdt.event == 877647)].bdt_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ev_run2.disc_qcd_and_ttbar_Run2_enhanced_v8p2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test if local inference on HH4b Run2 file is the same as saved in the skimmer ntuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events_bdt_dict[\"hh4b_run2\"].bdt_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events_bdt_dict[\"hh4b_run2\"].disc_qcd_and_ttbar_Run2_enhanced_v8p2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# it looks like very few differences\n",
    "inference_bdt = events_bdt_dict[\"hh4b_run2\"].bdt_prediction\n",
    "saved_bdt = events_bdt_dict[\"hh4b_run2\"].disc_qcd_and_ttbar_Run2_enhanced_v8p2\n",
    "diff = inference_bdt != saved_bdt\n",
    "same = inference_bdt == saved_bdt\n",
    "inference_bdt[diff]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with the exact same variables (0.08)\n",
    "# with the make vector (0.09)\n",
    "np.sum(diff) / (np.sum(same) + np.sum(diff))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load new Run2 HH4b sample produced with updated skimmer, JECs and v9_private_hh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_dir_run2_skim = f\"{MAIN_DIR}/../data/skimmer/Feb7_v9hh/\"\n",
    "samples_run2_skim = {\n",
    "    # \"hh4b_run2_skim\": [\"GluGlutoHHto4B_cHHH1_TuneCP5_PSWeights_13TeV-powheg-pythia8/nano_skim_0-30.root\"],\n",
    "    \"hh4b_run2_skim\": [\n",
    "        \"GluGlutoHHto4B_cHHH1_TuneCP5_PSWeights_13TeV-powheg-pythia8/nano_skim_0-1.root\"\n",
    "    ],\n",
    "}\n",
    "\n",
    "columns = [\n",
    "    \"run\",\n",
    "    \"luminosityBlock\",\n",
    "    \"event\",\n",
    "    \"bbFatJetPt0\",\n",
    "    \"bbFatJetEta0\",\n",
    "    \"bbFatJetPhi0\",\n",
    "    \"bbFatJetMass0\",\n",
    "    \"bbFatJetMsd0\",\n",
    "    \"bbFatJetPNetXbb0\",\n",
    "    \"bbFatJetPNetQCDb0\",\n",
    "    \"bbFatJetPNetQCDbb0\",\n",
    "    \"bbFatJetPNetQCDothers0\",\n",
    "    \"bbFatJetTau3OverTau20\",\n",
    "    \"bbFatJetPt1\",\n",
    "    \"bbFatJetEta1\",\n",
    "    \"bbFatJetPhi1\",\n",
    "    \"bbFatJetMass1\",\n",
    "    \"bbFatJetMsd1\",\n",
    "    \"bbFatJetPNetXbb1\",\n",
    "    \"bbFatJetPNetQCDb1\",\n",
    "    \"bbFatJetPNetQCDbb1\",\n",
    "    \"bbFatJetPNetQCDothers1\",\n",
    "    \"bbFatJetTau3OverTau21\",\n",
    "    \"MET_pt\",\n",
    "]\n",
    "for key, datasets in samples_run2_skim.items():\n",
    "    for dset in datasets:\n",
    "        df = uproot.open(f\"{path_to_dir_run2_skim}/{year}/{dset}:Events\").arrays(\n",
    "            columns, library=\"pd\"\n",
    "        )\n",
    "        events_dict[key] = df.rename(columns={\"luminosityBlock\": \"lumi\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events_bdt_dict[\"hh4b_run2_skim\"] = bdt_dataframe_nobb(\"hh4b_run2_skim\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test if inference in Run 2 HH4b (new skimmer) == Run2 HH4b (old skimmer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ev_bdt = events_bdt_dict[\"hh4b_run2\"]\n",
    "print(df_ev_bdt[(df_ev_bdt.event == 877647)].fatJet1Pt)\n",
    "print(df_ev_bdt[(df_ev_bdt.event == 877647)].fatJet1PNetXbb)\n",
    "print(df_ev_bdt[(df_ev_bdt.event == 877647)].bdt_prediction)\n",
    "print(df_ev_bdt[(df_ev_bdt.event == 877647)].disc_qcd_and_ttbar_Run2_enhanced_v8p2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ev_bdt = events_bdt_dict[\"hh4b_run2_skim\"]\n",
    "print(df_ev_bdt[(df_ev_bdt.event == 877647)].fatJet1Pt)\n",
    "print(df_ev_bdt[(df_ev_bdt.event == 877647)].fatJet1PNetXbb)\n",
    "print(df_ev_bdt[(df_ev_bdt.event == 877647)].bdt_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get consistent masks:\n",
    "\n",
    "    example of one event 447853 with 20230207_BDT \n",
    "    hh_pt 447853 [75.29954] [74.99527821]\n",
    "    hh_eta 447853 [3.8064182] [3.81099406]\n",
    "    hh_mass 447853 [972.2381] [972.90843845]\n",
    "    met 447853 [58.920475] [51.539936]\n",
    "    fatJet1Tau3OverTau2 447853 [0.88720536] [0.88720536]\n",
    "    fatJet2Tau3OverTau2 447853 [0.6964158] [0.69641578]\n",
    "    fatJet1MassSD 447853 [117.] [117.]\n",
    "    fatJet1Pt 447853 [427.17966] [427.55249023]\n",
    "    fatJet1Eta 447853 [1.5109863] [1.51098633]\n",
    "    fatJet1PNetXbb 447853 [0.99867326] [0.99861515]\n",
    "    fatJet1PNetQCDb 447853 [6.6529974e-05] [6.6529974e-05]\n",
    "    fatJet1PNetQCDbb 447853 [0.00126004] [0.00126004]\n",
    "    fatJet1PNetQCDothers 447853 [5.3305876e-10] [5.33058764e-10]\n",
    "    fatJet2Pt 447853 [501.32425] [501.38690186]\n",
    "    fatJet1PtOverMHH 447853 [0.43986812] [0.4394581]\n",
    "    fatJet2PtOverMHH 447853 [0.516215] [0.5153485]\n",
    "    ptj2_over_ptj1 447853 [1.1735677] [1.17269087]\n",
    "    bdt_prediction 447853 [0.8880559] [0.8857299]\n",
    "    event 447853 [447853] [447853]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run2 = events_bdt_dict[\"hh4b_run2\"]\n",
    "run2_skim = events_bdt_dict[\"hh4b_run2_skim\"]\n",
    "\n",
    "run2 = run2[(run2.fatJet1Pt > 300) & (run2.fatJet2Pt > 300)]\n",
    "run2_skim = run2_skim[(run2_skim.fatJet1Pt > 300) & (run2_skim.fatJet2Pt > 300)]\n",
    "\n",
    "# for i, ev in enumerate(run2.event):\n",
    "for i, ev in enumerate([447853, 699941]):\n",
    "    for key in run2_skim.keys():\n",
    "        # for key in [\"fatJet1Pt\", \"fatJet1PNetXbb\", \"bdt_prediction\"]:\n",
    "        val_run2 = run2[(run2.event == ev)][key].values\n",
    "        val_run2_skim = run2_skim[(run2_skim.event == ev)][key].values\n",
    "        print(key, ev, val_run2, val_run2_skim)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hist\n",
    "import matplotlib.pyplot as plt\n",
    "import mplhep as hep\n",
    "import matplotlib.ticker as mticker\n",
    "\n",
    "hep.style.use([\"CMS\", \"firamath\"])\n",
    "\n",
    "formatter = mticker.ScalarFormatter(useMathText=True)\n",
    "formatter.set_powerlimits((-3, 3))\n",
    "plt.rcParams.update({\"font.size\": 12})\n",
    "plt.rcParams[\"lines.linewidth\"] = 2\n",
    "plt.rcParams[\"grid.color\"] = \"#CCCCCC\"\n",
    "plt.rcParams[\"grid.linewidth\"] = 0.5\n",
    "plt.rcParams[\"figure.edgecolor\"] = \"none\"\n",
    "\n",
    "bdt_axis = hist.axis.Regular(40, 0, 1, name=\"bdt\", label=r\"BDT\")\n",
    "xbb_axis = hist.axis.Regular(40, 0.8, 1, name=\"xbb\", label=r\"Xbb\")\n",
    "cat_axis = hist.axis.StrCategory([], name=\"cat\", growth=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_bdt = hist.Hist(bdt_axis, cat_axis)\n",
    "h_xbb = hist.Hist(xbb_axis, cat_axis)\n",
    "\n",
    "keys = [\"hh4b_run2_skim\", \"hh4b_run2\"]\n",
    "for key in keys:\n",
    "    mask = (events_bdt_dict[key].fatJet1Pt > 300) & (\n",
    "        events_bdt_dict[key].fatJet2Pt > 300\n",
    "    )  # & (events_bdt_dict[key].fatJet1PNetXbb > 0.8)\n",
    "    h_bdt.fill(bdt=events_bdt_dict[key][mask][\"bdt_prediction\"].to_numpy(), cat=key)\n",
    "    h_xbb.fill(xbb=events_bdt_dict[key][mask][\"fatJet1PNetXbb\"].to_numpy(), cat=key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(6, 4))\n",
    "hep.histplot(\n",
    "    h_bdt[{\"cat\": \"hh4b_run2_skim\"}],\n",
    "    ax=ax,\n",
    "    label=\"hh4b v9 hh\",\n",
    "    histtype=\"step\",\n",
    "    linewidth=1,\n",
    "    color=\"black\",\n",
    "    density=True,\n",
    ")\n",
    "hep.histplot(\n",
    "    h_bdt[{\"cat\": \"hh4b_run2\"}],\n",
    "    ax=ax,\n",
    "    label=\"hh4b skimmer\",\n",
    "    histtype=\"step\",\n",
    "    linewidth=1,\n",
    "    color=\"red\",\n",
    "    density=True,\n",
    ")\n",
    "# hep.histplot(\n",
    "#     h_bdt[{\"cat\": \"hh4b\"}],\n",
    "#     ax=ax,\n",
    "#     label=\"hh4b run3\",\n",
    "#     histtype=\"step\",\n",
    "#     linewidth=1,\n",
    "#     color=\"blue\",\n",
    "#     density=True,\n",
    "# )\n",
    "ax.set_yscale(\"log\")\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(6, 4))\n",
    "hep.histplot(\n",
    "    h_bdt[{\"cat\": \"hh4b_run2_skim\"}],\n",
    "    ax=ax,\n",
    "    label=\"hh4b v9 hh\",\n",
    "    histtype=\"step\",\n",
    "    linewidth=1,\n",
    "    color=\"black\",\n",
    "    density=True,\n",
    ")\n",
    "hep.histplot(\n",
    "    h_bdt[{\"cat\": \"hh4b_run2\"}],\n",
    "    ax=ax,\n",
    "    label=\"hh4b skimmer\",\n",
    "    histtype=\"step\",\n",
    "    linewidth=1,\n",
    "    color=\"red\",\n",
    "    density=True,\n",
    ")\n",
    "# hep.histplot(\n",
    "#     h_bdt[{\"cat\": \"hh4b\"}],\n",
    "#     ax=ax,\n",
    "#     label=\"hh4b run3\",\n",
    "#     histtype=\"step\",\n",
    "#     linewidth=1,\n",
    "#     color=\"blue\",\n",
    "#     density=True,\n",
    "# )\n",
    "ax.set_yscale(\"log\")\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(6, 4))\n",
    "hep.histplot(\n",
    "    h_xbb[{\"cat\": \"hh4b_run2_skim\"}],\n",
    "    ax=ax,\n",
    "    label=\"hh4b v9 hh\",\n",
    "    histtype=\"step\",\n",
    "    linewidth=1,\n",
    "    color=\"black\",\n",
    "    density=True,\n",
    ")\n",
    "hep.histplot(\n",
    "    h_xbb[{\"cat\": \"hh4b_run2\"}],\n",
    "    ax=ax,\n",
    "    label=\"hh4b skimmer\",\n",
    "    histtype=\"step\",\n",
    "    linewidth=1,\n",
    "    color=\"red\",\n",
    "    density=True,\n",
    ")\n",
    "# hep.histplot(\n",
    "#     h_xbb[{\"cat\": \"hh4b\"}],\n",
    "#     ax=ax,\n",
    "#     label=\"hh4b run3\",\n",
    "#     histtype=\"step\",\n",
    "#     linewidth=1,\n",
    "#     color=\"blue\",\n",
    "#     density=True,\n",
    "# )\n",
    "ax.set_yscale(\"log\")\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A couple of conclusions:\n",
    "- Skimmer reproduces reasonably well ntuples for Run2, except for a couple of differences:\n",
    "  - mSD corrected by JMS/JMR disagrees\n",
    "  - pT disagrees at the 0.1% level\n",
    "  - MET disagrees at few % level\n",
    "- BDT inference seems to work\n",
    "- Not sure it is worth doing more checks event by event"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "coffea",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

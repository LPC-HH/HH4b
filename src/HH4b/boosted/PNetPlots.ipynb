{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import mplhep as hep\n",
    "import matplotlib.ticker as mticker\n",
    "import HH4b.utils as utils\n",
    "import HH4b.plotting as plotting\n",
    "from HH4b.postprocessing.postprocessing import Region, weight_shifts\n",
    "from HH4b.utils import ShapeVar, CUT_MAX_VAL\n",
    "from HH4b.hh_vars import samples, data_key, bg_keys, sig_keys\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "plt.style.use(hep.style.CMS)\n",
    "hep.style.use(\"CMS\")\n",
    "formatter = mticker.ScalarFormatter(useMathText=True)\n",
    "formatter.set_powerlimits((-3, 3))\n",
    "plt.rcParams.update({\"font.size\": 12})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# automatically reloads imported files on edits\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = \"2022EE\"\n",
    "\n",
    "samples_year = samples[year].copy()\n",
    "\n",
    "MAIN_DIR = \"/ceph/cms/store/user/dprimosc/bbbb/skimmer\"\n",
    "# this is the directory to the files\n",
    "\n",
    "tag = \"24Sep3_v12_private_signal\"\n",
    "path_to_dir = f\"{MAIN_DIR}/{tag}/\"\n",
    "\n",
    "# define dictionary with directories of files (this can be configured in a yaml file later in the script)\n",
    "sig_keys = [\"hh4b\"]\n",
    "for key in list(samples_year.keys()):\n",
    "    if key not in [\"qcd\", \"ttbar\"] + sig_keys:\n",
    "        del samples_year[key]\n",
    "\n",
    "sample_dirs = {path_to_dir: samples_year}\n",
    "\n",
    "# make plot and template directory\n",
    "date = \"24Sep6\"  # date of plotting\n",
    "plot_dir = f\"{MAIN_DIR}/plots/PostProcessing/{date}/{year}\"\n",
    "template_dir = f\"templates/{date}/\"  # why needed?\n",
    "_ = os.system(f\"mkdir -p {plot_dir}\")\n",
    "_ = os.system(f\"mkdir -p {template_dir}/cutflows/{year}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking contents of parquet files\n",
    "def examine_parquet_files(dir_path):\n",
    "\n",
    "    file_printed = False\n",
    "    for file_name in os.listdir(dir_path):\n",
    "        if file_printed:\n",
    "            break\n",
    "\n",
    "        if file_name.endswith(\".parquet\"):\n",
    "            file_printed = True\n",
    "\n",
    "            file_path = os.path.join(dir_path, file_name)\n",
    "\n",
    "            try:\n",
    "                # Read the parquet file into a DataFrame\n",
    "                pdf = pd.read_parquet(file_path)\n",
    "\n",
    "                # Display file information\n",
    "                print(f\"\\nContents of {file_path}:\")\n",
    "                print(\"Columns:\")\n",
    "                for column in pdf.columns:\n",
    "                    if column[1] == 0:\n",
    "                        # print column and number of entries\n",
    "                        print(f\"{column[0]}: {pdf[column[0]].shape[1]}\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error reading {file_path}: {e}\")\n",
    "\n",
    "\n",
    "test_directory = \"/ceph/cms/store/user/dprimosc/bbbb/skimmer/24Sep3_v12_private_signal/2022EE/GluGlutoHHto4B_kl-1p00_kt-1p00_c2-0p00_TuneCP5_13p6TeV/parquet\"\n",
    "print(test_directory)\n",
    "examine_parquet_files(test_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate signal and background for to fit with load_samples function\n",
    "bkg_sample_dirs = {}\n",
    "sig_sample_dirs = {}\n",
    "\n",
    "for path, datasets in sample_dirs.items():\n",
    "    bkg_sample_dirs[path] = {\"qcd\": datasets.get(\"qcd\", []), \"ttbar\": datasets.get(\"ttbar\", [])}\n",
    "    sig_sample_dirs[path] = {\"hh4b\": datasets.get(\"hh4b\", [])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filters, currently just a placeholder value to apply no real filter\n",
    "# TODO: what weights to use\n",
    "filters = [\n",
    "    [\n",
    "        (\"('ak8FatJetPt',0)\", \">=\", 400)(\"('ak8FatJetPt',0)\", \"<=\", 600)(\n",
    "            \"('ak8FatJetPt',1)\", \">=\", 400\n",
    "        )(\"('ak8FatJetPt',1)\", \"<=\", 600)(\"('ak8FatJetMsd',0)\", \">=\", 50)(\n",
    "            \"('ak8FatJetMsd',0)\", \"<=\", 250\n",
    "        )(\n",
    "            \"('ak8FatJetMsd',1)\", \">=\", 50\n",
    "        )(\n",
    "            \"('ak8FatJetMsd',1)\", \"<=\", 250\n",
    "        )\n",
    "    ],\n",
    "]\n",
    "\n",
    "# background columns to load\n",
    "bkg_load_columns = [\n",
    "    (\"weight\", 1),\n",
    "    (\"ak8FatJetPNetTXbb\", 2),\n",
    "    (\"ak8FatJetPNetTXbbLegacy\", 2),\n",
    "    (\"ak8FatJetPt\", 2),\n",
    "    (\"ak8FatJetMsd\", 2),\n",
    "]\n",
    "\n",
    "# signal columns to load\n",
    "sig_load_columns = [\n",
    "    (\"weight\", 1),\n",
    "    (\"ak8FatJetPNetTXbb\", 2),\n",
    "    (\"ak8FatJetPNetTXbbLegacy\", 2),\n",
    "    (\"ak8FatJetPt\", 2),\n",
    "    (\"ak8FatJetMsd\", 2),\n",
    "    (\"ak8FatJetHiggsMatchIndex\", 2),\n",
    "    (\"ak8FatJetNumBMatchedH1\", 2),\n",
    "    (\"ak8FatJetNumBMatchedH2\", 2),\n",
    "]\n",
    "\n",
    "# reformat into (\"column name\", \"idx\") format for reading multiindex columns\n",
    "bkg_columns = []\n",
    "for key, num_columns in bkg_load_columns:\n",
    "    for i in range(num_columns):\n",
    "        bkg_columns.append(f\"('{key}', '{i}')\")\n",
    "\n",
    "sig_columns = []\n",
    "for key, num_columns in sig_load_columns:\n",
    "    for i in range(num_columns):\n",
    "        sig_columns.append(f\"('{key}', '{i}')\")\n",
    "\n",
    "# save cutflow as pandas table\n",
    "# TODO: check this is running correctly\n",
    "cutflow = pd.DataFrame(index=list(samples_year.keys()))\n",
    "\n",
    "# dictionary that will contain all information (from all samples)\n",
    "events_dict = {}\n",
    "for input_dir, samples_dict in bkg_sample_dirs.items():\n",
    "    events_dict = {\n",
    "        **events_dict,\n",
    "        # this function will load files (only the columns selected), apply filters and compute a weight per event\n",
    "        # load background\n",
    "        **utils.load_samples(\n",
    "            input_dir,\n",
    "            samples_dict,\n",
    "            year,\n",
    "            filters=filters,\n",
    "            columns=bkg_columns,\n",
    "            reorder_txbb=False,\n",
    "            variations=False,\n",
    "            # columns_mc=utils.format_columns(load_columns_mc),\n",
    "        ),\n",
    "    }\n",
    "for input_dir, samples_dict in sig_sample_dirs.items():\n",
    "    events_dict = {\n",
    "        **events_dict,\n",
    "        # load signal\n",
    "        **utils.load_samples(\n",
    "            input_dir,\n",
    "            samples_dict,\n",
    "            year,\n",
    "            filters=filters,\n",
    "            columns=sig_columns,\n",
    "            reorder_txbb=False,\n",
    "            variations=False,\n",
    "            # columns_mc=utils.format_columns(load_columns_mc),\n",
    "        ),\n",
    "    }\n",
    "\n",
    "utils.add_to_cutflow(events_dict, \"Preselection\", \"finalWeight\", cutflow)\n",
    "print(\"\\n\", cutflow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexak8 = events_dict[\"hh4b\"][\n",
    "    \"ak8FatJetHiggsMatchIndex\"\n",
    "].to_numpy()  # index of higgs matched to jet\n",
    "nbh1ak8 = events_dict[\"hh4b\"][\n",
    "    \"ak8FatJetNumBMatchedH1\"\n",
    "].to_numpy()  # number of bquarks matched to H1\n",
    "nbh2ak8 = events_dict[\"hh4b\"][\n",
    "    \"ak8FatJetNumBMatchedH2\"\n",
    "].to_numpy()  # number of bquarks matched to H2\n",
    "\n",
    "matched_to_h1 = (indexak8 == 0) & (nbh1ak8 == 2)\n",
    "matched_to_h2 = (indexak8 == 1) & (nbh2ak8 == 2)\n",
    "matchedak8 = matched_to_h1 | matched_to_h2  # 2 b quarks matched to higgs (ak8 jet 0, ak8 ket 1)\n",
    "\n",
    "# TODO: revise how this is done, something is still not right\n",
    "pdf = pd.DataFrame(matchedak8, columns=[\"j1\", \"j2\"])\n",
    "mask = pd.concat([pdf[\"j1\"], pdf[\"j2\"]], ignore_index=True)\n",
    "sig_true = np.ones(2 * len(events_dict[\"hh4b\"]))\n",
    "sig_true[~mask] = 0\n",
    "print(matchedak8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to split up jets for object level analysis\n",
    "# Just concatenate the two rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# jet = 1  # second jet\n",
    "# we use both jets\n",
    "sig_key = \"hh4b\"\n",
    "bg_keys = [\"qcd\", \"ttbar\"]\n",
    "# bg_skip = 1\n",
    "\n",
    "y_true = np.concatenate(\n",
    "    [\n",
    "        sig_true,\n",
    "        np.zeros(\n",
    "            np.sum(2 * len(events_dict[bg_key]) for bg_key in bg_keys)\n",
    "        ),  # factor 2 needed bc we use both jets indivdiually\n",
    "    ]\n",
    ")\n",
    "# print(y_true[np.sum(sig_cut):])\n",
    "\n",
    "weights = np.concatenate(\n",
    "    [events_dict[sig_key][\"finalWeight\"]]\n",
    "    + [events_dict[sig_key][\"finalWeight\"]]\n",
    "    + [events_dict[bg_key][\"finalWeight\"] for bg_key in bg_keys]\n",
    "    + [events_dict[bg_key][\"finalWeight\"] for bg_key in bg_keys],\n",
    ")\n",
    "\n",
    "# following needs to match structure of weights\n",
    "scores = np.concatenate(\n",
    "    [events_dict[sig_key][\"ak8FatJetPNetTXbb\"][jet] for jet in (0, 1)]\n",
    "    + [events_dict[bg_key][\"ak8FatJetPNetTXbb\"][0] for bg_key in bg_keys]\n",
    "    + [events_dict[bg_key][\"ak8FatJetPNetTXbb\"][1] for bg_key in bg_keys],\n",
    ")\n",
    "\n",
    "legacy_scores = np.concatenate(\n",
    "    [events_dict[sig_key][\"ak8FatJetPNetTXbbLegacy\"][jet] for jet in (0, 1)]\n",
    "    + [events_dict[bg_key][\"ak8FatJetPNetTXbbLegacy\"][0] for bg_key in bg_keys]\n",
    "    + [events_dict[bg_key][\"ak8FatJetPNetTXbbLegacy\"][1] for bg_key in bg_keys],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = roc_curve(y_true, scores, sample_weight=weights)\n",
    "roc = {\"fpr\": fpr, \"tpr\": tpr, \"thresholds\": thresholds, \"label\": \"v12\"}\n",
    "\n",
    "legacy_fpr, legacy_tpr, legacy_thresholds = roc_curve(y_true, legacy_scores, sample_weight=weights)\n",
    "legacy_roc = {\n",
    "    \"fpr\": legacy_fpr,\n",
    "    \"tpr\": legacy_tpr,\n",
    "    \"thresholds\": legacy_thresholds,\n",
    "    \"label\": \"Legacy\",\n",
    "}\n",
    "\n",
    "rocs = {\n",
    "    \"V12 ROC\": {\"roc_1\": roc},\n",
    "    \"Legacy ROC\": {\"roc_2\": legacy_roc},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting.multiROCCurveGrey(\n",
    "    rocs=rocs,\n",
    "    sig_effs=[0.8, 0.9],  # Thresholds for signal efficiency lines\n",
    "    xlim=[0, 1],\n",
    "    ylim=[1e-5, 1],\n",
    "    plot_dir=plot_dir,\n",
    "    name=\"ak8FatJet12ROC_Comparison\",\n",
    "    show=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trigger SFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import coffea\n",
    "from hist import Hist\n",
    "from os import listdir\n",
    "from os.path import exists\n",
    "from typing import Union, List\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mplhep as hep\n",
    "from hist.intervals import clopper_pearson_interval\n",
    "import math\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams.update({\"font.size\": 11})\n",
    "plt.style.use(hep.style.CMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_selector(sample: str, selector: Union[str, List[str]]):\n",
    "    if isinstance(selector, list) or isinstance(selector, tuple):\n",
    "        for s in selector:\n",
    "            if s.startswith(\"*\"):\n",
    "                if s[1:] in sample:\n",
    "                    return True\n",
    "            else:\n",
    "                if sample.startswith(s):\n",
    "                    return True\n",
    "    else:\n",
    "        if selector.startswith(\"*\"):\n",
    "            if selector[1:] in sample:\n",
    "                return True\n",
    "        else:\n",
    "            if sample.startswith(selector):\n",
    "                return True\n",
    "\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = \"2022EE\"\n",
    "data_dir = f\"/eos/uscms/store/user/cmantill/bbbb/trigger_boosted/Aug15/\"\n",
    "samples = {\n",
    "    \"data\": [\"Run2022E\", \"Run2022F\", \"Run2022G\"],\n",
    "    \"ttbar\": [\"TTtoLNu2Q\"],\n",
    "}\n",
    "\n",
    "to_loop = {\n",
    "    \"data\": \"2022EE\",\n",
    "    \"ttbar\": \"TTToLNuQQ\",\n",
    "}\n",
    "\n",
    "full_samples_list = listdir(f\"{data_dir}/{year}\")\n",
    "events_dict = {}\n",
    "for label, selector in samples.items():\n",
    "    events_dict[label] = []\n",
    "    for sample in full_samples_list:\n",
    "        if not check_selector(sample, selector):\n",
    "            continue\n",
    "\n",
    "        if not exists(f\"{data_dir}/{year}/{sample}/parquet\"):\n",
    "            print(f\"No parquet file for {sample}\")\n",
    "            continue\n",
    "\n",
    "        events = pd.read_parquet(f\"{data_dir}/{year}/{sample}/parquet\", columns=None)\n",
    "        not_empty = len(events) > 0\n",
    "        if not_empty:\n",
    "            events_dict[label].append(events)\n",
    "\n",
    "        print(f\"Loaded {sample: <50}: {len(events)} entries\")\n",
    "\n",
    "    if len(events_dict[label]):\n",
    "        events_dict[label] = pd.concat(events_dict[label])\n",
    "    else:\n",
    "        del events_dict[label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_bins = [250, 275, 300, 325, 350, 375, 400, 425, 450, 475, 500, 550, 600, 800, 1000]\n",
    "xbb_bins = [0.0, 0.8, 0.9, 0.95, 0.98, 1.0]\n",
    "\n",
    "h0 = (\n",
    "    Hist.new\n",
    "    # .Reg(*pt_bins_fine, name=\"jet0pt\", label=\"fj$^0$ $p_T$ (GeV)\")\n",
    "    .Var(pt_bins, name=\"jet0pt\", label=\"fj$^0$ $p_T$ (GeV)\")\n",
    "    .Var(xbb_bins, name=\"jet0txbb\", label=\"fj$^0$ $T_{Xbb}$ Score\")\n",
    "    .Double()\n",
    ")\n",
    "\n",
    "trigger_dict = {\n",
    "    \"combined_nodijet\": (\n",
    "        [\n",
    "            \"AK8PFJet250_SoftDropMass40_PFAK8ParticleNetBB0p35\",\n",
    "            \"AK8PFJet425_SoftDropMass40\",\n",
    "        ],\n",
    "        \"AK8PFJet250_SoftDropMass40_PFAK8ParticleNetBB0p35 |\\nAK8PFJet425_SoftDropMass40\",\n",
    "    ),\n",
    "}\n",
    "\n",
    "trigger_info = {}\n",
    "for key, ev_label in to_loop.items():\n",
    "    trigger_info[key] = {}\n",
    "    events = events_dict[key]\n",
    "\n",
    "    xbb_0 = events[\"ak8FatJetPNetXbb\"][0]\n",
    "    pt_0 = events[\"ak8FatJetPt\"][0]\n",
    "    msd_0 = events[\"ak8FatJetMsd\"][0]\n",
    "\n",
    "    one_jet = (pt_0 > 200) & (msd_0 > 60)\n",
    "\n",
    "    for trigger_title, (triggers, trigger_label) in trigger_dict.items():\n",
    "        title = f\"{ev_label}_{trigger_title}\"\n",
    "\n",
    "        trigger_info[key][trigger_title] = []\n",
    "\n",
    "        selection = one_jet\n",
    "        trigger_selection = np.zeros_like(selection)\n",
    "\n",
    "        for hlt in triggers:\n",
    "            trigger_selection |= (events[hlt].values == 1).squeeze()\n",
    "        num_selection = selection & trigger_selection\n",
    "\n",
    "        den = h0.copy().fill(\n",
    "            jet0pt=pt_0[selection],\n",
    "            jet0txbb=xbb_0[selection],\n",
    "        )\n",
    "        num = h0.copy().fill(\n",
    "            jet0pt=pt_0[num_selection],\n",
    "            jet0txbb=xbb_0[num_selection],\n",
    "        )\n",
    "        trigger_info[key][trigger_title].append((num, den))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from correctionlib import schemav2\n",
    "\n",
    "\n",
    "def get_corr(eff, eff_unc_up, eff_unc_dn, label, trigger_label, edges):\n",
    "    def multibinning(sf):\n",
    "        return schemav2.MultiBinning(\n",
    "            nodetype=\"multibinning\",\n",
    "            inputs=[\"pt\", \"xbb\"],\n",
    "            edges=edges,\n",
    "            content=list(eff.flatten()),\n",
    "            flow=\"clamp\",\n",
    "        )\n",
    "\n",
    "    corr = schemav2.Correction(\n",
    "        name=f\"fatjet_triggereff_{year}_{label}\",\n",
    "        description=f\"{label} efficiency for trigger soup: {trigger_label}\",\n",
    "        version=1,\n",
    "        inputs=[\n",
    "            schemav2.Variable(\n",
    "                name=\"systematic\",\n",
    "                type=\"string\",\n",
    "                description=\"Systematic variation\",\n",
    "            ),\n",
    "            schemav2.Variable(\n",
    "                name=\"pt\",\n",
    "                type=\"real\",\n",
    "                description=\"Jet transverse momentum (NanoAODv11 nominal value)\",\n",
    "            ),\n",
    "            schemav2.Variable(\n",
    "                name=\"xbb\",\n",
    "                type=\"real\",\n",
    "                description=\"Jet Xbb (xbb/xbb+qcd) (NanoAODv11 nominal value)\",\n",
    "            ),\n",
    "        ],\n",
    "        output=schemav2.Variable(\n",
    "            name=\"weight\", type=\"real\", description=f\"Jet {label} trigger efficiency\"\n",
    "        ),\n",
    "        data=schemav2.Category(\n",
    "            nodetype=\"category\",\n",
    "            input=\"systematic\",\n",
    "            content=[\n",
    "                {\"key\": \"nominal\", \"value\": multibinning(eff)},\n",
    "                {\"key\": \"stat_up\", \"value\": multibinning(eff_unc_up)},\n",
    "                {\"key\": \"stat_dn\", \"value\": multibinning(eff_unc_dn)},\n",
    "            ],\n",
    "        ),\n",
    "    )\n",
    "    return corr\n",
    "\n",
    "\n",
    "for trigger_label in trigger_info[\"data\"].keys():\n",
    "    for i, _ in enumerate(trigger_info[\"data\"][trigger_label]):\n",
    "        numerator_data, denominator_data = trigger_info[\"data\"][trigger_label][i]\n",
    "        numerator_mc, denominator_mc = trigger_info[\"ttbar\"][trigger_label][i]\n",
    "\n",
    "        trigger_title = \"_\".join(title.split(\"_\")[1:])\n",
    "\n",
    "        rdata = (numerator_data / denominator_data).view()\n",
    "        rdata_unc = clopper_pearson_interval(numerator_data.view(), denominator_data.view())\n",
    "        rdata_unc_up = rdata_unc[1]\n",
    "        rdata_unc_dn = rdata_unc[0]\n",
    "\n",
    "        rmc = (numerator_mc / denominator_mc).view()\n",
    "        rmc = np.where(rmc == 0, 1.0, rmc)\n",
    "        rmc_unc = clopper_pearson_interval(numerator_mc.view(), denominator_mc.view())\n",
    "        rmc_unc_up = np.where(rmc_unc[0] == 0, np.inf, rmc_unc[0])\n",
    "        rmc_unc_dn = np.where(rmc_unc[1] == 0, 1.0, rmc_unc[1])\n",
    "\n",
    "        x = numerator_data\n",
    "        edges = [list(ax.edges) for ax in x.axes]\n",
    "\n",
    "        print(edges)\n",
    "\n",
    "        corr_mc = get_corr(rmc, rmc_unc_up, rmc_unc_dn, \"MC\", trigger_label, edges)\n",
    "        corr_data = get_corr(rdata, rdata_unc_up, rdata_unc_dn, \"data\", trigger_label, edges)\n",
    "\n",
    "        cset = schemav2.CorrectionSet(schema_version=2, corrections=[corr_mc, corr_data])\n",
    "        with open(f\"fatjet_triggereff_{year}_{trigger_label}.json\", \"w\") as fout:\n",
    "            fout.write(cset.json(exclude_unset=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rich\n",
    "\n",
    "rich.print(cset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "coffea-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

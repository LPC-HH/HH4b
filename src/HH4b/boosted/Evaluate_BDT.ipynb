{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from HH4b.boosted.TrainBDT import evaluate_model, roc_curve, _get_bdt_scores, get_legtitle\n",
    "from HH4b.postprocessing import (\n",
    "    get_evt_testing,\n",
    "    load_run3_samples,\n",
    ")\n",
    "import mplhep as hep\n",
    "from HH4b import hh_vars, plotting\n",
    "import pickle\n",
    "import importlib\n",
    "import hist\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "import argparse\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# definitions\n",
    "bdt_axis = hist.axis.Regular(40, 0, 1, name=\"bdt\", label=r\"BDT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading data\n",
    "# need to facilitate data loading as well as string arguments\n",
    "\n",
    "\n",
    "def preprocess_data(\n",
    "    events_dict: dict,\n",
    "    train_keys: list[str],\n",
    "    config_name: str,\n",
    "    test_size: float,\n",
    "    seed: int,\n",
    "    multiclass: bool,\n",
    "    equalize_weights: bool,\n",
    "    run2_wapproach: bool,\n",
    "    label_encoder,\n",
    "):\n",
    "\n",
    "    # dataframe function\n",
    "    make_bdt_dataframe = importlib.import_module(\n",
    "        f\".{config_name}\", package=\"HH4b.boosted.bdt_trainings_run3\"\n",
    "    )\n",
    "\n",
    "    training_keys = train_keys.copy()\n",
    "    print(\"Training keys \", training_keys)\n",
    "    for key in training_keys:\n",
    "        if key not in events_dict:\n",
    "            print(f\"removing {key}\")\n",
    "            training_keys.remove(key)\n",
    "\n",
    "    print(\"events dict \", events_dict.keys())\n",
    "\n",
    "    print(\"Train keys \", training_keys)\n",
    "\n",
    "    events_dict_bdt = {}\n",
    "    weights_bdt = {}\n",
    "    events_bdt = {}\n",
    "    for key in training_keys:\n",
    "        events_dict_bdt[key] = make_bdt_dataframe.bdt_dataframe(events_dict[key])\n",
    "        # get absolute weights (no negative weights)\n",
    "        weights_bdt[key] = np.abs(events_dict[key][\"finalWeight\"].to_numpy())\n",
    "        events_bdt[key] = events_dict[key][\"event\"].to_numpy()[:, 0]\n",
    "\n",
    "    events = pd.concat(\n",
    "        [events_dict_bdt[key] for key in training_keys],\n",
    "        keys=training_keys,\n",
    "    )\n",
    "\n",
    "    for key in weights_bdt:\n",
    "        print(f\"Total {key} pre-normalization: {np.sum(weights_bdt[key]):.3f}\")\n",
    "\n",
    "    # weights\n",
    "    if run2_wapproach:\n",
    "        print(\"Norm weights\")\n",
    "        bkg_weight = np.concatenate([weights_bdt[key] for key in args.bg_keys])\n",
    "        bkg_weight_min = np.amin(np.absolute(bkg_weight))\n",
    "        bkg_weight_rescale = 1.0 / np.absolute(bkg_weight_min)\n",
    "        print(\"Background weight rescale \", bkg_weight_rescale)\n",
    "        for key in args.bg_keys:\n",
    "            weights_bdt[key][weights_bdt[key] < 0] = 0\n",
    "            events.loc[key, \"weight\"] = weights_bdt[key] * bkg_weight_rescale\n",
    "\n",
    "        for sig_key in args.sig_keys:\n",
    "            sig_weight = weights_bdt[sig_key]\n",
    "            sig_weight_min = np.amin(np.absolute(sig_weight))\n",
    "            sig_weight_rescale = 1.0 / np.absolute(sig_weight_min)\n",
    "            print(\"Signal weight rescale \", sig_weight_rescale)\n",
    "            sig_weight[sig_weight < 0] = 0\n",
    "            events.loc[sig_key, \"weight\"] = sig_weight * sig_weight_rescale\n",
    "\n",
    "        for key in training_keys:\n",
    "            print(f\"Total {key} post-normalization: {events.loc[key, 'weight'].sum():.3f}\")\n",
    "\n",
    "    if equalize_weights:\n",
    "        print(\"Equalize weights\")\n",
    "        # scales signal such that total signal = total background\n",
    "        bkg_total = np.sum([np.sum(weights_bdt[key]) for key in args.bg_keys])\n",
    "\n",
    "        num_sigs = len(args.sig_keys)\n",
    "        for sig_key in args.sig_keys:\n",
    "            if sig_key not in weights_bdt:\n",
    "                continue\n",
    "            sig_total = np.sum(weights_bdt[sig_key])\n",
    "            print(f\"Scaling {sig_key} by {bkg_total / sig_total} / {num_sigs} signal(s).\")\n",
    "            events.loc[sig_key, \"weight\"] = (\n",
    "                weights_bdt[sig_key] * (bkg_total / sig_total) / num_sigs\n",
    "            )\n",
    "\n",
    "        for key in args.bg_keys:\n",
    "            events.loc[key, \"weight\"] = weights_bdt[key]\n",
    "\n",
    "        for key in training_keys:\n",
    "            print(f\"Total {key} post-normalization: {events.loc[key, 'weight'].sum():.3f}\")\n",
    "\n",
    "    # Define target\n",
    "    events[\"target\"] = 0  # Default to 0 (background)\n",
    "    for key in args.sig_keys:\n",
    "        if key in training_keys:\n",
    "            events.loc[key, \"target\"] = 1  # Set to 1 for 'hh4b' samples (signal)\n",
    "\n",
    "    target = events[\"target\"]\n",
    "    simple_target = events[\"target\"]\n",
    "\n",
    "    print(\"multiclass labeling\")\n",
    "    if multiclass:\n",
    "        target = label_encoder.transform(list(events.index.get_level_values(0)))\n",
    "\n",
    "    # Define event number\n",
    "    events[\"event\"] = 1\n",
    "    for key in training_keys:\n",
    "        events.loc[key, \"event\"] = events_bdt[key]\n",
    "    event_num = events[\"event\"]\n",
    "\n",
    "    # Define features\n",
    "    features = events.drop(columns=[\"target\", \"event\"])\n",
    "\n",
    "    # Split the (bdt dataframe) dataset\n",
    "    X_train, X_test, y_train, y_test, yt_train, yt_test, ev_train, ev_test = train_test_split(\n",
    "        features,\n",
    "        target,\n",
    "        simple_target,\n",
    "        event_num,\n",
    "        test_size=test_size,\n",
    "        random_state=seed,\n",
    "        shuffle=True,\n",
    "    )\n",
    "\n",
    "    # drop weights from features\n",
    "    weights_train = X_train[\"weight\"].copy()\n",
    "    X_train = X_train.drop(columns=[\"weight\"])\n",
    "    weights_test = X_test[\"weight\"].copy()\n",
    "    X_test = X_test.drop(columns=[\"weight\"])\n",
    "\n",
    "    for key in training_keys:\n",
    "        print(f\"Total training {key} after splitting: {weights_train.loc[key].sum():.3f}\")\n",
    "\n",
    "    for key in training_keys:\n",
    "        print(f\"Total testing {key} after splitting: {weights_test.loc[key].sum():.3f}\")\n",
    "\n",
    "    return (\n",
    "        X_train,\n",
    "        X_test,\n",
    "        y_train,\n",
    "        y_test,\n",
    "        weights_train,\n",
    "        weights_test,\n",
    "        yt_train,\n",
    "        yt_test,\n",
    "        ev_train,\n",
    "        ev_test,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the model\n",
    "\n",
    "model_dir = (\n",
    "    \"/home/users/dprimosc/HH4b/src/HH4b/boosted/bdt_trainings_run3/24May31_lr_0p02_md_8_AK4Away\"\n",
    ")\n",
    "config_name = \"24May31_lr_0p02_md_8_AK4Away\"\n",
    "\n",
    "\n",
    "def load_model(model_path: Path) -> xgb.XGBClassifier:\n",
    "    with open(model_path, \"rb\") as f:\n",
    "        model = pickle.load(f)\n",
    "    return model\n",
    "\n",
    "\n",
    "model = load_model(model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_bdt():\n",
    "    \"\"\"\n",
    "    1) Makes ROC curves for testing data\n",
    "    2) Prints Sig efficiency at Bkg efficiency\n",
    "    \"\"\"\n",
    "    plot_dir = model_dir / \"evaluation\"\n",
    "    plot_dir.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "    # sorting by importance\n",
    "    importances = model.feature_importances_\n",
    "    feature_importances = sorted(\n",
    "        zip(list(X_test.columns), importances), key=lambda x: x[1], reverse=True\n",
    "    )\n",
    "    feature_importance_df = pd.DataFrame.from_dict({\"Importance\": feature_importances})\n",
    "    feature_importance_df.to_markdown(f\"{model_dir}/feature_importances.md\")\n",
    "\n",
    "    # make and save ROCs for testing data\n",
    "    def find_nearest(array, value):\n",
    "        array = np.asarray(array)\n",
    "        idx = (np.abs(array - value)).argmin()\n",
    "        return idx\n",
    "\n",
    "    y_scores = model.predict_proba(X_test)\n",
    "    y_scores = _get_bdt_scores(y_scores, sig_keys, multiclass)\n",
    "\n",
    "    for i, sig_key in enumerate(sig_keys):\n",
    "        (plot_dir / sig_key).mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "        print(f\"Evaluating {sig_key} performance\")\n",
    "\n",
    "        if multiclass:\n",
    "            # selecting only this signal + BGs for ROC curves\n",
    "            bgs = y_test >= len(sig_keys)\n",
    "            sigs = y_test == i\n",
    "            sel = np.logical_or(sigs, bgs).squeeze()\n",
    "        else:\n",
    "            sel = np.ones(len(y_test), dtype=bool)\n",
    "\n",
    "        print(\"Test ROC with sample weights\")\n",
    "        fpr, tpr, thresholds = roc_curve(\n",
    "            yt_test[sel], y_scores[sel][:, i], sample_weight=weights_test[sel]\n",
    "        )\n",
    "\n",
    "        roc_info = {\n",
    "            \"fpr\": fpr,\n",
    "            \"tpr\": tpr,\n",
    "            \"thresholds\": thresholds,\n",
    "        }\n",
    "        with (plot_dir / sig_key / \"roc_dict.pkl\").open(\"wb\") as f:\n",
    "            pickle.dump(roc_info, f)\n",
    "\n",
    "        # print FPR, TPR for a couple of tprs\n",
    "        for tpr_val in [0.10, 0.12, 0.15]:\n",
    "            idx = find_nearest(tpr, tpr_val)\n",
    "            print(\n",
    "                f\"Signal efficiency: {tpr[idx]:.4f}, Background efficiency: {fpr[idx]:.5f}, BDT Threshold: {thresholds[idx]}\"\n",
    "            )\n",
    "\n",
    "        # plot BDT scores for test samples\n",
    "        make_bdt_dataframe = importlib.import_module(\n",
    "            f\".{config_name}\", package=\"HH4b.boosted.bdt_trainings_run3\"\n",
    "        )\n",
    "\n",
    "        print(\"Performing inference on all samples\")\n",
    "        # get scores from full dataframe, but only use testing indices\n",
    "        scores = {}\n",
    "        weights = {}\n",
    "        mass_dict = {}\n",
    "        msd_dict = {}\n",
    "        xbb_dict = {}\n",
    "\n",
    "        for key in training_keys:\n",
    "            score = []\n",
    "            weight = []\n",
    "            mass = []\n",
    "            msd = []\n",
    "            xbb = []\n",
    "            for year in events_dict_years:\n",
    "                evt_list = get_evt_testing(f\"{model_dir}/inferences/{year}\", key)\n",
    "                if evt_list is None:\n",
    "                    continue\n",
    "\n",
    "                events = events_dict_years[year][key]\n",
    "                bdt_events = make_bdt_dataframe.bdt_dataframe(events)\n",
    "                test_bdt_dataframe = bdt_events.copy()\n",
    "                bdt_events[\"event\"] = events[\"event\"].to_numpy()[:, 0]\n",
    "                bdt_events[\"finalWeight\"] = events[\"finalWeight\"]\n",
    "                bdt_events[\"mass\"] = events[pnet_mass_str][1]\n",
    "                bdt_events[\"msd\"] = events[\"bbFatJetMsd\"][1]\n",
    "                bdt_events[\"xbb\"] = events[pnet_xbb_str][1]\n",
    "                mask = bdt_events[\"event\"].isin(evt_list)\n",
    "                test_dataset = bdt_events[mask]\n",
    "\n",
    "                test_bdt_dataframe = test_bdt_dataframe[mask]\n",
    "                test_preds = model.predict_proba(test_bdt_dataframe)\n",
    "\n",
    "                score.append(_get_bdt_scores(test_preds, sig_keys, multiclass)[:, i])\n",
    "                weight.append(test_dataset[\"finalWeight\"])\n",
    "                mass.append(test_dataset[\"mass\"])\n",
    "                msd.append(test_dataset[\"msd\"])\n",
    "                xbb.append(test_dataset[\"xbb\"])\n",
    "\n",
    "            scores[key] = np.concatenate(score)\n",
    "            weights[key] = np.concatenate(weight)\n",
    "            mass_dict[key] = np.concatenate(mass)\n",
    "            msd_dict[key] = np.concatenate(msd)\n",
    "            xbb_dict[key] = np.concatenate(xbb)\n",
    "\n",
    "        for key in events_dict_years[year]:\n",
    "            if key in training_keys:\n",
    "                continue\n",
    "            score = []\n",
    "            weight = []\n",
    "            xbb = []\n",
    "            for year in events_dict_years:\n",
    "                preds = model.predict_proba(\n",
    "                    make_bdt_dataframe.bdt_dataframe(events_dict_years[year][key])\n",
    "                )\n",
    "                score.append(_get_bdt_scores(preds, sig_keys, multiclass)[:, i])\n",
    "                weight.append(events_dict_years[year][key][\"finalWeight\"])\n",
    "                xbb.append(events_dict_years[year][key][pnet_xbb_str][1])\n",
    "                msd.append(events_dict_years[year][key][\"bbFatJetMsd\"][1])\n",
    "                mass.append(events_dict_years[year][key][pnet_mass_str][1])\n",
    "            scores[key] = np.concatenate(score)\n",
    "            weights[key] = np.concatenate(weight)\n",
    "            xbb_dict[key] = np.concatenate(xbb)\n",
    "            msd_dict[key] = np.concatenate(msd)\n",
    "            mass_dict[key] = np.concatenate(mass)\n",
    "\n",
    "        print(\"Making BDT shape plots\")\n",
    "\n",
    "        legtitle = get_legtitle(legacy, pnet_xbb_str)\n",
    "\n",
    "        h_bdt = hist.Hist(bdt_axis, cat_axis)\n",
    "        h_bdt_weight = hist.Hist(bdt_axis, cat_axis)\n",
    "        for key in scores:\n",
    "            h_bdt.fill(bdt=scores[key], cat=key)\n",
    "            h_bdt_weight.fill(scores[key], key, weight=weights[key])\n",
    "\n",
    "        hists = {\n",
    "            \"weight\": h_bdt_weight,\n",
    "            \"no_weight\": h_bdt,\n",
    "        }\n",
    "        for h_key, h in hists.items():\n",
    "            colors = plotting.color_by_sample\n",
    "            legends = plotting.label_by_sample\n",
    "\n",
    "            fig, ax = plt.subplots(1, 1, figsize=(12, 8))\n",
    "            for key in scores:\n",
    "                hep.histplot(\n",
    "                    h[{\"cat\": key}],\n",
    "                    ax=ax,\n",
    "                    label=f\"{legends[key]}\",\n",
    "                    histtype=\"step\",\n",
    "                    linewidth=1,\n",
    "                    color=colors[key],\n",
    "                    density=True,\n",
    "                    flow=\"none\",\n",
    "                )\n",
    "            ax.set_yscale(\"log\")\n",
    "            ax.legend(\n",
    "                title=legtitle,\n",
    "                bbox_to_anchor=(1.03, 1),\n",
    "                loc=\"upper left\",\n",
    "            )\n",
    "            ax.set_ylabel(\"Density\")\n",
    "            ax.set_title(\"Pre-Selection\")\n",
    "            ax.xaxis.grid(True, which=\"major\")\n",
    "            ax.yaxis.grid(True, which=\"major\")\n",
    "            fig.tight_layout()\n",
    "            fig.savefig(plot_dir / sig_key / f\"bdt_shape_{h_key}.png\")\n",
    "            fig.savefig(plot_dir / sig_key / f\"bdt_shape_{h_key}.pdf\", bbox_inches=\"tight\")\n",
    "            plt.close()\n",
    "\n",
    "        print(\"Making ROC Curves\")\n",
    "\n",
    "        # Plot and save ROC figure\n",
    "        for log, logstr in [(False, \"\"), (True, \"_log\")]:\n",
    "            fig, ax = plt.subplots(1, 1, figsize=(18, 12))\n",
    "            bkg_colors = {**plotting.color_by_sample, \"merged\": \"orange\"}\n",
    "            legends = {**plotting.label_by_sample, \"merged\": \"Total Background\"}\n",
    "            plot_thresholds = bdt_cuts\n",
    "            th_colours = [\"#9381FF\", \"#1f78b4\", \"#a6cee3\", \"cyan\", \"blue\"]\n",
    "\n",
    "            for bkg in [*bg_keys, \"merged\"]:\n",
    "                if bkg != \"merged\":\n",
    "                    scores_roc = np.concatenate([scores[sig_key], scores[bkg]])\n",
    "                    sig_jets_score = scores[sig_key]\n",
    "                    bkg_jets_score = scores[bkg]\n",
    "                    scores_true = np.concatenate(\n",
    "                        [\n",
    "                            np.ones(len(sig_jets_score)),\n",
    "                            np.zeros(len(bkg_jets_score)),\n",
    "                        ]\n",
    "                    )\n",
    "                    scores_weights = np.concatenate([weights[sig_key], weights[bkg]])\n",
    "                    fpr, tpr, thresholds = roc_curve(\n",
    "                        scores_true, scores_roc, sample_weight=scores_weights\n",
    "                    )\n",
    "                    # save background roc curves\n",
    "                    roc_info_bg = {\n",
    "                        \"fpr\": fpr,\n",
    "                        \"tpr\": tpr,\n",
    "                        \"thresholds\": thresholds,\n",
    "                    }\n",
    "                    with (plot_dir / sig_key / f\"roc_dict_{bkg}.pkl\").open(\"wb\") as f:\n",
    "                        pickle.dump(roc_info_bg, f)\n",
    "                else:\n",
    "                    scores_roc = np.concatenate(\n",
    "                        [scores[sig_key]] + [scores[bg_key] for bg_key in bg_keys]\n",
    "                    )\n",
    "                    sig_jets_score = scores[sig_key]\n",
    "                    bkg_jets_score = np.concatenate([scores[bg_key] for bg_key in bg_keys])\n",
    "                    scores_true = np.concatenate(\n",
    "                        [\n",
    "                            np.ones(len(sig_jets_score)),\n",
    "                            np.zeros(len(bkg_jets_score)),\n",
    "                        ]\n",
    "                    )\n",
    "                    scores_weights = np.concatenate(\n",
    "                        [weights[sig_key]] + [weights[bg_key] for bg_key in bg_keys]\n",
    "                    )\n",
    "                    fpr, tpr, thresholds = roc_curve(\n",
    "                        scores_true, scores_roc, sample_weight=scores_weights\n",
    "                    )\n",
    "                    # save background roc curves\n",
    "                    roc_info_bg = {\n",
    "                        \"fpr\": fpr,\n",
    "                        \"tpr\": tpr,\n",
    "                        \"thresholds\": thresholds,\n",
    "                    }\n",
    "                    with (plot_dir / sig_key / f\"roc_dict_{bkg}.pkl\").open(\"wb\") as f:\n",
    "                        pickle.dump(roc_info_bg, f)\n",
    "\n",
    "                ax.plot(tpr, fpr, linewidth=2, color=bkg_colors[bkg], label=legends[bkg])\n",
    "\n",
    "                pths = {th: [[], []] for th in plot_thresholds}\n",
    "                for th in plot_thresholds:\n",
    "                    idx = find_nearest(thresholds, th)\n",
    "                    pths[th][0].append(tpr[idx])\n",
    "                    pths[th][1].append(fpr[idx])\n",
    "\n",
    "                if bkg == \"merged\":\n",
    "                    for k, th in enumerate(plot_thresholds):\n",
    "                        plt.scatter(\n",
    "                            *pths[th],\n",
    "                            marker=\"o\",\n",
    "                            s=40,\n",
    "                            label=rf\"BDT > {th}\",\n",
    "                            color=th_colours[k],\n",
    "                            zorder=100,\n",
    "                        )\n",
    "\n",
    "                        plt.vlines(\n",
    "                            x=pths[th][0],\n",
    "                            ymin=0,\n",
    "                            ymax=pths[th][1],\n",
    "                            color=th_colours[k],\n",
    "                            linestyles=\"dashed\",\n",
    "                            alpha=0.5,\n",
    "                        )\n",
    "\n",
    "                        plt.hlines(\n",
    "                            y=pths[th][1],\n",
    "                            xmin=0,\n",
    "                            xmax=pths[th][0],\n",
    "                            color=th_colours[k],\n",
    "                            linestyles=\"dashed\",\n",
    "                            alpha=0.5,\n",
    "                        )\n",
    "\n",
    "            ax.set_title(f\"{plotting.label_by_sample[sig_key]} BDT ROC Curve\")\n",
    "            ax.set_xlabel(\"Signal efficiency\")\n",
    "            ax.set_ylabel(\"Background efficiency\")\n",
    "\n",
    "            if log:\n",
    "                ax.set_xlim([0.0, 0.6])\n",
    "                ax.set_ylim([1e-5, 1e-1])\n",
    "                ax.set_yscale(\"log\")\n",
    "            else:\n",
    "                ax.set_xlim([0.0, 0.7])\n",
    "                ax.set_ylim([0, 0.08])\n",
    "\n",
    "            ax.xaxis.grid(True, which=\"major\")\n",
    "            ax.yaxis.grid(True, which=\"major\")\n",
    "            ax.legend(\n",
    "                title=legtitle,\n",
    "                bbox_to_anchor=(1.03, 1),\n",
    "                loc=\"upper left\",\n",
    "            )\n",
    "            fig.tight_layout()\n",
    "            fig.savefig(plot_dir / sig_key / f\"roc_weights{logstr}.png\")\n",
    "            fig.savefig(plot_dir / sig_key / f\"roc_weights{logstr}.pdf\", bbox_inches=\"tight\")\n",
    "            plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\n",
    "        \"--year\",\n",
    "        nargs=\"+\",\n",
    "        type=str,\n",
    "        default=[\"2022EE\"],\n",
    "        choices=hh_vars.years,\n",
    "        help=\"years to train on\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--data-path\",\n",
    "        required=True,\n",
    "        help=\"path to training data\",\n",
    "        type=str,\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--model-name\",\n",
    "        required=True,\n",
    "        help=\"model name\",\n",
    "        type=str,\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--config-name\",\n",
    "        default=None,\n",
    "        help=\"config name in case model name is different\",\n",
    "        type=str,\n",
    "    )\n",
    "    parser.add_argument(\"--test-size\", default=0.4, help=\"testing/training split\", type=float)\n",
    "    parser.add_argument(\"--seed\", default=42, help=\"seed for testing/training split\", type=int)\n",
    "\n",
    "    parser.add_argument(\n",
    "        \"--sig-keys\", default=[\"hh4b\"], help=\"which signals to train on\", type=str, nargs=\"+\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--bg-keys\",\n",
    "        default=[\"qcd\", \"ttbar\"],\n",
    "        help=\"which backgrounds to train on\",\n",
    "        type=str,\n",
    "        nargs=\"+\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--xbb\",\n",
    "        choices=[\"bbFatJetPNetTXbb\", \"bbFatJetPNetTXbbLegacy\"],\n",
    "        help=\"xbb branch\",\n",
    "        required=True,\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--mass\",\n",
    "        choices=[\"bbFatJetPNetMass\", \"bbFatJetPNetMassLegacy\", \"bbFatJetMsd\"],\n",
    "        help=\"xbb pnet mass\",\n",
    "        required=True,\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--learning-rate\",\n",
    "        default=0.1,\n",
    "        help=\"BDT's learning rate\",\n",
    "        type=float,\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--max-depth\",\n",
    "        default=3,\n",
    "        help=\"BDT's maximum depth\",\n",
    "        type=int,\n",
    "    )\n",
    "\n",
    "    add_bool_arg(parser, \"legacy\", \"Legacy PNet versions\", default=False)\n",
    "    add_bool_arg(parser, \"evaluate-only\", \"Only evaluation, no training\", default=False)\n",
    "    add_bool_arg(parser, \"multiclass\", \"Classify each background separately\", default=True)\n",
    "    add_bool_arg(\n",
    "        parser, \"equalize-weights\", \"Equalise total signal and background weights\", default=True\n",
    "    )\n",
    "    add_bool_arg(parser, \"run2-wapproach\", \"Run2 weight approach\", default=False)\n",
    "    add_bool_arg(parser, \"pnet-plots\", \"Make PNet plots\", default=True)\n",
    "    add_bool_arg(parser, \"apply-cuts\", \"Apply cuts\", default=True)\n",
    "\n",
    "    args = parser.parse_args()\n",
    "    args.pnet_xbb_str = args.xbb\n",
    "    args.pnet_mass_str = args.mass\n",
    "\n",
    "    if args.config_name is None:\n",
    "        args.config_name = args.model_name\n",
    "\n",
    "    main(args)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (hh4b)",
   "language": "python",
   "name": "hh4b"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

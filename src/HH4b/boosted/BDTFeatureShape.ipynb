{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import hist\n",
    "import argparse\n",
    "import importlib\n",
    "import logging\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import mplhep as hep\n",
    "\n",
    "hep.style.use(\"CMS\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import auc, roc_curve\n",
    "\n",
    "import HH4b.utils as utils\n",
    "from HH4b import hh_vars\n",
    "from HH4b.log_utils import log_config\n",
    "from HH4b.plotting import multiROCCurveGrey\n",
    "from HH4b.utils import get_var_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_events_and_bdt(path_to_dir, year, jet_coll_pnet, jet_coll_mass, bdt_models):\n",
    "    # logger.info(f\"Load {year}\")\n",
    "\n",
    "    jet_collection = \"bbFatJet\"\n",
    "    reorder_txbb = True\n",
    "    txbb_str = \"bbFatJet\" + jet_coll_pnet\n",
    "    mass_str = \"bbFatJet\" + jet_coll_mass\n",
    "\n",
    "    txbb_preselection = {\n",
    "        \"bbFatJetPNetTXbb\": 0.3,\n",
    "        \"bbFatJetPNetTXbbLegacy\": 0.8,\n",
    "        \"bbFatJetParTTXbb\": 0.3,\n",
    "    }\n",
    "    msd1_preselection = {\n",
    "        \"bbFatJetPNetTXbb\": 40,\n",
    "        \"bbFatJetPNetTXbbLegacy\": 40,\n",
    "        \"bbFatJetParTTXbb\": 40,\n",
    "    }\n",
    "    msd2_preselection = {\n",
    "        \"bbFatJetPNetTXbb\": 30,\n",
    "        \"bbFatJetPNetTXbbLegacy\": 0,\n",
    "        \"bbFatJetParTTXbb\": 30,\n",
    "    }\n",
    "\n",
    "    sample_dirs = {\n",
    "        year: {\n",
    "            \"QCD\": [\n",
    "                \"QCD_HT-1000to1200\",\n",
    "                \"QCD_HT-1200to1500\",\n",
    "                \"QCD_HT-1500to2000\",\n",
    "                \"QCD_HT-2000\",\n",
    "                \"QCD_HT-400to600\",\n",
    "                \"QCD_HT-600to800\",\n",
    "                \"QCD_HT-800to1000\",\n",
    "            ],\n",
    "            \"ttbar\": [\n",
    "                \"TTto4Q\",\n",
    "            ],\n",
    "            \"diboson\": [\n",
    "                \"WW\",\n",
    "                \"WZ\",\n",
    "                \"ZZ\",\n",
    "            ],\n",
    "            \"VBFHH\": [\n",
    "                \"VBFHHTo4B_CV_1_C2V_1_C3_1_TuneCP5_13TeV-madgraph-pythia8\",\n",
    "                \"VBFHHto4B_CV_1_C2V_1_C3_1_TuneCP5_13p6TeV_madgraph-pythia8\",\n",
    "                \"VBFHHto4B_CV-1p74_C2V-1p37_C3-14p4_TuneCP5_13p6TeV_madgraph-pythia8\",\n",
    "                \"VBFHHto4B_CV-m0p012_C2V-0p030_C3-10p2_TuneCP5_13p6TeV_madgraph-pythia8\",\n",
    "                \"VBFHHto4B_CV-m0p758_C2V-1p44_C3-m19p3_TuneCP5_13p6TeV_madgraph-pythia8\",\n",
    "                \"VBFHHto4B_CV-m0p962_C2V-0p959_C3-m1p43_TuneCP5_13p6TeV_madgraph-pythia8\",\n",
    "                \"VBFHHto4B_CV-m1p21_C2V-1p94_C3-m0p94_TuneCP5_13p6TeV_madgraph-pythia8\",\n",
    "                \"VBFHHto4B_CV-m1p60_C2V-2p72_C3-m1p36_TuneCP5_13p6TeV_madgraph-pythia8\",\n",
    "                \"VBFHHto4B_CV-m1p83_C2V-3p57_C3-m3p39_TuneCP5_13p6TeV_madgraph-pythia8\",\n",
    "                \"VBFHHto4B_CV-m2p12_C2V-3p87_C3-m5p96_TuneCP5_13p6TeV_madgraph-pythia8\",\n",
    "            ],\n",
    "            \"VBFH\": [\n",
    "                \"VBFHto2B_M-125_dipoleRecoilOn\",\n",
    "            ],\n",
    "        },\n",
    "    }\n",
    "    sample_dirs_sig = {\n",
    "        year: {\n",
    "            \"hh4b\": [\n",
    "                \"GluGlutoHHto4B_kl-1p00_kt-1p00_c2-0p00_TuneCP5_13p6TeV?\"\n",
    "            ],  # the ? enforces exact matching\n",
    "        }\n",
    "    }\n",
    "\n",
    "    num_jets = 2\n",
    "\n",
    "    columns = [\n",
    "        (\"weight\", 1),  # genweight * otherweights\n",
    "        (\"event\", 1),\n",
    "        (\"MET_pt\", 1),\n",
    "        (\"bbFatJetTau3OverTau2\", 2),\n",
    "        (\"VBFJetPt\", 2),\n",
    "        (\"VBFJetEta\", 2),\n",
    "        (\"VBFJetPhi\", 2),\n",
    "        (\"VBFJetMass\", 2),\n",
    "        (\"AK4JetAwayPt\", 2),\n",
    "        (\"AK4JetAwayEta\", 2),\n",
    "        (\"AK4JetAwayPhi\", 2),\n",
    "        (\"AK4JetAwayMass\", 2),\n",
    "        (f\"{jet_collection}rawFactor\", num_jets),\n",
    "        (f\"{jet_collection}Pt\", num_jets),\n",
    "        (f\"{jet_collection}Msd\", num_jets),\n",
    "        (f\"{jet_collection}Eta\", num_jets),\n",
    "        (f\"{jet_collection}Phi\", num_jets),\n",
    "        (f\"{jet_collection}PNetPXbbLegacy\", num_jets),  # Legacy PNet\n",
    "        (f\"{jet_collection}PNetPQCDbLegacy\", num_jets),\n",
    "        (f\"{jet_collection}PNetPQCDbbLegacy\", num_jets),\n",
    "        (f\"{jet_collection}PNetPQCD0HFLegacy\", num_jets),\n",
    "        (f\"{jet_collection}PNetMassLegacy\", num_jets),\n",
    "        (f\"{jet_collection}PNetTXbbLegacy\", num_jets),\n",
    "        (f\"{jet_collection}PNetTXbb\", num_jets),  # 103X PNet\n",
    "        (f\"{jet_collection}PNetMass\", num_jets),\n",
    "        (f\"{jet_collection}PNetQCD0HF\", num_jets),\n",
    "        (f\"{jet_collection}PNetQCD1HF\", num_jets),\n",
    "        (f\"{jet_collection}PNetQCD2HF\", num_jets),\n",
    "        (f\"{jet_collection}ParTmassVis\", num_jets),  # GloParT\n",
    "        (f\"{jet_collection}ParTTXbb\", num_jets),\n",
    "        (f\"{jet_collection}ParTPXbb\", num_jets),\n",
    "        (f\"{jet_collection}ParTPQCD0HF\", num_jets),\n",
    "        (f\"{jet_collection}ParTPQCD1HF\", num_jets),\n",
    "        (f\"{jet_collection}ParTPQCD2HF\", num_jets),\n",
    "    ]\n",
    "    signal_exclusive_columns = []\n",
    "\n",
    "    # selection to apply\n",
    "    filters = [\n",
    "        [\n",
    "            (f\"('{jet_collection}Pt', '0')\", \">=\", 250),\n",
    "            (f\"('{jet_collection}Pt', '1')\", \">=\", 250),\n",
    "        ],\n",
    "    ]\n",
    "\n",
    "    # correct mass for glopart-v2; remove once done in skimmer!\n",
    "    def correct_mass(events_dict, mass_str):\n",
    "        for key in events_dict:\n",
    "            print(events_dict[key][(mass_str, 0)])\n",
    "            events_dict[key][(mass_str, 0)] = events_dict[key][(mass_str, 0)] * (\n",
    "                1 - events_dict[key][(\"bbFatJetrawFactor\", 0)]\n",
    "            )\n",
    "            print(events_dict[key][(mass_str, 0)])\n",
    "\n",
    "            events_dict[key][(mass_str, 1)] = events_dict[key][(mass_str, 1)] * (\n",
    "                1 - events_dict[key][(\"bbFatJetrawFactor\", 1)]\n",
    "            )\n",
    "        return events_dict\n",
    "\n",
    "    def apply_cuts(events_dict, txbb_str, mass_str):\n",
    "        for key in events_dict:\n",
    "\n",
    "            msd1 = events_dict[key][\"bbFatJetMsd\"][0]\n",
    "            msd2 = events_dict[key][\"bbFatJetMsd\"][1]\n",
    "            pt1 = events_dict[key][\"bbFatJetPt\"][0]\n",
    "            pt2 = events_dict[key][\"bbFatJetPt\"][1]\n",
    "            txbb1 = events_dict[key][txbb_str][0]\n",
    "            mass1 = events_dict[key][mass_str][0]\n",
    "            mass2 = events_dict[key][mass_str][1]\n",
    "            # add msd > 40 cut for the first jet FIXME: replace this by the trigobj matched jet\n",
    "            events_dict[key] = events_dict[key][\n",
    "                (pt1 > 250)\n",
    "                & (pt2 > 250)\n",
    "                & (txbb1 > txbb_preselection[txbb_str])\n",
    "                & (msd1 > msd1_preselection[txbb_str])\n",
    "                & (msd2 > msd2_preselection[txbb_str])\n",
    "                & (mass1 > 50)\n",
    "                & (mass2 > 50)\n",
    "            ].copy()\n",
    "\n",
    "        events_dict = correct_mass(events_dict, mass_str)\n",
    "        return events_dict\n",
    "\n",
    "    # dictionary that will contain all information (from all samples)\n",
    "    events_dict = {\n",
    "        # this function will load files (only the columns selected), apply filters and compute a weight per event\n",
    "        **utils.load_samples(\n",
    "            path_to_dir,\n",
    "            sample_dirs_sig[year],\n",
    "            year,\n",
    "            filters=filters,\n",
    "            columns=utils.format_columns(columns + signal_exclusive_columns),\n",
    "            reorder_txbb=reorder_txbb,\n",
    "            txbb_str=txbb_str,\n",
    "            variations=False,\n",
    "        ),\n",
    "        **utils.load_samples(\n",
    "            path_to_dir,  # input directory\n",
    "            sample_dirs[year],\n",
    "            year,  # year (to find corresponding luminosity)\n",
    "            filters=filters,\n",
    "            columns=utils.format_columns(\n",
    "                columns\n",
    "            ),  # columns to load from parquet (to not load all columns), IMPORTANT columns must be formatted: (\"column name\", \"idx\")\n",
    "            reorder_txbb=reorder_txbb,  # whether to reorder bbFatJet collection\n",
    "            txbb_str=txbb_str,\n",
    "            variations=False,  # do not load systematic variations of weights\n",
    "        ),\n",
    "    }\n",
    "\n",
    "    def get_bdt(events_dict, bdt_model, bdt_model_name, bdt_config, jlabel=\"\"):\n",
    "        bdt_model = xgb.XGBClassifier()\n",
    "        bdt_model.load_model(\n",
    "            fname=f\"../boosted/bdt_trainings_run3/{bdt_model_name}/trained_bdt.model\"\n",
    "        )\n",
    "        make_bdt_dataframe = importlib.import_module(\n",
    "            f\".{bdt_config}\", package=\"HH4b.boosted.bdt_trainings_run3\"\n",
    "        )\n",
    "        bdt_events = make_bdt_dataframe.bdt_dataframe(events_dict, get_var_mapping(jlabel))\n",
    "        preds = bdt_model.predict_proba(bdt_events)\n",
    "\n",
    "        bdt_score = None\n",
    "        bdt_score_vbf = None\n",
    "        if preds.shape[1] == 2:  # binary BDT only\n",
    "            bdt_score = preds[:, 1]\n",
    "        elif preds.shape[1] == 3:  # multi-class BDT with ggF HH, QCD, ttbar classes\n",
    "            bdt_score = preds[:, 0]  # ggF HH\n",
    "        elif preds.shape[1] == 4:  # multi-class BDT with ggF HH, VBF HH, QCD, ttbar classes\n",
    "            bg_tot = np.sum(preds[:, 2:], axis=1)\n",
    "            bdt_score = preds[:, 0] / (preds[:, 0] + bg_tot)\n",
    "            bdt_score_vbf = preds[:, 1] / (preds[:, 1] + preds[:, 2] + preds[:, 3])\n",
    "\n",
    "        print(len(bdt_score))\n",
    "        print(len(bdt_score_vbf))\n",
    "        print(bdt_events.shape[0])\n",
    "        return bdt_score, bdt_score_vbf, bdt_events\n",
    "\n",
    "    events_dict = apply_cuts(events_dict, txbb_str, mass_str)\n",
    "\n",
    "    # TODO: check that weights are applied and correct scores used\n",
    "    bdt_score_dict = {}\n",
    "    bdt_score_vbf_dict = {}\n",
    "    bdt_df_dict = {}\n",
    "\n",
    "    for bdt_model in bdt_models:\n",
    "        # logger.info(f\"Perform inference {bdt_model}\")\n",
    "        bdt_config = bdt_models[bdt_model][\"config\"]\n",
    "        bdt_model_name = bdt_models[bdt_model][\"model_name\"]\n",
    "\n",
    "        for key in events_dict:\n",
    "            bdt_score, bdt_score_vbf, bdt_df = get_bdt(\n",
    "                events_dict[key], bdt_model, bdt_model_name, bdt_config\n",
    "            )\n",
    "\n",
    "            # Add BDT scores back to the event dictionary under the specific key\n",
    "            events_dict[key][f\"bdtscore_{bdt_model}\"] = (\n",
    "                bdt_score if bdt_score is not None else np.ones(events_dict[key][\"weight\"])\n",
    "            )\n",
    "            events_dict[key][f\"bdtscoreVBF_{bdt_model}\"] = (\n",
    "                bdt_score_vbf if bdt_score_vbf is not None else np.ones(events_dict[key][\"weight\"])\n",
    "            )\n",
    "\n",
    "            # Store the results for each key (hh4b, qcd, ttbar) separately\n",
    "            if key not in bdt_score_dict:\n",
    "                bdt_score_dict[key] = []\n",
    "                bdt_score_vbf_dict[key] = []\n",
    "                bdt_df_dict[key] = []\n",
    "\n",
    "            # Append the BDT scores and DataFrame for each key\n",
    "            bdt_score_dict[key].append(bdt_score)\n",
    "            bdt_score_vbf_dict[key].append(bdt_score_vbf)\n",
    "            bdt_df_dict[key].append(bdt_df)\n",
    "\n",
    "    # Concatenate all the BDT scores and DataFrames for each key separately\n",
    "    bdt_score_dict = {key: np.concatenate(bdt_score_dict[key]) for key in bdt_score_dict}\n",
    "    bdt_score_vbf_dict = {\n",
    "        key: np.concatenate(bdt_score_vbf_dict[key]) for key in bdt_score_vbf_dict\n",
    "    }\n",
    "    bdt_df_dict = {key: pd.concat(bdt_df_dict[key], ignore_index=True) for key in bdt_df_dict}\n",
    "\n",
    "    # Add finalWeight to the list of columns being retained\n",
    "    for key in events_dict:\n",
    "        bdt_scores = [f\"bdtscore_{bdt_model}\", f\"bdtscoreVBF_{bdt_model}\", \"finalWeight\"]\n",
    "        events_dict[key] = events_dict[key][bdt_scores]\n",
    "\n",
    "    # Return dictionaries for BDT scores and the DataFrames, with keys retained\n",
    "    return (\n",
    "        bdt_score_dict,\n",
    "        bdt_score_vbf_dict,\n",
    "        bdt_df_dict,\n",
    "    )  # TODO: adjust return values so they have keys for each sample key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Plot BDT Inputs\n",
    "\n",
    "#TODO: add description of the function\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def plot_bdt_features(bdt_score_dict, bdt_score_vbf_dict, bdt_df_dict, model_key):\n",
    "\n",
    "    # Define the BDT cut thresholds\n",
    "    bdt_cuts = [0.03, 0.88, 0.98]\n",
    "\n",
    "    # Define colors and labels for each histogram, including before any cut\n",
    "    colors = [\"black\", \"blue\", \"green\", \"red\"]  # Adjust colors as needed\n",
    "    labels = [\"Before BDT Cut\", \"BDT Cut > 0.03\", \"BDT Cut > 0.88\", \"BDT Cut > 0.98\"]\n",
    "\n",
    "    # Iterate over each key (e.g., \"hh4b\", \"qcd\", \"ttbar\")\n",
    "    for key in bdt_score_dict:\n",
    "        # Get BDT score, BDT score VBF, and BDT DataFrame for the current key\n",
    "        bdt_score = bdt_score_dict[key]\n",
    "        bdt_score_vbf = bdt_score_vbf_dict[key]\n",
    "        bdt_df = bdt_df_dict[key]\n",
    "\n",
    "        # Create boolean masks for each BDT cut\n",
    "        bdt_masks = [np.ones(len(bdt_score), dtype=bool)]  # Initial mask: all True (no cut)\n",
    "        for cut in bdt_cuts:\n",
    "            bdt_masks.append(bdt_score > cut)\n",
    "\n",
    "        bdt_masks_vbf = [np.ones(len(bdt_score_vbf), dtype=bool)]  # Initial mask: all True (no cut)\n",
    "        for cut in bdt_cuts:\n",
    "            bdt_masks_vbf.append(bdt_score_vbf > cut)\n",
    "\n",
    "        # Filter the columns to exclude those containing \"VBF\" or \"AK4\"\n",
    "        # columns_to_plot = [col for col in bdt_df.columns if (\"VBF\" not in col and \"AK4\" not in col)]\n",
    "\n",
    "        columns_to_plot = [\"H1Mass\"]\n",
    "        # print(columns_to_plot)\n",
    "        # Loop over each feature in the DataFrame\n",
    "        for column in columns_to_plot:\n",
    "            plt.figure(figsize=(12, 6))\n",
    "            print(f\"Plotting {column} for {key}\")\n",
    "\n",
    "            # Define a consistent binning for the histogram (50 bins between min and max of the column)\n",
    "            min_val = bdt_df[column].min()\n",
    "            max_val = bdt_df[column].max()\n",
    "            feature_axis = hist.axis.Regular(50, min_val, max_val, name=\"Feature\", label=column)\n",
    "            cut_axis = hist.axis.StrCategory([], name=\"Cut\", growth=True)\n",
    "\n",
    "            # Create a 2D histogram object for this feature and cuts\n",
    "            h = hist.Hist(feature_axis, cut_axis)\n",
    "\n",
    "            # Fill the histogram for each mask (i.e., each BDT cut)\n",
    "            for i, mask in enumerate(bdt_masks):\n",
    "                h.fill(Feature=bdt_df.loc[mask, column], Cut=labels[i])\n",
    "\n",
    "            # Plot the histograms using mplhep\n",
    "            hep.histplot(\n",
    "                [h[{\"Cut\": label}] for label in labels],\n",
    "                stack=False,\n",
    "                density=True,\n",
    "                histtype=\"step\",\n",
    "                label=labels,\n",
    "                color=colors,\n",
    "                linewidth=1.5,\n",
    "            )\n",
    "\n",
    "            plt.title(f\"Distribution of {column} for {key} (model: {model_key})\")\n",
    "            plt.xlabel(f\"{column} (GeV)\")  # TODO: automate units\n",
    "            plt.ylabel(\"Events (Normalized)\")\n",
    "            plt.legend()\n",
    "            plt.grid(True)\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "Execute functions here \n",
    "\n",
    "\"\"\"\n",
    "\n",
    "path_to_dir = \"/home/users/dprimosc/data/24Sep25_v12v2_private_signal\"\n",
    "year = \"2022\"\n",
    "jet_collection = \"bbFatJet\"\n",
    "jet_index = 0\n",
    "jet_coll_pnet = \"ParTTXbb\"  # \"PNetTXbbLegacy\"\n",
    "jet_coll_mass = \"ParTmassVis\"  # \"PNetMassLegacy\"\n",
    "\n",
    "bdt_models = {\n",
    "    # \"v5_PNetLegacy\": {\n",
    "    #    \"config\": \"v5\",\n",
    "    #    \"model_name\": \"24May31_lr_0p02_md_8_AK4Away\",\n",
    "    # },\n",
    "    \"v5_ParT\": {\n",
    "        \"config\": \"v5_glopartv2\",\n",
    "        \"model_name\": \"24Sep27_v5_glopartv2\",\n",
    "    },\n",
    "    # \"v5_parT_rawmass\": {\n",
    "    #    \"config\": \"v5_glopartv2\",\n",
    "    #    \"model_name\": \"24Nov7_v5_glopartv2_rawmass\",\n",
    "    # },\n",
    "}\n",
    "print(bdt_models.items())\n",
    "model_key = bdt_models.items()\n",
    "\n",
    "bdt_score_dict, bdt_score_vbf_dict, bdt_df_dict = load_events_and_bdt(\n",
    "    path_to_dir, year, jet_coll_pnet, jet_coll_mass, bdt_models\n",
    ")\n",
    "\n",
    "\n",
    "plot_bdt_features(bdt_score_dict, bdt_score_vbf_dict, bdt_df_dict, \"v5_ParT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
